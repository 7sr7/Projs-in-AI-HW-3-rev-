{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7sr7/Projs-in-AI-HW-3-rev-/blob/main/Silvestre_Projs_in_AI_HW3_redo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuQZsap_cL1l"
      },
      "source": [
        "Silvestre Ronin\n",
        "\n",
        "Professor Mushtaque\n",
        "\n",
        "PROJECTS IN AI & MACHINE LRNG - CSCI 4170 - 01\n",
        "\n",
        "2025 06 19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "Vl8xG8zIrLJP"
      },
      "outputs": [],
      "source": [
        "# importing required libraries...\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import Normalizer, StandardScaler\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMqYJS-NFHUG"
      },
      "source": [
        "NOTE TO GRADER:\n",
        "\n",
        "The very first thing I did after choosing my dataset was to run EDA and train-dev-test split. This step is explitictly stated in Part 2, Task 2.\n",
        "\n",
        "However, the reason I chose to do this as my first step was because I figured running the \"unclean\" data on my Part 1 did not make sense to do since maybe features are highly correlated or if the data is not normalized, then perhaps the model will not predict as accurately as it should be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE2ZISi1omm5"
      },
      "source": [
        "The following link is the dataset I have chosen:\n",
        "\n",
        "https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17?select=star_classification.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoikrqRvrOha",
        "outputId": "651f517c-22b1-4f22-ddc4-2c574f8bf63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mounting to google drive...\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ynTHIqnorPaU"
      },
      "outputs": [],
      "source": [
        "# reading data set...\n",
        "data = pd.read_csv('/content/drive/MyDrive/star_classification.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Xq2OTS6Krua_",
        "outputId": "94163eae-166f-4583-f1f9-8acae2b4aef8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
              "\n",
              "    class  redshift  plate    MJD  fiber_ID  \n",
              "0  GALAXY  0.634794   5812  56354       171  \n",
              "1  GALAXY  0.779136  10445  58158       427  \n",
              "2  GALAXY  0.644195   4576  55592       299  \n",
              "3  GALAXY  0.932346   9149  58039       775  \n",
              "4  GALAXY  0.116123   6121  56187       842  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c3b0ab5-482d-4037-9cb8-4f1dcb40df6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>class</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237661e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543777e+18</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237665e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176014e+19</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237661e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237663e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030107e+19</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891865e+18</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c3b0ab5-482d-4037-9cb8-4f1dcb40df6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c3b0ab5-482d-4037-9cb8-4f1dcb40df6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c3b0ab5-482d-4037-9cb8-4f1dcb40df6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-59b3b543-96ed-411a-b643-5c130377b20a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59b3b543-96ed-411a-b643-5c130377b20a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-59b3b543-96ed-411a-b643-5c130377b20a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8438559894562.677,\n        \"min\": 1.23764594290439e+18,\n        \"max\": 1.2376805313563863e+18,\n        \"num_unique_values\": 78053,\n        \"samples\": [\n          1.2376623373364104e+18,\n          1.2376517368478438e+18,\n          1.2376584933481513e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96.50224089833225,\n        \"min\": 0.0055278279239701,\n        \"max\": 359.999809770956,\n        \"num_unique_values\": 99999,\n        \"samples\": [\n          118.663236264366,\n          358.991829744244,\n          30.887222067625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.644665404293633,\n        \"min\": -18.7853280771825,\n        \"max\": 83.00051858898,\n        \"num_unique_values\": 99999,\n        \"samples\": [\n          39.6424291996807,\n          32.7490859208678,\n          1.18870964120799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.769290803750323,\n        \"min\": -9999.0,\n        \"max\": 32.78139,\n        \"num_unique_values\": 93748,\n        \"samples\": [\n          25.78018,\n          20.35472,\n          18.63082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.750292329083205,\n        \"min\": -9999.0,\n        \"max\": 31.60224,\n        \"num_unique_values\": 92651,\n        \"samples\": [\n          20.88286,\n          23.75559,\n          17.81253\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8547596943455276,\n        \"min\": 9.82207,\n        \"max\": 29.57186,\n        \"num_unique_values\": 91901,\n        \"samples\": [\n          17.36957,\n          21.53207,\n          16.49815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"i\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7578947904903852,\n        \"min\": 9.469903,\n        \"max\": 32.14147,\n        \"num_unique_values\": 92019,\n        \"samples\": [\n          20.34415,\n          17.00401,\n          19.63559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.728151785953937,\n        \"min\": -9999.0,\n        \"max\": 29.38374,\n        \"num_unique_values\": 92007,\n        \"samples\": [\n          17.31985,\n          22.73434,\n          19.62752\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1964,\n        \"min\": 109,\n        \"max\": 8162,\n        \"num_unique_values\": 430,\n        \"samples\": [\n          6174,\n          7917,\n          4679\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rerun_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 301,\n        \"max\": 301,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cam_col\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 149,\n        \"min\": 11,\n        \"max\": 989,\n        \"num_unique_values\": 856,\n        \"samples\": [\n          706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spec_obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.324016169583855e+18,\n        \"min\": 2.9951908938097664e+17,\n        \"max\": 1.4126940609093851e+19,\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          4.855016555329904e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"GALAXY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"redshift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7307072761888128,\n        \"min\": -0.009970667,\n        \"max\": 7.011245,\n        \"num_unique_values\": 99295,\n        \"samples\": [\n          3.202965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2952,\n        \"min\": 266,\n        \"max\": 12547,\n        \"num_unique_values\": 6284,\n        \"samples\": [\n          2264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MJD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1808,\n        \"min\": 51608,\n        \"max\": 58932,\n        \"num_unique_values\": 2180,\n        \"samples\": [\n          55332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fiber_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# viewing the first few rows of the data...\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za3kBBaeDVOx",
        "outputId": "9af0d58b-68b7-4a1d-8e0b-b717f1cb6932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# determining data size....\n",
        "# many data observations and data parameters --> \"complex data\" --> use of NNs...\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "AEDZ35RsYnVV",
        "outputId": "4f39cfd9-9305-480d-e0cb-7ac230ab4e33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "obj_ID         0\n",
              "alpha          0\n",
              "delta          0\n",
              "u              0\n",
              "g              0\n",
              "r              0\n",
              "i              0\n",
              "z              0\n",
              "run_ID         0\n",
              "rerun_ID       0\n",
              "cam_col        0\n",
              "field_ID       0\n",
              "spec_obj_ID    0\n",
              "class          0\n",
              "redshift       0\n",
              "plate          0\n",
              "MJD            0\n",
              "fiber_ID       0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>obj_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rerun_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cam_col</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>field_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>redshift</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MJD</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiber_ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# checking missing values...\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gY_YLosDYogQ",
        "outputId": "c91bb13b-83ba-4e0a-a325-ce4ac272f384"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         obj_ID       alpha      delta         u         g         r  \\\n",
              "0  1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
              "1  1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
              "2  1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
              "3  1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
              "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
              "\n",
              "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
              "0  19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
              "1  21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
              "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
              "3  20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
              "4  15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
              "\n",
              "    class  redshift  plate    MJD  fiber_ID  isGalaxy  \n",
              "0  GALAXY  0.634794   5812  56354       171         1  \n",
              "1  GALAXY  0.779136  10445  58158       427         1  \n",
              "2  GALAXY  0.644195   4576  55592       299         1  \n",
              "3  GALAXY  0.932346   9149  58039       775         1  \n",
              "4  GALAXY  0.116123   6121  56187       842         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad028fdc-186c-4a47-a5a2-9238ce44d3a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>class</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>isGalaxy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.237661e+18</td>\n",
              "      <td>135.689107</td>\n",
              "      <td>32.494632</td>\n",
              "      <td>23.87882</td>\n",
              "      <td>22.27530</td>\n",
              "      <td>20.39501</td>\n",
              "      <td>19.16573</td>\n",
              "      <td>18.79371</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>6.543777e+18</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.634794</td>\n",
              "      <td>5812</td>\n",
              "      <td>56354</td>\n",
              "      <td>171</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.237665e+18</td>\n",
              "      <td>144.826101</td>\n",
              "      <td>31.274185</td>\n",
              "      <td>24.77759</td>\n",
              "      <td>22.83188</td>\n",
              "      <td>22.58444</td>\n",
              "      <td>21.16812</td>\n",
              "      <td>21.61427</td>\n",
              "      <td>4518</td>\n",
              "      <td>301</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>1.176014e+19</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.779136</td>\n",
              "      <td>10445</td>\n",
              "      <td>58158</td>\n",
              "      <td>427</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.237661e+18</td>\n",
              "      <td>142.188790</td>\n",
              "      <td>35.582444</td>\n",
              "      <td>25.26307</td>\n",
              "      <td>22.66389</td>\n",
              "      <td>20.60976</td>\n",
              "      <td>19.34857</td>\n",
              "      <td>18.94827</td>\n",
              "      <td>3606</td>\n",
              "      <td>301</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>5.152200e+18</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.644195</td>\n",
              "      <td>4576</td>\n",
              "      <td>55592</td>\n",
              "      <td>299</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.237663e+18</td>\n",
              "      <td>338.741038</td>\n",
              "      <td>-0.402828</td>\n",
              "      <td>22.13682</td>\n",
              "      <td>23.77656</td>\n",
              "      <td>21.61162</td>\n",
              "      <td>20.50454</td>\n",
              "      <td>19.25010</td>\n",
              "      <td>4192</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>214</td>\n",
              "      <td>1.030107e+19</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.932346</td>\n",
              "      <td>9149</td>\n",
              "      <td>58039</td>\n",
              "      <td>775</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.237680e+18</td>\n",
              "      <td>345.282593</td>\n",
              "      <td>21.183866</td>\n",
              "      <td>19.43718</td>\n",
              "      <td>17.58028</td>\n",
              "      <td>16.49747</td>\n",
              "      <td>15.97711</td>\n",
              "      <td>15.54461</td>\n",
              "      <td>8102</td>\n",
              "      <td>301</td>\n",
              "      <td>3</td>\n",
              "      <td>137</td>\n",
              "      <td>6.891865e+18</td>\n",
              "      <td>GALAXY</td>\n",
              "      <td>0.116123</td>\n",
              "      <td>6121</td>\n",
              "      <td>56187</td>\n",
              "      <td>842</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad028fdc-186c-4a47-a5a2-9238ce44d3a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad028fdc-186c-4a47-a5a2-9238ce44d3a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad028fdc-186c-4a47-a5a2-9238ce44d3a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1c16f883-795d-419e-bd26-063828c6a2fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c16f883-795d-419e-bd26-063828c6a2fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1c16f883-795d-419e-bd26-063828c6a2fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8438559894562.677,\n        \"min\": 1.23764594290439e+18,\n        \"max\": 1.2376805313563863e+18,\n        \"num_unique_values\": 78053,\n        \"samples\": [\n          1.2376623373364104e+18,\n          1.2376517368478438e+18,\n          1.2376584933481513e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96.50224089833225,\n        \"min\": 0.0055278279239701,\n        \"max\": 359.999809770956,\n        \"num_unique_values\": 99999,\n        \"samples\": [\n          118.663236264366,\n          358.991829744244,\n          30.887222067625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.644665404293633,\n        \"min\": -18.7853280771825,\n        \"max\": 83.00051858898,\n        \"num_unique_values\": 99999,\n        \"samples\": [\n          39.6424291996807,\n          32.7490859208678,\n          1.18870964120799\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.769290803750323,\n        \"min\": -9999.0,\n        \"max\": 32.78139,\n        \"num_unique_values\": 93748,\n        \"samples\": [\n          25.78018,\n          20.35472,\n          18.63082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.750292329083205,\n        \"min\": -9999.0,\n        \"max\": 31.60224,\n        \"num_unique_values\": 92651,\n        \"samples\": [\n          20.88286,\n          23.75559,\n          17.81253\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8547596943455276,\n        \"min\": 9.82207,\n        \"max\": 29.57186,\n        \"num_unique_values\": 91901,\n        \"samples\": [\n          17.36957,\n          21.53207,\n          16.49815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"i\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7578947904903852,\n        \"min\": 9.469903,\n        \"max\": 32.14147,\n        \"num_unique_values\": 92019,\n        \"samples\": [\n          20.34415,\n          17.00401,\n          19.63559\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31.728151785953937,\n        \"min\": -9999.0,\n        \"max\": 29.38374,\n        \"num_unique_values\": 92007,\n        \"samples\": [\n          17.31985,\n          22.73434,\n          19.62752\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1964,\n        \"min\": 109,\n        \"max\": 8162,\n        \"num_unique_values\": 430,\n        \"samples\": [\n          6174,\n          7917,\n          4679\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rerun_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 301,\n        \"max\": 301,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cam_col\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 149,\n        \"min\": 11,\n        \"max\": 989,\n        \"num_unique_values\": 856,\n        \"samples\": [\n          706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spec_obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.324016169583855e+18,\n        \"min\": 2.9951908938097664e+17,\n        \"max\": 1.4126940609093851e+19,\n        \"num_unique_values\": 100000,\n        \"samples\": [\n          4.855016555329904e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"GALAXY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"redshift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7307072761888128,\n        \"min\": -0.009970667,\n        \"max\": 7.011245,\n        \"num_unique_values\": 99295,\n        \"samples\": [\n          3.202965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2952,\n        \"min\": 266,\n        \"max\": 12547,\n        \"num_unique_values\": 6284,\n        \"samples\": [\n          2264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MJD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1808,\n        \"min\": 51608,\n        \"max\": 58932,\n        \"num_unique_values\": 2180,\n        \"samples\": [\n          55332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fiber_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 272,\n        \"min\": 1,\n        \"max\": 1000,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isGalaxy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# so the dataset i am using characterizes space stuff into galaxies, stars, or quasars...\n",
        "# upon looking at the dataset, I noticed that \"GALAXY\" comprised most of the classification.\n",
        "# thus, i decided to make this a binary classification as just \"GALAXY\" and \"others (stars or quasars)\"...\n",
        "\n",
        "# making a new column that will be my binary output...\n",
        "data['isGalaxy'] = data['class'].apply(lambda x: 1 if x == 'GALAXY' else 0)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hMwuLXraCYs",
        "outputId": "0fca5e8f-8a7f-4fd0-cd62-dcfbe3e44af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 19 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   obj_ID       100000 non-null  float64\n",
            " 1   alpha        100000 non-null  float64\n",
            " 2   delta        100000 non-null  float64\n",
            " 3   u            100000 non-null  float64\n",
            " 4   g            100000 non-null  float64\n",
            " 5   r            100000 non-null  float64\n",
            " 6   i            100000 non-null  float64\n",
            " 7   z            100000 non-null  float64\n",
            " 8   run_ID       100000 non-null  int64  \n",
            " 9   rerun_ID     100000 non-null  int64  \n",
            " 10  cam_col      100000 non-null  int64  \n",
            " 11  field_ID     100000 non-null  int64  \n",
            " 12  spec_obj_ID  100000 non-null  float64\n",
            " 13  class        100000 non-null  object \n",
            " 14  redshift     100000 non-null  float64\n",
            " 15  plate        100000 non-null  int64  \n",
            " 16  MJD          100000 non-null  int64  \n",
            " 17  fiber_ID     100000 non-null  int64  \n",
            " 18  isGalaxy     100000 non-null  int64  \n",
            "dtypes: float64(10), int64(8), object(1)\n",
            "memory usage: 14.5+ MB\n"
          ]
        }
      ],
      "source": [
        "# general information about the dataset...\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ynnVDvDbaDzM",
        "outputId": "1ba23385-7b53-4877-845a-235916127abc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             obj_ID          alpha          delta              u  \\\n",
              "count  1.000000e+05  100000.000000  100000.000000  100000.000000   \n",
              "mean   1.237665e+18     177.629117      24.135305      21.980468   \n",
              "std    8.438560e+12      96.502241      19.644665      31.769291   \n",
              "min    1.237646e+18       0.005528     -18.785328   -9999.000000   \n",
              "25%    1.237659e+18     127.518222       5.146771      20.352353   \n",
              "50%    1.237663e+18     180.900700      23.645922      22.179135   \n",
              "75%    1.237668e+18     233.895005      39.901550      23.687440   \n",
              "max    1.237681e+18     359.999810      83.000519      32.781390   \n",
              "\n",
              "                   g              r              i              z  \\\n",
              "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
              "mean       20.531387      19.645762      19.084854      18.668810   \n",
              "std        31.750292       1.854760       1.757895      31.728152   \n",
              "min     -9999.000000       9.822070       9.469903   -9999.000000   \n",
              "25%        18.965230      18.135828      17.732285      17.460677   \n",
              "50%        21.099835      20.125290      19.405145      19.004595   \n",
              "75%        22.123767      21.044785      20.396495      19.921120   \n",
              "max        31.602240      29.571860      32.141470      29.383740   \n",
              "\n",
              "              run_ID  rerun_ID        cam_col       field_ID   spec_obj_ID  \\\n",
              "count  100000.000000  100000.0  100000.000000  100000.000000  1.000000e+05   \n",
              "mean     4481.366060     301.0       3.511610     186.130520  5.783882e+18   \n",
              "std      1964.764593       0.0       1.586912     149.011073  3.324016e+18   \n",
              "min       109.000000     301.0       1.000000      11.000000  2.995191e+17   \n",
              "25%      3187.000000     301.0       2.000000      82.000000  2.844138e+18   \n",
              "50%      4188.000000     301.0       4.000000     146.000000  5.614883e+18   \n",
              "75%      5326.000000     301.0       5.000000     241.000000  8.332144e+18   \n",
              "max      8162.000000     301.0       6.000000     989.000000  1.412694e+19   \n",
              "\n",
              "            redshift          plate            MJD       fiber_ID  \\\n",
              "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
              "mean        0.576661    5137.009660   55588.647500     449.312740   \n",
              "std         0.730707    2952.303351    1808.484233     272.498404   \n",
              "min        -0.009971     266.000000   51608.000000       1.000000   \n",
              "25%         0.054517    2526.000000   54234.000000     221.000000   \n",
              "50%         0.424173    4987.000000   55868.500000     433.000000   \n",
              "75%         0.704154    7400.250000   56777.000000     645.000000   \n",
              "max         7.011245   12547.000000   58932.000000    1000.000000   \n",
              "\n",
              "            isGalaxy  \n",
              "count  100000.000000  \n",
              "mean        0.594450  \n",
              "std         0.491001  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         1.000000  \n",
              "75%         1.000000  \n",
              "max         1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f504c56b-7a4f-4c90-9212-26e723161039\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>isGalaxy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.000000e+05</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>1.000000e+05</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.237665e+18</td>\n",
              "      <td>177.629117</td>\n",
              "      <td>24.135305</td>\n",
              "      <td>21.980468</td>\n",
              "      <td>20.531387</td>\n",
              "      <td>19.645762</td>\n",
              "      <td>19.084854</td>\n",
              "      <td>18.668810</td>\n",
              "      <td>4481.366060</td>\n",
              "      <td>301.0</td>\n",
              "      <td>3.511610</td>\n",
              "      <td>186.130520</td>\n",
              "      <td>5.783882e+18</td>\n",
              "      <td>0.576661</td>\n",
              "      <td>5137.009660</td>\n",
              "      <td>55588.647500</td>\n",
              "      <td>449.312740</td>\n",
              "      <td>0.594450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.438560e+12</td>\n",
              "      <td>96.502241</td>\n",
              "      <td>19.644665</td>\n",
              "      <td>31.769291</td>\n",
              "      <td>31.750292</td>\n",
              "      <td>1.854760</td>\n",
              "      <td>1.757895</td>\n",
              "      <td>31.728152</td>\n",
              "      <td>1964.764593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.586912</td>\n",
              "      <td>149.011073</td>\n",
              "      <td>3.324016e+18</td>\n",
              "      <td>0.730707</td>\n",
              "      <td>2952.303351</td>\n",
              "      <td>1808.484233</td>\n",
              "      <td>272.498404</td>\n",
              "      <td>0.491001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.237646e+18</td>\n",
              "      <td>0.005528</td>\n",
              "      <td>-18.785328</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>9.822070</td>\n",
              "      <td>9.469903</td>\n",
              "      <td>-9999.000000</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>301.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>2.995191e+17</td>\n",
              "      <td>-0.009971</td>\n",
              "      <td>266.000000</td>\n",
              "      <td>51608.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.237659e+18</td>\n",
              "      <td>127.518222</td>\n",
              "      <td>5.146771</td>\n",
              "      <td>20.352353</td>\n",
              "      <td>18.965230</td>\n",
              "      <td>18.135828</td>\n",
              "      <td>17.732285</td>\n",
              "      <td>17.460677</td>\n",
              "      <td>3187.000000</td>\n",
              "      <td>301.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>2.844138e+18</td>\n",
              "      <td>0.054517</td>\n",
              "      <td>2526.000000</td>\n",
              "      <td>54234.000000</td>\n",
              "      <td>221.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.237663e+18</td>\n",
              "      <td>180.900700</td>\n",
              "      <td>23.645922</td>\n",
              "      <td>22.179135</td>\n",
              "      <td>21.099835</td>\n",
              "      <td>20.125290</td>\n",
              "      <td>19.405145</td>\n",
              "      <td>19.004595</td>\n",
              "      <td>4188.000000</td>\n",
              "      <td>301.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>5.614883e+18</td>\n",
              "      <td>0.424173</td>\n",
              "      <td>4987.000000</td>\n",
              "      <td>55868.500000</td>\n",
              "      <td>433.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.237668e+18</td>\n",
              "      <td>233.895005</td>\n",
              "      <td>39.901550</td>\n",
              "      <td>23.687440</td>\n",
              "      <td>22.123767</td>\n",
              "      <td>21.044785</td>\n",
              "      <td>20.396495</td>\n",
              "      <td>19.921120</td>\n",
              "      <td>5326.000000</td>\n",
              "      <td>301.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>241.000000</td>\n",
              "      <td>8.332144e+18</td>\n",
              "      <td>0.704154</td>\n",
              "      <td>7400.250000</td>\n",
              "      <td>56777.000000</td>\n",
              "      <td>645.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.237681e+18</td>\n",
              "      <td>359.999810</td>\n",
              "      <td>83.000519</td>\n",
              "      <td>32.781390</td>\n",
              "      <td>31.602240</td>\n",
              "      <td>29.571860</td>\n",
              "      <td>32.141470</td>\n",
              "      <td>29.383740</td>\n",
              "      <td>8162.000000</td>\n",
              "      <td>301.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>989.000000</td>\n",
              "      <td>1.412694e+19</td>\n",
              "      <td>7.011245</td>\n",
              "      <td>12547.000000</td>\n",
              "      <td>58932.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f504c56b-7a4f-4c90-9212-26e723161039')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f504c56b-7a4f-4c90-9212-26e723161039 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f504c56b-7a4f-4c90-9212-26e723161039');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-05b5980b-fff6-41e7-a209-77a99c17847e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05b5980b-fff6-41e7-a209-77a99c17847e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-05b5980b-fff6-41e7-a209-77a99c17847e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.729250097863645e+17,\n        \"min\": 100000.0,\n        \"max\": 1.2376805313563863e+18,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.2376647218149033e+18,\n          1.2376634631442929e+18,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35296.074017679835,\n        \"min\": 0.0055278279239701,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          177.6291166216363,\n          180.9007001209685,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35346.426876733196,\n        \"min\": -18.7853280771825,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          24.135304595352267,\n          23.64592229835845,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36023.84468984557,\n        \"min\": -9999.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          21.980468269,\n          22.179135000000002,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36024.142466149366,\n        \"min\": -9999.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          20.5313869616,\n          21.099835,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35349.26898073893,\n        \"min\": 1.8547596943455276,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19.645762146,\n          20.12529,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"i\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35349.27983964072,\n        \"min\": 1.7578947904903852,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19.084854232030004,\n          19.405144999999997,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36024.584207028514,\n        \"min\": -9999.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          18.66881032223,\n          19.004595000000002,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34052.927613371845,\n        \"min\": 109.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4481.36606,\n          4188.0,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rerun_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35264.2795828867,\n        \"min\": 0.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          100000.0,\n          301.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cam_col\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35354.17244945678,\n        \"min\": 1.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.51161,\n          4.0,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35265.54531832858,\n        \"min\": 11.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          186.13052,\n          146.0,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spec_obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.628093122083379e+18,\n        \"min\": 100000.0,\n        \"max\": 1.4126940609093851e+19,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5.783882297552056e+18,\n          5.614883135353543e+18,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"redshift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35354.859743283996,\n        \"min\": -0.009970667,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5766608040203002,\n          0.42417325,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33748.82871803982,\n        \"min\": 266.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5137.00966,\n          4987.0,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MJD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26411.010981384956,\n        \"min\": 1808.4842328524269,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          55588.6475,\n          55868.5,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fiber_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35203.980693933205,\n        \"min\": 1.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          449.31274,\n          433.0,\n          100000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isGalaxy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35355.13271535509,\n        \"min\": 0.0,\n        \"max\": 100000.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.59445,\n          1.0,\n          0.4910006194661764\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# statistics of the dataset (numeric columns)...\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "iBfxGad0aHfv",
        "outputId": "14a33fe1-d275-4782-aa83-f292be56b22f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "obj_ID         False\n",
              "alpha          False\n",
              "delta          False\n",
              "u              False\n",
              "g              False\n",
              "r              False\n",
              "i              False\n",
              "z              False\n",
              "run_ID         False\n",
              "rerun_ID       False\n",
              "cam_col        False\n",
              "field_ID       False\n",
              "spec_obj_ID    False\n",
              "class          False\n",
              "redshift       False\n",
              "plate          False\n",
              "MJD            False\n",
              "fiber_ID       False\n",
              "isGalaxy       False\n",
              "dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>obj_ID</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_ID</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rerun_ID</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cam_col</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>field_ID</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>redshift</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plate</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MJD</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiber_ID</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isGalaxy</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# which columns have a missing value...?\n",
        "data.isnull().any(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "lLxWes5taKPS",
        "outputId": "d9d827ee-98a0-46b4-fd54-a09218ca929b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               obj_ID     alpha     delta         u         g         r  \\\n",
              "obj_ID       1.000000 -0.013735 -0.301237  0.015310  0.015710  0.153891   \n",
              "alpha       -0.013735  1.000000  0.138691 -0.001532 -0.002423 -0.022083   \n",
              "delta       -0.301237  0.138691  1.000000  0.002074  0.003523 -0.006835   \n",
              "u            0.015310 -0.001532  0.002074  1.000000  0.999311  0.054149   \n",
              "g            0.015710 -0.002423  0.003523  0.999311  1.000000  0.062387   \n",
              "r            0.153891 -0.022083 -0.006835  0.054149  0.062387  1.000000   \n",
              "i            0.147670 -0.023580 -0.004480  0.045730  0.056271  0.962868   \n",
              "z            0.013811 -0.002918  0.003630  0.998093  0.999161  0.053677   \n",
              "run_ID       1.000000 -0.013737 -0.301238  0.015309  0.015710  0.153889   \n",
              "rerun_ID          NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "cam_col     -0.046997  0.019582  0.032565  0.003548  0.003508  0.008480   \n",
              "field_ID     0.031498 -0.165577 -0.173416 -0.008374 -0.008852 -0.026423   \n",
              "spec_obj_ID  0.239461 -0.002553  0.112329  0.029997  0.039443  0.655245   \n",
              "redshift     0.065400  0.001667  0.031638  0.014309  0.022954  0.433241   \n",
              "plate        0.239460 -0.002554  0.112329  0.029997  0.039443  0.655243   \n",
              "MJD          0.262687  0.019943  0.107333  0.031997  0.040274  0.671180   \n",
              "fiber_ID     0.067178  0.030464  0.028250  0.016305  0.017470  0.223106   \n",
              "isGalaxy     0.019994  0.004085 -0.038297  0.023129  0.014289 -0.037997   \n",
              "\n",
              "                    i         z    run_ID  rerun_ID   cam_col  field_ID  \\\n",
              "obj_ID       0.147670  0.013811  1.000000       NaN -0.046997  0.031498   \n",
              "alpha       -0.023580 -0.002918 -0.013737       NaN  0.019582 -0.165577   \n",
              "delta       -0.004480  0.003630 -0.301238       NaN  0.032565 -0.173416   \n",
              "u            0.045730  0.998093  0.015309       NaN  0.003548 -0.008374   \n",
              "g            0.056271  0.999161  0.015710       NaN  0.003508 -0.008852   \n",
              "r            0.962868  0.053677  0.153889       NaN  0.008480 -0.026423   \n",
              "i            1.000000  0.055994  0.147668       NaN  0.007615 -0.026679   \n",
              "z            0.055994  1.000000  0.013811       NaN  0.003365 -0.008903   \n",
              "run_ID       0.147668  0.013811  1.000000       NaN -0.047098  0.031498   \n",
              "rerun_ID          NaN       NaN       NaN       NaN       NaN       NaN   \n",
              "cam_col      0.007615  0.003365 -0.047098       NaN  1.000000 -0.015684   \n",
              "field_ID    -0.026679 -0.008903  0.031498       NaN -0.015684  1.000000   \n",
              "spec_obj_ID  0.661641  0.037813  0.239460       NaN -0.001946 -0.083471   \n",
              "redshift     0.492383  0.030380  0.065400       NaN  0.000097 -0.021331   \n",
              "plate        0.661640  0.037813  0.239459       NaN -0.001949 -0.083471   \n",
              "MJD          0.672523  0.037469  0.262687       NaN -0.006745 -0.095064   \n",
              "fiber_ID     0.214787  0.014668  0.067165       NaN  0.121597 -0.012337   \n",
              "isGalaxy    -0.160379 -0.008382  0.019996       NaN -0.020569  0.039654   \n",
              "\n",
              "             spec_obj_ID  redshift     plate       MJD  fiber_ID  isGalaxy  \n",
              "obj_ID          0.239461  0.065400  0.239460  0.262687  0.067178  0.019994  \n",
              "alpha          -0.002553  0.001667 -0.002554  0.019943  0.030464  0.004085  \n",
              "delta           0.112329  0.031638  0.112329  0.107333  0.028250 -0.038297  \n",
              "u               0.029997  0.014309  0.029997  0.031997  0.016305  0.023129  \n",
              "g               0.039443  0.022954  0.039443  0.040274  0.017470  0.014289  \n",
              "r               0.655245  0.433241  0.655243  0.671180  0.223106 -0.037997  \n",
              "i               0.661641  0.492383  0.661640  0.672523  0.214787 -0.160379  \n",
              "z               0.037813  0.030380  0.037813  0.037469  0.014668 -0.008382  \n",
              "run_ID          0.239460  0.065400  0.239459  0.262687  0.067165  0.019996  \n",
              "rerun_ID             NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "cam_col        -0.001946  0.000097 -0.001949 -0.006745  0.121597 -0.020569  \n",
              "field_ID       -0.083471 -0.021331 -0.083471 -0.095064 -0.012337  0.039654  \n",
              "spec_obj_ID     1.000000  0.388642  1.000000  0.970167  0.241279 -0.109753  \n",
              "redshift        0.388642  1.000000  0.388641  0.387109  0.127044 -0.256925  \n",
              "plate           1.000000  0.388641  1.000000  0.970166  0.241258 -0.109753  \n",
              "MJD             0.970167  0.387109  0.970166  1.000000  0.256970 -0.110584  \n",
              "fiber_ID        0.241279  0.127044  0.241258  0.256970  1.000000  0.005923  \n",
              "isGalaxy       -0.109753 -0.256925 -0.109753 -0.110584  0.005923  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ece4555-6087-4b67-9a9e-f3f057c8f139\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obj_ID</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>u</th>\n",
              "      <th>g</th>\n",
              "      <th>r</th>\n",
              "      <th>i</th>\n",
              "      <th>z</th>\n",
              "      <th>run_ID</th>\n",
              "      <th>rerun_ID</th>\n",
              "      <th>cam_col</th>\n",
              "      <th>field_ID</th>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <th>redshift</th>\n",
              "      <th>plate</th>\n",
              "      <th>MJD</th>\n",
              "      <th>fiber_ID</th>\n",
              "      <th>isGalaxy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>obj_ID</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.013735</td>\n",
              "      <td>-0.301237</td>\n",
              "      <td>0.015310</td>\n",
              "      <td>0.015710</td>\n",
              "      <td>0.153891</td>\n",
              "      <td>0.147670</td>\n",
              "      <td>0.013811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.046997</td>\n",
              "      <td>0.031498</td>\n",
              "      <td>0.239461</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>0.239460</td>\n",
              "      <td>0.262687</td>\n",
              "      <td>0.067178</td>\n",
              "      <td>0.019994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <td>-0.013735</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.138691</td>\n",
              "      <td>-0.001532</td>\n",
              "      <td>-0.002423</td>\n",
              "      <td>-0.022083</td>\n",
              "      <td>-0.023580</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>-0.013737</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.019582</td>\n",
              "      <td>-0.165577</td>\n",
              "      <td>-0.002553</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>-0.002554</td>\n",
              "      <td>0.019943</td>\n",
              "      <td>0.030464</td>\n",
              "      <td>0.004085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>-0.301237</td>\n",
              "      <td>0.138691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002074</td>\n",
              "      <td>0.003523</td>\n",
              "      <td>-0.006835</td>\n",
              "      <td>-0.004480</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>-0.301238</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.032565</td>\n",
              "      <td>-0.173416</td>\n",
              "      <td>0.112329</td>\n",
              "      <td>0.031638</td>\n",
              "      <td>0.112329</td>\n",
              "      <td>0.107333</td>\n",
              "      <td>0.028250</td>\n",
              "      <td>-0.038297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u</th>\n",
              "      <td>0.015310</td>\n",
              "      <td>-0.001532</td>\n",
              "      <td>0.002074</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.999311</td>\n",
              "      <td>0.054149</td>\n",
              "      <td>0.045730</td>\n",
              "      <td>0.998093</td>\n",
              "      <td>0.015309</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003548</td>\n",
              "      <td>-0.008374</td>\n",
              "      <td>0.029997</td>\n",
              "      <td>0.014309</td>\n",
              "      <td>0.029997</td>\n",
              "      <td>0.031997</td>\n",
              "      <td>0.016305</td>\n",
              "      <td>0.023129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g</th>\n",
              "      <td>0.015710</td>\n",
              "      <td>-0.002423</td>\n",
              "      <td>0.003523</td>\n",
              "      <td>0.999311</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062387</td>\n",
              "      <td>0.056271</td>\n",
              "      <td>0.999161</td>\n",
              "      <td>0.015710</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003508</td>\n",
              "      <td>-0.008852</td>\n",
              "      <td>0.039443</td>\n",
              "      <td>0.022954</td>\n",
              "      <td>0.039443</td>\n",
              "      <td>0.040274</td>\n",
              "      <td>0.017470</td>\n",
              "      <td>0.014289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r</th>\n",
              "      <td>0.153891</td>\n",
              "      <td>-0.022083</td>\n",
              "      <td>-0.006835</td>\n",
              "      <td>0.054149</td>\n",
              "      <td>0.062387</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.962868</td>\n",
              "      <td>0.053677</td>\n",
              "      <td>0.153889</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.008480</td>\n",
              "      <td>-0.026423</td>\n",
              "      <td>0.655245</td>\n",
              "      <td>0.433241</td>\n",
              "      <td>0.655243</td>\n",
              "      <td>0.671180</td>\n",
              "      <td>0.223106</td>\n",
              "      <td>-0.037997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>0.147670</td>\n",
              "      <td>-0.023580</td>\n",
              "      <td>-0.004480</td>\n",
              "      <td>0.045730</td>\n",
              "      <td>0.056271</td>\n",
              "      <td>0.962868</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.055994</td>\n",
              "      <td>0.147668</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.007615</td>\n",
              "      <td>-0.026679</td>\n",
              "      <td>0.661641</td>\n",
              "      <td>0.492383</td>\n",
              "      <td>0.661640</td>\n",
              "      <td>0.672523</td>\n",
              "      <td>0.214787</td>\n",
              "      <td>-0.160379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>0.013811</td>\n",
              "      <td>-0.002918</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.998093</td>\n",
              "      <td>0.999161</td>\n",
              "      <td>0.053677</td>\n",
              "      <td>0.055994</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.013811</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>-0.008903</td>\n",
              "      <td>0.037813</td>\n",
              "      <td>0.030380</td>\n",
              "      <td>0.037813</td>\n",
              "      <td>0.037469</td>\n",
              "      <td>0.014668</td>\n",
              "      <td>-0.008382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>run_ID</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.013737</td>\n",
              "      <td>-0.301238</td>\n",
              "      <td>0.015309</td>\n",
              "      <td>0.015710</td>\n",
              "      <td>0.153889</td>\n",
              "      <td>0.147668</td>\n",
              "      <td>0.013811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.047098</td>\n",
              "      <td>0.031498</td>\n",
              "      <td>0.239460</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>0.239459</td>\n",
              "      <td>0.262687</td>\n",
              "      <td>0.067165</td>\n",
              "      <td>0.019996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rerun_ID</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cam_col</th>\n",
              "      <td>-0.046997</td>\n",
              "      <td>0.019582</td>\n",
              "      <td>0.032565</td>\n",
              "      <td>0.003548</td>\n",
              "      <td>0.003508</td>\n",
              "      <td>0.008480</td>\n",
              "      <td>0.007615</td>\n",
              "      <td>0.003365</td>\n",
              "      <td>-0.047098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.015684</td>\n",
              "      <td>-0.001946</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.006745</td>\n",
              "      <td>0.121597</td>\n",
              "      <td>-0.020569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>field_ID</th>\n",
              "      <td>0.031498</td>\n",
              "      <td>-0.165577</td>\n",
              "      <td>-0.173416</td>\n",
              "      <td>-0.008374</td>\n",
              "      <td>-0.008852</td>\n",
              "      <td>-0.026423</td>\n",
              "      <td>-0.026679</td>\n",
              "      <td>-0.008903</td>\n",
              "      <td>0.031498</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.015684</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.083471</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>-0.083471</td>\n",
              "      <td>-0.095064</td>\n",
              "      <td>-0.012337</td>\n",
              "      <td>0.039654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spec_obj_ID</th>\n",
              "      <td>0.239461</td>\n",
              "      <td>-0.002553</td>\n",
              "      <td>0.112329</td>\n",
              "      <td>0.029997</td>\n",
              "      <td>0.039443</td>\n",
              "      <td>0.655245</td>\n",
              "      <td>0.661641</td>\n",
              "      <td>0.037813</td>\n",
              "      <td>0.239460</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001946</td>\n",
              "      <td>-0.083471</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388642</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.970167</td>\n",
              "      <td>0.241279</td>\n",
              "      <td>-0.109753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>redshift</th>\n",
              "      <td>0.065400</td>\n",
              "      <td>0.001667</td>\n",
              "      <td>0.031638</td>\n",
              "      <td>0.014309</td>\n",
              "      <td>0.022954</td>\n",
              "      <td>0.433241</td>\n",
              "      <td>0.492383</td>\n",
              "      <td>0.030380</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>-0.021331</td>\n",
              "      <td>0.388642</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388641</td>\n",
              "      <td>0.387109</td>\n",
              "      <td>0.127044</td>\n",
              "      <td>-0.256925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plate</th>\n",
              "      <td>0.239460</td>\n",
              "      <td>-0.002554</td>\n",
              "      <td>0.112329</td>\n",
              "      <td>0.029997</td>\n",
              "      <td>0.039443</td>\n",
              "      <td>0.655243</td>\n",
              "      <td>0.661640</td>\n",
              "      <td>0.037813</td>\n",
              "      <td>0.239459</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>-0.083471</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.388641</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.970166</td>\n",
              "      <td>0.241258</td>\n",
              "      <td>-0.109753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MJD</th>\n",
              "      <td>0.262687</td>\n",
              "      <td>0.019943</td>\n",
              "      <td>0.107333</td>\n",
              "      <td>0.031997</td>\n",
              "      <td>0.040274</td>\n",
              "      <td>0.671180</td>\n",
              "      <td>0.672523</td>\n",
              "      <td>0.037469</td>\n",
              "      <td>0.262687</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.006745</td>\n",
              "      <td>-0.095064</td>\n",
              "      <td>0.970167</td>\n",
              "      <td>0.387109</td>\n",
              "      <td>0.970166</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.256970</td>\n",
              "      <td>-0.110584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fiber_ID</th>\n",
              "      <td>0.067178</td>\n",
              "      <td>0.030464</td>\n",
              "      <td>0.028250</td>\n",
              "      <td>0.016305</td>\n",
              "      <td>0.017470</td>\n",
              "      <td>0.223106</td>\n",
              "      <td>0.214787</td>\n",
              "      <td>0.014668</td>\n",
              "      <td>0.067165</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.121597</td>\n",
              "      <td>-0.012337</td>\n",
              "      <td>0.241279</td>\n",
              "      <td>0.127044</td>\n",
              "      <td>0.241258</td>\n",
              "      <td>0.256970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isGalaxy</th>\n",
              "      <td>0.019994</td>\n",
              "      <td>0.004085</td>\n",
              "      <td>-0.038297</td>\n",
              "      <td>0.023129</td>\n",
              "      <td>0.014289</td>\n",
              "      <td>-0.037997</td>\n",
              "      <td>-0.160379</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>0.019996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.020569</td>\n",
              "      <td>0.039654</td>\n",
              "      <td>-0.109753</td>\n",
              "      <td>-0.256925</td>\n",
              "      <td>-0.109753</td>\n",
              "      <td>-0.110584</td>\n",
              "      <td>0.005923</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ece4555-6087-4b67-9a9e-f3f057c8f139')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ece4555-6087-4b67-9a9e-f3f057c8f139 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ece4555-6087-4b67-9a9e-f3f057c8f139');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4dc6ad3-fa9b-4c3f-b44c-6e560b61665c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4dc6ad3-fa9b-4c3f-b44c-6e560b61665c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4dc6ad3-fa9b-4c3f-b44c-6e560b61665c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataNum\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3386565959554362,\n        \"min\": -0.3012366821459863,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          1.0,\n          -0.013735038510872639,\n          0.15389102608819166\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alpha\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24939868520763067,\n        \"min\": -0.16557686219366577,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -0.013735038510872639,\n          1.0,\n          -0.022082945713254545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27829431256930354,\n        \"min\": -0.3012383493838131,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -0.3012366821459863,\n          0.13869101131405084,\n          -0.006834618991868231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3853145600106789,\n        \"min\": -0.008374362929758166,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.015309911729666618,\n          -0.0015316817054685339,\n          0.05414885777788513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"g\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3842776999637355,\n        \"min\": -0.008852025561684549,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.015710379115483727,\n          -0.002422561432469447,\n          0.062387354251842574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"r\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.359383769257498,\n        \"min\": -0.037997109863897725,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.15389102608819166,\n          -0.022082945713254545,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"i\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37110441720991616,\n        \"min\": -0.16037922596550536,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.14766977762216135,\n          -0.02358001591223914,\n          0.9628678587557876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3851823088313049,\n        \"min\": -0.00890270674866319,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.013811409047460876,\n          -0.0029177680403378536,\n          0.053676979066420966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3386610605700141,\n        \"min\": -0.3012383493838131,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.9999999949157568,\n          -0.013736759174198697,\n          0.1538894751596169\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rerun_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cam_col\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24437798889692827,\n        \"min\": -0.04709786631742395,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2596056464905682,\n        \"min\": -0.17341631998827303,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spec_obj_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3906096711384679,\n        \"min\": -0.10975268040914939,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"redshift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29416632324477376,\n        \"min\": -0.25692538477126525,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3906099924580057,\n        \"min\": -0.1097534105455363,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MJD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3881940164436401,\n        \"min\": -0.11058357094637461,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fiber_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23775637387580892,\n        \"min\": -0.012336892752880586,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isGalaxy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26577585130685194,\n        \"min\": -0.25692538477126525,\n        \"max\": 1.0,\n        \"num_unique_values\": 17,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# this shows me how each column is correlated to the other ones...\n",
        "dataNum = data.select_dtypes(include='number')\n",
        "dataNum.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTcaRmWgaaQy",
        "outputId": "05d05d6a-247e-4fd0-b780-9ad92f8e0843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        feature           VIF\n",
            "0        obj_ID  5.612779e-10\n",
            "1         alpha  1.000006e+00\n",
            "2         delta  1.012774e+00\n",
            "3             u  1.000901e+00\n",
            "4             g  1.001558e+00\n",
            "5             r  1.752373e+00\n",
            "6             i  1.778624e+00\n",
            "7             z  1.001432e+00\n",
            "8        run_ID  1.060856e+00\n",
            "9      rerun_ID  0.000000e+00\n",
            "10      cam_col  1.000002e+00\n",
            "11     field_ID  1.007017e+00\n",
            "12  spec_obj_ID  2.351782e+02\n",
            "13     redshift  1.177915e+00\n",
            "14        plate  2.090999e+09\n",
            "15          MJD  1.701719e+01\n",
            "16     fiber_ID  1.061814e+00\n",
            "17     isGalaxy  1.012193e+00\n"
          ]
        }
      ],
      "source": [
        "# using VIF to determine highly correlated variables...\n",
        "# these columns are very not highly correlated according to the VIF shown below, so no need to drop any of the columns...\n",
        "\n",
        "X = data.select_dtypes(include='number')\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = X.columns\n",
        "\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
        "                          for i in range(len(X.columns))]\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "p-eDV2H0a4nO",
        "outputId": "c141e728-cc94-4df5-d1d9-c5bdb34a9a9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isGalaxy\n",
              "1    0.59445\n",
              "0    0.40555\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isGalaxy</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.59445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.40555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# is the data imbalanced...?\n",
        "data.isGalaxy.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "mtpjCOyaqGpx"
      },
      "outputs": [],
      "source": [
        "# THIS TAKES TOO LONG -- 17+ mins and still running...\n",
        "\n",
        "# ploting pairwise relationships in the dataset...\n",
        "\n",
        "# sns.pairplot(data, hue='isGalaxy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "mZGmHvKZqJJk",
        "outputId": "3e2744d8-840e-4926-aa31-7bb70bc40d6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAALdCAYAAADqLmhVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjzdJREFUeJzs3Xd8FHX+x/H3bMoSUmkJoYbeOycCUgVBAeXOOzn1pKqHgNKRnAUBJYCCiKLYKFbkFO+s4SQUaSItFEXAUGJJQFCBUDYhmd8f/FhZkywBszub3dfTxzwe2ZnZnXeGmOxnP9/5jmGapikAAAAACBA2qwMAAAAAgDdRBAEAAAAIKBRBAAAAAAIKRRAAAACAgEIRBAAAACCgUAQBAAAACCgUQQAAAAACCkUQAAAAgIBCEQQAAAAgoFAEAQAAAAgoFEEAAAAALPH555+rT58+qlSpkgzD0H/+85/LPmf16tVq2bKl7Ha7ateurUWLFl3xcSmCAAAAAFji9OnTatasmebNm1ek/Q8ePKhevXqpS5cuSk1N1ahRo3T33Xdr+fLlV3RcwzRN82oCAwAAAEBxMQxD77//vvr27VvoPg8++KA+/vhj7d6927nu73//u3799VclJycX+Vh0ggAAAAAUG4fDoZMnT7osDoejWF5748aN6tatm8u6Hj16aOPGjVf0OsHFkgbFLji0stURJElnD6+wOoLTuRkTrI4gSSr14EyrI/ic819+aHWE3wT5xq+14FY3Wh3BKax6t8vv5AXns3+wOoIkybFvndURnIzQUlZHkCSdf3e+1RGcgnr2szqCJCk3+R2rIziZZ85aHUGSFNy3v9URnIyylayOIEkKrdLE6giFsvK95MP/ukeTJ092WTdp0iQ99thjf/i1MzMzFRcX57IuLi5OJ0+e1NmzZxUWFlak1/GNdwsAAAAA/EJiYqLGjBnjss5ut1uUpmAUQQAAAICfMSw8tt1u91jRU7FiRR05csRl3ZEjRxQVFVXkLpDENUEAAAAASoi2bdsqJSXFZd1nn32mtm3bXtHrUAQBAAAAsERWVpZSU1OVmpoq6cIU2KmpqUpPT5d0YWhd//6/XY82dOhQHThwQBMmTNA333yj559/XkuXLtXo0aOv6LgMhwMAAAD8jGFYOSCu6LZs2aIuXbo4H1+8lmjAgAFatGiRMjIynAWRJNWoUUMff/yxRo8erWeeeUZVqlTRK6+8oh49elzRcSmCAAAAAFiic+fOcnfb0kWLFhX4nO3bt/+h41IEAQAAAH6mpHSCrMI1QQAAAAACCkUQAAAAgIDCcDgAAADAzxiW3inI9wVMJ2j16tUyDEO//vrrH9oHAAAAQMkWMEVQUbRr104ZGRmKjo6+7L6/L5guPjYMQzabTdHR0WrRooUmTJigjIwMDycHAAAAfnPxfakVS0lAEXSJ0NBQVaxY8Q/94+3du1c//vijNm/erAcffFArVqxQ48aNtWvXrmJMCgAAAOBq+VUR5HA49MADDyg2NlalSpXSddddp82bN7vss379ejVt2lSlSpXStddeq927dzu3FcdwuNjYWFWsWFF169bV3//+d61fv14VKlTQfffdd9WvCQAAAFwJm2FYtpQEflUETZgwQe+9954WL16sbdu2qXbt2urRo4d+/vln5z7jx4/XrFmztHnzZlWoUEF9+vRRTk6OxzKFhYVp6NChWr9+vY4ePeqx4wAAAAAoGr8pgk6fPq0XXnhBTz75pG688UY1bNhQL7/8ssLCwvTqq68695s0aZK6d++uJk2aaPHixTpy5Ijef/99j2arX7++JOnQoUMFbnc4HDp58qTL4u7OuQAAAACunt8UQWlpacrJyVH79u2d60JCQnTNNddoz549znVt27Z1fl22bFnVq1fPZbsnXCxoCrvWKCkpSdHR0S6LmXfKo5kAAADgvwwL/ysJ/KYI8mUXi6yEhIQCtycmJurEiRMui2GL9GJCAAAAIHD4TRFUq1YthYaGav369c51OTk52rx5sxo2bOhc98UXXzi//uWXX7Rv3z41aNDAY7nOnj2rl156SR07dlSFChUK3MdutysqKsplKSnTCwIAAMD3MDGCe8FWBygu4eHhuu+++zR+/HiVLVtW1apV08yZM3XmzBkNGTJEO3bskCRNmTJF5cqVU1xcnB566CGVL19effv2LbYcR48e1blz53Tq1Clt3bpVM2fO1LFjx7Rs2bJiOwYAAACAq+c3RZAkTZ8+XXl5ebrrrrt06tQptW7dWsuXL1eZMmVc9hk5cqT279+v5s2b68MPP1RoaGixZahXr54Mw1BERIRq1qypG264QWPGjFHFihWL7RgAAAAArp5fFUGlSpXS3LlzNXfu3HzbOnfu7JygoHfv3gU+3+FwyDAMlS5d+rLHuvT1CnoMAAAAWIVLK9zzm2uC/qgjR47ov//9r+rUqVOsnSEAAAAAvoUi6P/ddNNNWrFihebNmydJuvHGGxUREVHgMm3aNIvTAgAAAIWzybBsKQn8ajjcH7F161aXx6+88orOnj1b4L5ly5b1RiQAAAAAHkARVIjKlStbHQEAAAC4KlwT5B7D4QAAAAAEFIogAAAAAAGF4XAAAACAn7ExHM4tOkEAAAAAAgqdIAAAAMDPMDGCe3SCAAAAAAQUiiAAAAAAAcUwTdO0OgTyy8nYY3UESVJY9W5WR3A69d8HrY4gSQr+U2+rI/gc89xpqyP8xsyzOoEkyQiLtDrCb3IcVieQJIXEN7A6giQp+8evrI7glLvhfasjSJKCO99hdQS44TO/Y3NzrE7g5Cu/Y0Ni61gdoVBx0fUtO/aRE99YduyiohMEAAAAIKAwMQIAAADgZ5gYwT06QQAAAAACCkUQAAAAgIDCcDgAAADAzxhiOJw7dIIAAAAABBQ6QQAAAICfsTExglt0ggAAAAAEFDpBAAAAgJ9himz36AQBAAAACCgBWwQdOnRIhmEoNTW1yM9ZtGiRYmJiPJYJAAAAgOcxHA4AAADwMzamyHYrYDtBAAAAAAKTXxdBycnJuu666xQTE6Ny5cqpd+/eSktLK3Df1atXyzAMffzxx2ratKlKlSqla6+9Vrt378637/Lly9WgQQNFRESoZ8+eysjIcG7bvHmzunfvrvLlyys6OlqdOnXStm3bPPY9AgAAAL9nGIZlS0ng10XQ6dOnNWbMGG3ZskUpKSmy2Wz685//rLy8vEKfM378eM2aNUubN29WhQoV1KdPH+Xk5Di3nzlzRk899ZRef/11ff7550pPT9e4ceOc20+dOqUBAwZo3bp1+uKLL1SnTh3ddNNNOnXqlEe/VwAAAABF49fXBN16660ujxcsWKAKFSro66+/VkRERIHPmTRpkrp37y5JWrx4sapUqaL3339ft912myQpJydH8+fPV61atSRJI0aM0JQpU5zP79q1q8vrvfTSS4qJidGaNWvUu3fvAo/pcDjkcDhc1tkc2bLbQ6/guwUAAABQFH7dCdq/f79uv/121axZU1FRUUpISJAkpaenF/qctm3bOr8uW7as6tWrpz179jjXlS5d2lkASVJ8fLyOHj3qfHzkyBHdc889qlOnjqKjoxUVFaWsrCy3x0xKSlJ0dLTLMuPZl67mWwYAAABkk2HZUhL4dSeoT58+ql69ul5++WVVqlRJeXl5aty4sbKzs6/6NUNCQlweG4Yh0zSdjwcMGKDjx4/rmWeeUfXq1WW329W2bVu3x0xMTNSYMWNc1tl+PnjVGQEAAAAUzm+LoOPHj2vv3r16+eWX1aFDB0nSunXrLvu8L774QtWqVZMk/fLLL9q3b58aNGhQ5OOuX79ezz//vG666SZJ0nfffadjx465fY7dbpfdbndZl3OaoXAAAAC4Oobh1wO+/jC/LYLKlCmjcuXK6aWXXlJ8fLzS09M1ceLEyz5vypQpKleunOLi4vTQQw+pfPny6tu3b5GPW6dOHb3++utq3bq1Tp48qfHjxyssLOwPfCcAAAAAipPflog2m01LlizR1q1b1bhxY40ePVpPPvnkZZ83ffp0jRw5Uq1atVJmZqY+/PBDhYYWvSvz6quv6pdfflHLli1111136YEHHlBsbOwf+VYAAACAK2JY+F9JYJiXXtASwFavXq0uXbrol19+UUxMjNVxlJOx5/I7eUFY9W5WR3A69d8HrY4gSQr+U8Gz/AUy89xpqyP8xix8CnxvMsIirY7wmxzH5ffxgpD4og8t9qTsH7+yOoJT7ob3rY4gSQrufIfVEeCGz/yOzc25/D5e4iu/Y0Ni61gdoVC1yre07Nhpx3z/Hpl+2wkCAAAAgIL47TVBAAAAQKCyGSVjWJpVKIL+X+fOncXIQAAAAMD/UQQBAAAAfqakTFBgFa4JAgAAABBQKIIAAAAABBSGwwEAAAB+hokR3KMTBAAAACCg0AkCAAAA/AwTI7hHJwgAAABAQKETBAAAAPgZrglyjyLIR52bMcHqCJKkU/990OoITpG3zLA6giTp7I+9rY7gc4zQUlZHgBu+8vskZM6HVke4IPus1Ql+k5trdQJJ0vmvP7c6glNQtcZWR5Ak5abvtjqCk2EEWR1BkmSr1sjqCE5m1i9WR7gg1uoAuFoMhwMAAAAQUOgEAQAAAH6GiRHcoxMEAAAAIKDQCQIAAAD8DBMjuEcnCAAAAEBAoQgCAAAAEFAYDgcAAAD4GSZGcI9OEAAAAICAQicIAAAA8DM2OkFu0QkCAAAAEFACvgjq3LmzRo0aVaR9Fy1apJiYGI/mAQAAAP4owzAsW0qCgC+C/ojHHntMzZs3tzoGAAAAgCtAEQQAAAAgoARUEXT69Gn1799fERERio+P16xZs1y2OxwOjRs3TpUrV1Z4eLjatGmj1atXF/haixYt0uTJk7Vjxw5n62/RokWSpNmzZ6tJkyYKDw9X1apVNWzYMGVlZXn4uwMAAAAusMmwbCkJAqoIGj9+vNasWaP//ve/+t///qfVq1dr27Ztzu0jRozQxo0btWTJEu3cuVN/+9vf1LNnT+3fvz/fa/Xr109jx45Vo0aNlJGRoYyMDPXr10+SZLPZNHfuXH311VdavHixVq5cqQkTJnjt+wQAAABQuICZIjsrK0uvvvqq3njjDV1//fWSpMWLF6tKlSqSpPT0dC1cuFDp6emqVKmSJGncuHFKTk7WwoULNW3aNJfXCwsLU0REhIKDg1WxYkWXbZdOtJCQkKDHH39cQ4cO1fPPP+/B7xAAAAC4oKRMUGCVgCmC0tLSlJ2drTZt2jjXlS1bVvXq1ZMk7dq1S7m5uapbt67L8xwOh8qVK3dFx1qxYoWSkpL0zTff6OTJkzp//rzOnTunM2fOqHTp0vn2dzgccjgcLuuyz+fKHhx0RccFAAAAcHkBUwRdTlZWloKCgrR161YFBbkWHxEREUV+nUOHDql3796677779MQTT6hs2bJat26dhgwZouzs7AKLoKSkJE2ePNll3cQ2dfSva+td3TcDAAAAoFABUwTVqlVLISEh2rRpk6pVqyZJ+uWXX7Rv3z516tRJLVq0UG5uro4ePaoOHToU6TVDQ0OVm5vrsm7r1q3Ky8vTrFmzZLNduORq6dKlbl8nMTFRY8aMcVmX/a+/F/VbAwAAAFwYJWSCAqsETBEUERGhIUOGaPz48SpXrpxiY2P10EMPOQuVunXr6s4771T//v01a9YstWjRQj/99JNSUlLUtGlT9erVK99rJiQk6ODBg0pNTVWVKlUUGRmp2rVrKycnR88++6z69Omj9evXa/78+W6z2e122e12l3WnGAoHAAAAeERAzQ735JNPqkOHDurTp4+6deum6667Tq1atXJuX7hwofr376+xY8eqXr166tu3rzZv3uzsHP3erbfeqp49e6pLly6qUKGC3n77bTVr1kyzZ8/WjBkz1LhxY7355ptKSkry1rcIAAAAMEX2ZRimaZpWh0B+p0b1sTqCJCm4R3erIzhF3jLD6giSpLM/rrU6gu/Jy738PoHG5jvd3HOPj7Q6giQpcs6HVkeQJGUf2mJ1BKfcTR9bHeGC+OpWJ3AKqtbY6giSpNz03VZHcDIM3/h9YqvWyOoIv8k9b3UCSVJozWusjlCoayt1tuzYX/y42rJjF1XADIcDAAAAAgVTZLsXUMPhAAAAAIAiCAAAAEBAYTgcAAAA4GdKygQFVqETBAAAACCg0AkCAAAA/AydIPfoBAEAAAAIKBRBAAAAAAIKw+EAAAAAP8NgOPfoBAEAAAAIKHSCAAAAAD9jM+gFuUMnCAAAAEBAoRPko0o9ONPqCBeE2K1O4HT2x95WR5AkhVXqYHUEn3N651tWR/hNUIjVCSRJ4Y3+ZnUEp7OHV1gdwacYEWWtjuAU3PnvVkeQJJnnTlsdwckIDbM6giQpqHpTqyP8xsyzOsEFPvSewFd+1/syg6uC3KITBAAAACCgUAQBAAAACCgMhwMAAAD8jI3hcG7RCQIAAAAQUOgEAQAAAH7GYIpst+gEAQAAAAgoFEEAAAAAAgrD4QAAAAA/w8QI7tEJAgAAABBQ6AQBAAAAfsagE+QWnSAAAAAAAYUiCAAAAEBAoQjygISEBM2ZM8dlXfPmzfXYY49ZkgcAAACBxWbhUhKUlJwAAAAAUCyYGAEAAADwM4bBxAju0AnyAQ6HQydPnnRZHI5sq2MBAAAAHjdv3jwlJCSoVKlSatOmjb788ku3+8+ZM0f16tVTWFiYqlatqtGjR+vcuXNXdEyKIA+w2WwyTdNlXU5OTqH7JyUlKTo62mWZ8exLno4JAAAAP2WTYdlyJd555x2NGTNGkyZN0rZt29SsWTP16NFDR48eLXD/t956SxMnTtSkSZO0Z88evfrqq3rnnXf0r3/96wrPD4pdhQoVlJGR4Xx88uRJHTx4sND9ExMTdeLECZflwfvv9UZUAAAAwDKzZ8/WPffco0GDBqlhw4aaP3++SpcurQULFhS4/4YNG9S+fXvdcccdSkhI0A033KDbb7/9st2j36MI8oCuXbvq9ddf19q1a7Vr1y4NGDBAQUFBhe5vt9sVFRXlstjtoV5MDAAAABSPgi/1cOTbLzs7W1u3blW3bt2c62w2m7p166aNGzcW+Nrt2rXT1q1bnUXPgQMH9Mknn+imm266oowUQR6QmJioTp06qXfv3urVq5f69u2rWrVqWR0LAAAAAcKw8L+CLvVISkrKl/HYsWPKzc1VXFycy/q4uDhlZmYW+H3dcccdmjJliq677jqFhISoVq1a6ty58xUPh2N2OA+IiorSkiVLXNYNGDDAojQAAACA9yQmJmrMmDEu6+x2e7G89urVqzVt2jQ9//zzatOmjb799luNHDlSU6dO1SOPPFLk16EIAgAAAPyMlcO97HZ7kYqe8uXLKygoSEeOHHFZf+TIEVWsWLHA5zzyyCO66667dPfdd0uSmjRpotOnT+vee+/VQw89JJutaN85w+EAAAAAeF1oaKhatWqllJQU57q8vDylpKSobdu2BT7nzJkz+Qqdi9fe/352ZnfoBAEAAACwxJgxYzRgwAC1bt1a11xzjebMmaPTp09r0KBBkqT+/furcuXKzmuK+vTpo9mzZ6tFixbO4XCPPPKI+vTp43Yist+jCAIAAAD8zJXer8cq/fr1008//aRHH31UmZmZat68uZKTk52TJaSnp7t0fh5++GEZhqGHH35YP/zwgypUqKA+ffroiSeeuKLjGuaV9I3gNTkZe6yOcEFI8VzE5k/CKnWwOoLPOb3zLasj/CYoxOoEkqTwRn+zOoLT2cMrrI4gSQqJb2B1BElSzrEDVkf4TW7hN9L2JvPcaasjOBmhYVZHkCSZ2WetjvAbM8/qBBf4yL+NJCnPN85JaJUmVkco1J+r9bHs2O+nf2jZsYuKThAAAADgZwyjZHSCrMLECAAAAAACCp0gAAAAwM/Q6XCP8wMAAAAgoFAEAQAAAAgoDIcDAAAA/IxRQqbItgqdIAAAAAABhU4QgD8u97zVCX7jK/fTAEoQ83y21RF+4yP3+vKpc+IjfKmvYATxFvZySsrNUq1CJwgAAABAQKEIAgAAABBQ6CUCAAAAfoZOh3ucHwAAAAABhU4QAAAA4GeYIts9OkEAAAAAAgqdIAAAAMDPMEW2e3SCAAAAAAQUiiAAAAAAAYXhcAAAAICfYTCce3SCAAAAAAQUOkEAAACAn7EZ9ILcoRPkAadOndKdd96p8PBwxcfH6+mnn1bnzp01atQoq6MBAAAAAY8iyAPGjBmj9evX64MPPtBnn32mtWvXatu2bVbHAgAAACCGwxW7U6dOafHixXrrrbd0/fXXS5IWLlyoSpUqWZwMAAAAgYJOh3sUQcXswIEDysnJ0TXXXONcFx0drXr16hX6HIfDIYfD4bLO5siW3R7qsZwAAABAoKJI9AFJSUmKjo52WWY8+5LVsQAAAFBCGRb+VxJQBBWzmjVrKiQkRJs3b3auO3HihPbt21focxITE3XixAmX5cH77/VGXAAAACDgMByumEVGRmrAgAEaP368ypYtq9jYWE2aNEk2m01GIVMV2u122e12l3U5pxkKBwAAgKtDp8M9zo8HzJ49W23btlXv3r3VrVs3tW/fXg0aNFCpUqWsjgYAAAAEPIogD4iMjNSbb76p06dPKyMjQ/fee6/27t2r2rVrWx0NAAAACHgMh/OA7du365tvvtE111yjEydOaMqUKZKkW265xeJkAAAACAQlZYICq1AEechTTz2lvXv3KjQ0VK1atdLatWtVvnx5q2MBAAAAAY8iyANatGihrVu3Wh0DAAAAAYprXtzj/AAAAAAIKBRBAAAAAAIKw+EAAAAAP2NjYgS36AQBAAAACCh0ggAAAAA/Qx/IPTpBAAAAAAIKnSAAAADAz3BNkHt0ggAAAAAEFIogAAAAAAGF4XA+6vyXH1odQZIU1OpGqyM4GaGlrI4gSTq98y2rI/wm97zVCSRJ4S36Wx3BKZyfk3x85fdJyC0NrI5wQW6O1QmczOxzVkeQJD3T9TmrIzj1K5dpdQRJ0jvHK1odwckh0+oIkqSx46KtjuAU3Gug1RF8Hp0O9zg/AAAAAAIKnSAAAADAzxhMjOAWnSAAAAAAAYUiCAAAAEBAYTgcAAAA4GfodLjH+QEAAAAQUOgEAQAAAH6GaRHcoxMEAAAAIKDQCQIAAAD8jI1ekFt0ggAAAAAEFIogAAAAAAGF4XAAAACAn6HT4R7nx8uys7OtjgAAAAAENDpBHta5c2c1btxYwcHBeuONN9SkSROtWrXK6lgAAADwY0yL4B5FkBcsXrxY9913n9avX291FAAAACDgUQR5QZ06dTRz5sxCtzscDjkcDpd1eTnnZQ/hnwcAAAAoblwT5AWtWrVyuz0pKUnR0dEuy5PvMmQOAAAAV8cmw7KlJKAI8oLw8HC32xMTE3XixAmXZfxfu3gpHQAAABBYGG/lA+x2u+x2u8u6swyFAwAAwFWi0+Ee5wcAAABAQKEIAgAAABBQGHPlYatXr7Y6AgAAAAJMyZiewDp0ggAAAAAEFDpBAAAAgJ8pKVNVW4VOEAAAAICAQicIAAAA8DM20+oEvo1OEAAAAICAQhEEAAAAIKAwHA4AAADwM3Q63OP8AAAAAAgodIIAAAAAP8ME2e7RCQIAAAAQUCiCAAAAAAQUhsP5qiAf+acx86xO4HuCQqxO8Bsf+fcJDy1ldQSn09nnrI5wgY/820jynd8nvsLg87/fy7U6wCWO/xRudQRJUq4P/Zj4zO1eQnzn719u6gqrI1xQ8xqrExTKh36EfRLnBwAAAEBA4eNBAAAAwM/YmBrBLTpBAAAAAAIKnSAAAADAz9AHco9OEAAAAICAQhEEAAAAIKAwHA4AAADwM3Q63OP8AAAAAAgodIIAAAAAP2Pzmbvs+iY6QQAAAAACCkWQl3Tu3FmjRo2yOgYAAAAQ8BgO5yXLli1TSEiI1TEAAAAQALhPkHsUQV5StmxZqyMAAAAAEMPhvIbhcAAAAPAWm4VLSVBScgIAAABAsWA4nA9wOBxyOBwu6/Jyzssewj8PAAAArhydDvc4Pz4gKSlJ0dHRLsuT/06xOhYAAADglyiCfEBiYqJOnDjhsoz/2/VWxwIAAAD8EuOtfIDdbpfdbndZd5ahcAAAALhKNtPqBL6NThAAAACAgEK7AQAAAPAz3CzVPYogL1m9erXVEQAAAACI4XAAAAAAAgydIAAAAMDP0Olwj/MDAAAAIKDQCQIAAAD8DJ0O9zg/AAAAAAIKnSAAAADAzxjcLNUtOkEAAAAAAgpFEAAAAICAwnA4AAAAwM/Q6XCP8wMAAAAgoNAJAgAAAPwMnQ73OD8AAAAAAgqdIB8V3OpGqyNcEGK3OoHPCW/0N6sj+JzTO9+yOsJvzDyrE0iSwpv9w+oITmcPr7A6gm+xBVmdwMkILWV1BEnS2FUPWB3hN0G+8dakce55qyP4HCMs0uoIv7HxOT7+GN/4TQMAAACg2Ni4T5BblNEAAAAALDNv3jwlJCSoVKlSatOmjb788ku3+//6668aPny44uPjZbfbVbduXX3yySdXdEw6QQAAAICfMawOUETvvPOOxowZo/nz56tNmzaaM2eOevToob179yo2Njbf/tnZ2erevbtiY2P17rvvqnLlyjp8+LBiYmKu6LgUQQAAAAAsMXv2bN1zzz0aNGiQJGn+/Pn6+OOPtWDBAk2cODHf/gsWLNDPP/+sDRs2KCQkRJKUkJBwxcdlOBwAAADgZ2wWLg6HQydPnnRZHA5HvozZ2dnaunWrunXr9ltum03dunXTxo0bC/y+PvjgA7Vt21bDhw9XXFycGjdurGnTpik3N/eKzw8AAAAAFIukpCRFR0e7LElJSfn2O3bsmHJzcxUXF+eyPi4uTpmZmQW+9oEDB/Tuu+8qNzdXn3zyiR555BHNmjVLjz/++BVlZDgcAAAAgGKTmJioMWPGuKyz24vntit5eXmKjY3VSy+9pKCgILVq1Uo//PCDnnzySU2aNKnIr0MRBAAAAPgZK6fIttvtRSp6ypcvr6CgIB05csRl/ZEjR1SxYsUCnxMfH6+QkBAFBf12z7cGDRooMzNT2dnZCg0NLVJGhsMBAAAA8LrQ0FC1atVKKSkpznV5eXlKSUlR27ZtC3xO+/bt9e233yov77ebo+/bt0/x8fFFLoAkiiAAAADA7xgWLldizJgxevnll7V48WLt2bNH9913n06fPu2cLa5///5KTEx07n/ffffp559/1siRI7Vv3z59/PHHmjZtmoYPH35Fx2U4HAAAAABL9OvXTz/99JMeffRRZWZmqnnz5kpOTnZOlpCeni6b7be+TdWqVbV8+XKNHj1aTZs2VeXKlTVy5Eg9+OCDV3RciiAAAAAAlhkxYoRGjBhR4LbVq1fnW9e2bVt98cUXf+iYDIfzkEOHDskwjHxL586drY4GAAAAP2eTadlSEtAJ8pCqVasqIyPD+TgzM1PdunVTx44dLUwFAAAAgCLIQ4KCgpxT+507d059+/ZV27Zt9dhjj1kbDAAAAH7PyimySwKKIC8YPHiwTp06pc8++8zlwq6LHA6HHA6HyzqbI1t2e9Gn+QMAAABQNFwT5GGPP/64li9frg8++ECRkZEF7pOUlKTo6GiXZcazL3k5KQAAAPyFzcKlJKAT5EHvvfeepkyZok8//VS1atUqdL/ExESNGTPGZZ3t54OejgcAAAAEJIogD9m9e7f69++vBx98UI0aNVJmZqakC3fGLVu2rMu+drtddrvdZV3OaYbCAQAAAJ5QUjpWJc6WLVt05swZPf7444qPj3cuf/nLX6yOBgAAAD9nWLiUBBRBHjJw4ECZpplvKeiGTwAAAAC8h+FwAAAAgJ+xmcyR7Q6dIAAAAAABhSIIAAAAQEBhOBwAAADgZ+h0uMf5AQAAABBQ6AQBAAAAfqakTFVtFTpBAAAAAAIKRRAAAACAgMJwOAAAAMDP2MR9gtyhEwQAAAAgoNAJAgAAAPyMjUaQW3SCAAAAAAQUOkE+Kqx6N6sjSJLOHl5hdQSnczMmWB1Bkm+dE19x/ssPrY7wmyDf+LXmSz8nvvL75Hz2D1ZHkCTl/fyj1RGcjNBSVkeQJJ1f9pLVEZyCevazOoIkKTf5HasjOJlnzlodQZIU3Le/1RGcjLKVrI7g8wyuCXKLThAAAACAgEIRBAAAACCg+Ma4EQAAAADFhk6He5wfAAAAAAGFThAAAADgZ+h0uMf5AQAAABBQKIIAAAAABBSGwwEAAAB+hvsEuUcnCAAAAEBAoRMEAAAA+Bk6He5xfq7CokWLFBMT4/LYMAwZhqGgoCCVKVNGbdq00ZQpU3TixAnrggIAAADIx++KoOzsbEuOGxUVpYyMDH3//ffasGGD7r33Xr322mtq3ry5fvzxR0syAQAAIDAZMi1bSoISXwR17txZI0aM0KhRo1S+fHn16NFDhmEoNTXVuc+vv/4qwzC0evVqSdLq1atlGIZSUlLUunVrlS5dWu3atdPevXuvOodhGKpYsaLi4+PVoEEDDRkyRBs2bFBWVpYmTJjwB79LAAAAAMWlxBdBkrR48WKFhoZq/fr1mj9/fpGf99BDD2nWrFnasmWLgoODNXjw4GLNFRsbqzvvvFMffPCBcnNzi/W1AQAAAFwdv5gYoU6dOpo5c6Yk6dChQ0V+3hNPPKFOnTpJkiZOnKhevXrp3LlzKlWqVLFlq1+/vk6dOqXjx48rNja22F4XAAAAKIythAxLs4pfFEGtWrW6quc1bdrU+XV8fLwk6ejRo6pWrVqx5JIk07zwA2gYRqH7OBwOORyOfM9z9xwAAAAAV8cvhsOFh4c7v7bZLnxLF4sPScrJySnweSEhIc6vLxYceXl5xZptz549ioqKUrly5QrdJykpSdHR0S6LmXeqWHMAAAAgcNgM65aSwC+KoEtVqFBBkpSRkeFcd+kkCd509OhRvfXWW+rbt6+zOCtIYmKiTpw44bIYtkgvJgUAAAACh18Mh7tUWFiYrr32Wk2fPl01atTQ0aNH9fDDD3v8uKZpKjMzU6Zp6tdff9XGjRs1bdo0RUdHa/r06W6fa7fbZbfbXdYxFA4AAADwDL8rgiRpwYIFGjJkiFq1aqV69epp5syZuuGGGzx6zJMnTyo+Pl6GYSgqKkr16tXTgAEDNHLkSEVFRXn02AAAAMClSsr9eqxS4ougi/f+uVSDBg20YcMGl3WXXiPUuXNnl8eS1Lx583zrCjNw4EANHDiw0McAAAAAfFeJL4IAAAAAuPK7C/+LGeenAI0aNVJERESBy5tvvml1PAAAAAB/AJ2gAnzyySeFTqsdFxfn5TQAAADAlTEMrglyhyKoANWrV7c6AgAAAAAPYTgcAAAAgIBCJwgAAADwMzaGw7lFJwgAAABAQKETBAAAAPgZw+oAPo5OEAAAAICAQhEEAAAAIKAwHA4AAADwM0yM4B6dIAAAAAABxTBNkzIRAAAA8CNbqvS17Nitv/+PZccuKjpBAAAAAAIK1wQBAAAAfoZrgtyjEwQAAAAgoFAEAQAAAAgoDIcDAAAA/IxhWJ3At9EJAgAAABBQ6AQBAAAAfsZgYgS36AQBAAAACCgUQQAAAAACCsPhAAAAAD/DfYLcoxMEAAAAIKBQBF2FRYsWKSYmxuWxYRgyDENBQUEqU6aM2rRpoylTpujEiRPWBQUAAEBAMgzrlpLAZ4ug7OxsrzynuERFRSkjI0Pff/+9NmzYoHvvvVevvfaamjdvrh9//NGyXAAAAABc+UwR1LlzZ40YMUKjRo1S+fLl1aNHD+3evVs33nijIiIiFBcXp7vuukvHjh1z+5xDhw7JMAylpqY69/v1119lGIZWr14tSVq9erUMw1BKSopat26t0qVLq127dtq7d+9V5zcMQxUrVlR8fLwaNGigIUOGaMOGDcrKytKECROu+nUBAACAK2UYpmVLSeAzRZAkLV68WKGhoVq/fr2mT5+url27qkWLFtqyZYuSk5N15MgR3XbbbYU+Z/78+Vd0vIceekizZs3Sli1bFBwcrMGDBxfnt6PY2Fjdeeed+uCDD5Sbm1usrw0AAADg6vjU7HB16tTRzJkzJUmPP/64WrRooWnTpjm3L1iwQFWrVtW+fftUt27dfM+RpEOHDhX5eE888YQ6deokSZo4caJ69eqlc+fOqVSpUsXw3VxQv359nTp1SsePH1dsbGyB+zgcDjkcDpd1drtddru92HIAAAAAuMCnOkGtWrVyfr1jxw6tWrVKERERzqV+/fqSpLS0tAKfc6WaNm3q/Do+Pl6SdPTo0at+vYKY5oWWoOHmKrGkpCRFR0e7LElJScWaAwAAAIHDZpiWLSWBT3WCwsPDnV9nZWWpT58+mjFjRr79LhYsv3+OJNlsF+q6i8WHJOXk5BR4vJCQEOfXF4uUvLy8q0heuD179igqKkrlypUrdJ/ExESNGTPGZR1dIAAAAMAzfKoIulTLli313nvvKSEhQcHBRY9ZoUIFSVJGRoZatGghSS6TJHjT0aNH9dZbb6lv377O4qwgDH0DAABAcTJsJaMjYxWfGg53qeHDh+vnn3/W7bffrs2bNystLU3Lly/XoEGD3E4yEBYWpmuvvVbTp0/Xnj17tGbNGj388MMez2uapjIzM5WRkaE9e/ZowYIFateunaKjozV9+nSPHx8AAABA0fhsEVSpUiWtX79eubm5uuGGG9SkSRONGjVKMTExbrsq0oUJFM6fP69WrVpp1KhRevzxxz2e9+TJk4qPj1flypXVtm1bvfjiixowYIC2b9/uMnwPAAAAgLUM89KLZwAAAACUeN/UvcmyY9ff94llxy4qn+0EAQAAAIAnUAQVoFGjRi5Tc1+6vPnmm1bHAwAAANwybKZlS0ngs7PDWemTTz4pdFrtuLg4L6cBAAAAUJwoggpQvXp1qyMAAAAAV80oITcttQrD4QAAAAAEFIogAAAAAAGF4XAAAACAn7ExHM4tOkEAAAAAAgqdIAAAAMDPGLQ63OL0AAAAAAgoFEEAAAAAAgrD4XyUY986qyNIkoyIMlZH+E32WasTSJKMiLJWR/A9uQXfXNgSvtL/twVZncAp7+cfrY4gSbLXvc7qCJKk4NDKVkdwOnt4hdURLgixW50A7uTlWp1AknR+1yqrIzgF1WtrdQRJUmiVJlZHKBT3CXLPR94tAAAAAIB30AkCAAAA/IxhoxPkDp0gAAAAAAGFIggAAABAQGE4HAAAAOBnDMPqBL6NThAAAACAgEInCAAAAPAzTIzgHp0gAAAAAAGFThAAAADgZ+gEuUcnCAAAAEBAoQjygoSEBM2ZM8fqGAAAAADEcDgAAADA7zBFtnt0ggAAAAAEFJ8sgvLy8jRz5kzVrl1bdrtd1apV0xNPPCFJevDBB1W3bl2VLl1aNWvW1COPPKKcnBzncx977DE1b95cCxYsULVq1RQREaFhw4YpNzdXM2fOVMWKFRUbG+t8vaL49ddf9c9//lNxcXEqVaqUGjdurI8++si5/b333lOjRo1kt9uVkJCgWbNmFd/JAAAAAK6QYTMtW0oCnxwOl5iYqJdffllPP/20rrvuOmVkZOibb76RJEVGRmrRokWqVKmSdu3apXvuuUeRkZGaMGGC8/lpaWn69NNPlZycrLS0NP31r3/VgQMHVLduXa1Zs0YbNmzQ4MGD1a1bN7Vp08Ztlry8PN144406deqU3njjDdWqVUtff/21goKCJElbt27Vbbfdpscee0z9+vXThg0bNGzYMJUrV04DBw702DkCAAAAcHV8rgg6deqUnnnmGT333HMaMGCAJKlWrVq67rrrJEkPP/ywc9+EhASNGzdOS5YscSmC8vLytGDBAkVGRqphw4bq0qWL9u7dq08++UQ2m0316tXTjBkztGrVqssWQStWrNCXX36pPXv2qG7dupKkmjVrOrfPnj1b119/vR555BFJUt26dfX111/rySefLHIR5HA45HA4XFdmZ8seGlqk5wMAAAAoOp8bDrdnzx45HA5df/31BW5/55131L59e1WsWFERERF6+OGHlZ6e7rJPQkKCIiMjnY/j4uLUsGFD2Ww2l3VHjx69bJ7U1FRVqVLFWQAVlLd9+/Yu69q3b6/9+/crNzf3sq8vSUlJSYqOjnZZZr74RpGeCwAAAPyeYbNuKQl8LmZYWFih2zZu3Kg777xTN910kz766CNt375dDz30kLKzs132CwkJcXlsGEaB6/Ly8v5QnuKSmJioEydOuCwT/vkPjx8XAAAACEQ+NxyuTp06CgsLU0pKiu6++26XbRs2bFD16tX10EMPOdcdPnzYo3maNm2q77//Xvv27SuwG9SgQQOtX7/eZd369etVt25d53VDl2O322W3213WORgKBwAAgKtkGCVjggKr+FwRVKpUKT344IOaMGGCQkND1b59e/3000/66quvVKdOHaWnp2vJkiX605/+pI8//ljvv/++R/N06tRJHTt21K233qrZs2erdu3a+uabb2QYhnr27KmxY8fqT3/6k6ZOnap+/fpp48aNeu655/T88897NBcAAACAq+Nzw+Ek6ZFHHtHYsWP16KOPqkGDBurXr5+OHj2qm2++WaNHj9aIESPUvHlzbdiwwTkhgSe99957+tOf/qTbb79dDRs21IQJE5zX+7Rs2VJLly7VkiVL1LhxYz366KOaMmUKM8MBAADAMlwT5J5hmia9Mh/k2LfO6giSJCOijNURfpN91uoEkiQjoqzVEXxPbs7l9/EWX/ntayvacFhvyPv5R6sjSJLsda+zOoIkKTi0stURnM4eXmF1hAtC7JffB9bJK9pES552ftcqqyM4BdVra3UESVJolSZWRyhUxnVdLDt2/Drf+VkpjI+8WwAAAAAA7wj4IujNN99UREREgUujRo2sjgcAAABcMcNmWrZcqXnz5ikhIUGlSpVSmzZt9OWXXxbpeUuWLJFhGOrbt+8VH9PnJkbwtptvvrnQG6b+flptAAAAAMXnnXfe0ZgxYzR//ny1adNGc+bMUY8ePbR3717FxsYW+rxDhw5p3Lhx6tChw1UdN+CLoMjISJcbqwIAAAAlna9cIns5s2fP1j333KNBgwZJkubPn6+PP/5YCxYs0MSJEwt8Tm5uru68805NnjxZa9eu1a+//nrFxy0hpwcAAABASeBwOHTy5EmXxeFw5NsvOztbW7duVbdu3ZzrbDabunXrpo0bNxb6+lOmTFFsbKyGDBly1RkpggAAAAAUm6SkJEVHR7ssSUlJ+fY7duyYcnNzFRcX57I+Li5OmZmZBb72unXr9Oqrr+rll1/+QxkDfjgcAAAA4HcM6+6Ck5iYqDFjxriss9v/+FT8p06d0l133aWXX35Z5cuX/0OvRREEAAAAoNjY7fYiFT3ly5dXUFCQjhw54rL+yJEjqlixYr7909LSdOjQIfXp08e5Li8vT5IUHBysvXv3qlatWkXKyHA4AAAAwM8YNuuWogoNDVWrVq2UkpLiXJeXl6eUlBS1bZv/hrj169fXrl27lJqa6lxuvvlmdenSRampqapatWqRj00nCAAAAIAlxowZowEDBqh169a65pprNGfOHJ0+fdo5W1z//v1VuXJlJSUlqVSpUmrcuLHL82NiYiQp3/rLoQgCAAAA/ExJmSK7X79++umnn/Too48qMzNTzZs3V3JysnOyhPT0dNlsxf/NGKZpWnfVFAqVfWiL1REkSblbkq2O8JvcXKsTSJKCO//d6gg+x8w+Z3UEn2OElrI6gpN59pTVESRJoQmtrY4gScrJ2GN1BKew6t0uv5MXZG2cZ3UEJ1tc0cbze1rekTSrI/wmJ//UwlYIqt7U6ghOeWdOWB1BkmSvda3VEQr1U/dOlh27wmdrLDt2UZWQGhEAAAAAigfD4QAAAAA/U1KGw1mF0wMAAAAgoNAJAgAAAPwNrQ63OD0AAAAAAgpFEAAAAICAwnA4AAAAwM8wMYJ7nB4AAAAAAYVOEAAAAOBvaHW4xekBAAAAEFBKTBFkmqbuvfdelS1bVoZhKCYmRqNGjSry8xctWqSYmBi3+zz22GNq3rz5H8oJAAAAWM2wWbeUBCUkppScnKxFixbpo48+UkZGhvbt26epU6daluf3BdNjjz0mwzBkGIaCg4NVvnx5dezYUXPmzJHD4bAsJwAAAABXJeaaoLS0NMXHx6tdu3ZWRylUo0aNtGLFCuXl5en48eNavXq1Hn/8cb3++utavXq1IiMjrY4IAAAABLwS0QkaOHCg7r//fqWnp8swDCUkJKhz584uw+EcDofGjRunypUrKzw8XG3atNHq1avdvu706dMVFxenyMhIDRkyROfOnftDOYODg1WxYkVVqlRJTZo00f333681a9Zo9+7dmjFjxh96bQAAAKDIbBYuJUCJiPnMM89oypQpqlKlijIyMrR58+Z8+4wYMUIbN27UkiVLtHPnTv3tb39Tz549tX///gJfc+nSpXrsscc0bdo0bdmyRfHx8Xr++eeLPXv9+vV14403atmyZcX+2gAAAACuXIkYDhcdHa3IyEgFBQWpYsWK+banp6dr4cKFSk9PV6VKlSRJ48aNU3JyshYuXKhp06ble86cOXM0ZMgQDRkyRJL0+OOPa8WKFX+4G1SQ+vXr63//+1+xvy4AAABQEMNmWB3Bp5WIIuhydu3apdzcXNWtW9dlvcPhULly5Qp8zp49ezR06FCXdW3bttWqVauKPZ9pmjKMwn8QHQ5HvskTDEe27PbQYs8CAAAABDq/KIKysrIUFBSkrVu3KigoyGVbRESERal+s2fPHtWoUaPQ7UlJSZo8ebLLuodH3qNHRt3r6WgAAABAwPGLIqhFixbKzc3V0aNH1aFDhyI9p0GDBtq0aZP69+/vXPfFF18Ue7ZvvvlGycnJSkxMLHSfxMREjRkzxmWdkbG72LMAAAAgQJSIK/+t4xdFUN26dXXnnXeqf//+mjVrllq0aKGffvpJKSkpatq0qXr16pXvOSNHjtTAgQPVunVrtW/fXm+++aa++uor1axZ86pznD9/XpmZmfmmyG7evLnGjx9f6PPsdrvsdrvLuuyfGQoHAAAAeIJfFEGStHDhQj3++OMaO3asfvjhB5UvX17XXnutevfuXeD+/fr1U1pamiZMmKBz587p1ltv1X333afly5dfdYavvvpK8fHxCgoKUnR0tBo2bKjExETdd999+YocAAAAwFOYGME9wzRN0+oQyC/70BarI0iScrckWx3hN7m5VieQJAV3/rvVEXyOmV38syqWdEZoKasjOJlnT1kdQZIUmtDa6giSpJyMPVZHcAqr3s3qCJKkrI3zrI7gZIurZXUESVLekTSrI/wmx3H5fbwgqHpTqyM45Z05YXUESZK91rVWRyjUr/26WHbsmHeKf6Kx4uY3nSAAAAAA/49rgtzi9BQiIiKi0GXt2rVWxwMAAABwlegEFSI1NbXQbZUrV/ZeEAAAAADFiiKoELVr17Y6AgAAAHB1mBjBLYbDAQAAAAgodIIAAAAAP8MU2e7RCQIAAAAQUCiCAAAAAAQUhsMBAAAA/oZWh1ucHgAAAAABhU4QAAAA4G+YGMEtOkEAAAAAAgqdIB91/t35VkeQJIUM/JfVEZzOf/251REkSea501ZHcDLPZ1sdQZL0TNfnrI7glGt1gP83dtUDVkdwOr/sJasjSJJCx71idYQLQuxWJ3DK2jjP6giSpIi2w62O4JTRyTduVh6/5lurIziVCg61OoIk6eiU662O4GRcc53VES6oda3VCQrFFNnu0QkCAAAAEFAoggAAAAAEFIbDAQAAAP6G4XBu0QkCAAAAEFDoBAEAAAD+hk6QW3SCAAAAAAQUiiAAAAAAAYXhcAAAAICfMQyGw7lDJwgAAABAQAmYIujQoUMyDEOpqal/aB8AAADA59kM65YSIGCKoKKoWrWqMjIy1Lhx48vu+/uC6eLji0tkZKQaNWqk4cOHa//+/R5ODgAAAKCoKIIuERQUpIoVKyo4+OovlVqxYoUyMjK0Y8cOTZs2TXv27FGzZs2UkpJSjEkBAAAAXK0rLoLeffddNWnSRGFhYSpXrpy6deum06dPa+DAgerbt68mT56sChUqKCoqSkOHDlV2drbzuXl5eUpKSlKNGjUUFhamZs2a6d1333V5/a+++kq9e/dWVFSUIiMj1aFDB6WlpV02V15enqZMmaIqVarIbrerefPmSk5OzrffN998o3bt2qlUqVJq3Lix1qxZ49xWHMPhypUrp4oVK6pmzZq65ZZbtGLFCrVp00ZDhgxRbm7uVb8uAAAAUGQMh3PrioqgjIwM3X777Ro8eLD27Nmj1atX6y9/+YtM05QkpaSkONe//fbbWrZsmSZPnux8flJSkl577TXNnz9fX331lUaPHq1//OMfzkLkhx9+UMeOHWW327Vy5Upt3bpVgwcP1vnz5y+b7ZlnntGsWbP01FNPaefOnerRo4duvvnmfEPRxo8fr7Fjx2r79u1q27at+vTpo+PHj1/JabgiNptNI0eO1OHDh7V161aPHQcAAABA0VzRuK+MjAydP39ef/nLX1S9enVJUpMmTZzbQ0NDtWDBApUuXVqNGjXSlClTNH78eE2dOlU5OTmaNm2aVqxYobZt20qSatasqXXr1unFF19Up06dNG/ePEVHR2vJkiUKCQmRJNWtW7dI2Z566ik9+OCD+vvf/y5JmjFjhlatWqU5c+Zo3rx5zv1GjBihW2+9VZL0wgsvKDk5Wa+++qomTJhwJafiitSvX1/ShU7TNddc47HjAAAAAJIkG1e9uHNFRVCzZs10/fXXq0mTJurRo4duuOEG/fWvf1WZMmWc20uXLu3cv23btsrKytJ3332nrKwsnTlzRt27d3d5zezsbLVo0UKSlJqaqg4dOjgLoKI6efKkfvzxR7Vv395lffv27bVjxw6XdRcLMEkKDg5W69attWfPnis63pW62CkrbL52h8Mhh8Phsi73fK7swUEezQUAAAAEoisqEYOCgvTZZ5/p008/VcOGDfXss8+qXr16Onjw4GWfm5WVJUn6+OOPlZqa6ly+/vpr53VBYWFhV/Et+L6LRVaNGjUK3J6UlKTo6GiX5amVOwrcFwAAALgsrgly64r7ZIZhqH379po8ebK2b9+u0NBQvf/++5KkHTt26OzZs859v/jiC0VERKhq1apq2LCh7Ha70tPTVbt2bZelatWqkqSmTZtq7dq1ysnJuaJMUVFRqlSpktavX++yfv369WrYsKHLui+++ML59fnz57V161Y1aNDgio53JfLy8jR37lzVqFHD2fH6vcTERJ04ccJlGde1mccyAQAAAIHsiobDbdq0SSkpKbrhhhsUGxurTZs26aefflKDBg20c+dOZWdna8iQIXr44Yd16NAhTZo0SSNGjJDNZlNkZKTGjRun0aNHKy8vT9ddd51OnDih9evXKyoqSgMGDNCIESP07LPP6u9//7sSExMVHR2tL774Qtdcc43q1avnNtv48eM1adIk1apVS82bN9fChQuVmpqqN99802W/efPmqU6dOmrQoIGefvpp/fLLLxo8ePCVn7lCHD9+XJmZmTpz5ox2796tOXPm6Msvv9THH3+soKCCh7fZ7XbZ7XaXdWcYCgcAAAB4xBUVQVFRUfr88881Z84cnTx5UtWrV9esWbN044036p133tH111+vOnXqqGPHjnI4HLr99tv12GOPOZ8/depUVahQQUlJSTpw4IBiYmLUsmVL/etf/5J0YXrplStXavz48erUqZOCgoLUvHnzfNf6FOSBBx7QiRMnNHbsWB09elQNGzbUBx98oDp16rjsN336dE2fPl2pqamqXbu2PvjgA5UvX/5KToNb3bp1kySVLl1a1atXV5cuXfTSSy+pdu3axXYMAAAAwB2jhAxLs8oVFUENGjQo8N47l5o8ebLLtNiXMgxDI0eO1MiRIwt9ftOmTbV8+fIriSXpwlTUkyZN0qRJkwrcnpCQ4Jyg4Pbbby9wn4uTE0RERFz2eJe+XkGPAQAAAPimKyqC/NnPP/+sd999V1FRUc5rlAAAAIASiU6QWyVmAvGIiIhCl7Vr1/7h1x8yZIhefPFFvfDCC7Lb7Ro6dGihxxs6dGgxfEcAAAAArFBsnaBFixYV10sVKDU1tdBtlStX/sOvf3GGu4umTJmicePGFbhvVFTUHz4eAAAAAGuUmOFw3p5YIDY2VrGxsV49JgAAAFAsjBIz4MsSnB0AAAAAAaXEdIIAAAAAFBETI7hFJwgAAABAQKETBAAAAPgbOkFu0QkCAAAAEFAoggAAAAAEFIbDAQAAAH7GsNHrcIezAwAAACCg0AnyUUE9+1kdwecEVWtsdQRJkhEaZnWE3wSFWJ1AktSvXKbVEZyO/xRudYQLgnzn1yu/T3yXLa6W1REkSRmdvHtDcnfi13xrdQRJvnVOfIXRvLXVEZzy1q60OsIFHQdanaBwTIzgFp0gAAAAAAGFIggAAABAQPGd8RoAAAAAiodBr8Mdzg4AAACAgEInCAAAAPA3TIzgFp0gAAAAAAGFThAAAADgb7hZqlucHQAAAAABhSIIAAAAQEBhOBwAAADgb5gYwa2A6gR17txZo0aNKrZ9DcPQf/7zH+fjb775Rtdee61KlSql5s2bX3VOAAAAAJ5DJ+gPyMjIUJkyZZyPJ02apPDwcO3du1cRERFatGiRRo0apV9//dW6kAAAAAg83CzVrRJZBGVnZys0NNTqGKpYsaLL47S0NPXq1UvVq1e3KBEAAACAyykRJWLnzp01YsQIjRo1SuXLl1ePHj20e/du3XjjjYqIiFBcXJzuuusuHTt2zPmc06dPq3///oqIiFB8fLxmzZqV73Wff/551alTR6VKlVJcXJz++te/umzPy8vThAkTVLZsWVWsWFGPPfaYy/ZLh8MZhqGtW7dqypQpMgxDnTt31qBBg3TixAkZhiHDMPI9HwAAAID3lYgiSJIWL16s0NBQrV+/XtOnT1fXrl3VokULbdmyRcnJyTpy5Ihuu+025/7jx4/XmjVr9N///lf/+9//tHr1am3bts25fcuWLXrggQc0ZcoU7d27V8nJyerYsWO+Y4aHh2vTpk2aOXOmpkyZos8++6zAfBkZGWrUqJHGjh2rjIwMffDBB5ozZ46ioqKUkZGhjIwMjRs3zjMnBwAAALiUzbBuKQFKzHC4OnXqaObMmZKkxx9/XC1atNC0adOc2xcsWKCqVatq3759qlSpkl599VW98cYbuv766yVdKGiqVKni3D89PV3h4eHq3bu3IiMjVb16dbVo0cLlmE2bNtWkSZOcx3/uueeUkpKi7t2758tXsWJFBQcHKyIiwjlMLjo6WoZh5Bs293sOh0MOh8N1ZXa27D4w5A8AAADwNyWmE9SqVSvn1zt27NCqVasUERHhXOrXry/pwnU5aWlpys7OVps2bZzPKVu2rOrVq+d83L17d1WvXl01a9bUXXfdpTfffFNnzpxxOWbTpk1dHsfHx+vo0aPF/r0lJSUpOjraZZn5ypJiPw4AAAACg2GzWbaUBCUjpaTw8HDn11lZWerTp49SU1Ndlv379+cb0laYyMhIbdu2TW+//bbi4+P16KOPqlmzZi4zuYWEhLg8xzAM5eXlFcv3c6nExESdOHHCZZlw99+L/TgAAAAASlARdKmWLVvqq6++UkJCgmrXru2yhIeHq1atWgoJCdGmTZucz/nll1+0b98+l9cJDg5Wt27dNHPmTO3cuVOHDh3SypUriy1naGiocnNzL7uf3W5XVFSUy8JQOAAAAFw1rglyq0QWQcOHD9fPP/+s22+/XZs3b1ZaWpqWL1+uQYMGKTc3VxERERoyZIjGjx+vlStXavfu3Ro4cKBsl7TnPvroI82dO1epqak6fPiwXnvtNeXl5bkMmfujEhISlJWVpZSUFB07dizfcDsAAAAA3lcii6BKlSpp/fr1ys3N1Q033KAmTZpo1KhRiomJcRY6Tz75pDp06KA+ffqoW7duuu6661yuK4qJidGyZcvUtWtXNWjQQPPnz9fbb7+tRo0aFVvOdu3aaejQoerXr58qVKjgnNgBAAAAgHUM0zRNq0MgP8fugqfi9jZbxVpWR3Ays362OoIkybCHX34nLzFzz1sdQZKUcfNoqyM4Hf/JN/59Gq+bZHUEJ/PUcasjSJLsjfPPrGmFnGMHrI7gZJ47bXUESdKJQSOsjuAUv+ZbqyNIkjI61bY6gs+JePB2qyM45W3aYHUESVL4Q69ZHaFQZ56627Jjlx73imXHLqoS2QkCAAAAgKtVYu4TBAAAAKCISsgEBVahEwQAAAAgoFAEAQAAAAgoDIcDAAAA/I2NXoc7nB0AAAAAAYVOEAAAAOBvDCZGcIdOEAAAAICAQicIAAAA8DdcE+QWZwcAAABAQKEIAgAAABBQGA7no3KT37E6giTJNvBfVkdwyk3fbXUESVJQ9aZWR3Ayz2dbHUGS9M7xilZHcMr1kY92GueetzqCk6/8PlHj7lYn8Dl5R9KsjiBJil/zrdURnDI61bY6giTfOielgkOtjiBJOpq6xeoITrYOXa2O4PsYDucWZwcAAABAQKETBAAAAPgbG1Nku0MnCAAAAEBAoQgCAAAAEFAYDgcAAAD4G4NehzucHQAAAAABhU4QAAAA4G+YItstzg4AAACAgEInCAAAAPAzBlNku0UnCAAAAIBl5s2bp4SEBJUqVUpt2rTRl19+Wei+L7/8sjp06KAyZcqoTJky6tatm9v9C0MR9P8SEhI0Z84cq2MAAAAAAeOdd97RmDFjNGnSJG3btk3NmjVTjx49dPTo0QL3X716tW6//XatWrVKGzduVNWqVXXDDTfohx9+uKLjUgRdpUWLFikmJsbqGAAAAEB+hs265QrMnj1b99xzjwYNGqSGDRtq/vz5Kl26tBYsWFDg/m+++aaGDRum5s2bq379+nrllVeUl5enlJSUKzouRRAAAACAYuNwOHTy5EmXxeFw5NsvOztbW7duVbdu3ZzrbDabunXrpo0bNxbpWGfOnFFOTo7Kli17RRkDpgjq3LmzRowYoREjRig6Olrly5fXI488ItM0C9x/9uzZatKkicLDw1W1alUNGzZMWVlZki604QYNGqQTJ07IMAwZhqHHHntM0oV/9HHjxqly5coKDw9XmzZttHr1ai99lwAAAIAuTJFt0ZKUlKTo6GiXJSkpKV/EY8eOKTc3V3FxcS7r4+LilJmZWaRv88EHH1SlSpVcCqkinZ4r2ruEW7x4sYKDg/Xll1/qmWee0ezZs/XKK68UuK/NZtPcuXP11VdfafHixVq5cqUmTJggSWrXrp3mzJmjqKgoZWRkKCMjQ+PGjZMkjRgxQhs3btSSJUu0c+dO/e1vf1PPnj21f/9+r32fAAAAgFUSExN14sQJlyUxMbHYjzN9+nQtWbJE77//vkqVKnVFzw2oKbKrVq2qp59+WoZhqF69etq1a5eefvpp3XPPPfn2HTVqlPPrhIQEPf744xo6dKief/55hYaGKjo6WoZhqGLFis790tPTtXDhQqWnp6tSpUqSpHHjxik5OVkLFy7UtGnTCszlcDjytQhzz+fKHhxUDN81AAAA4D12u112u/2y+5UvX15BQUE6cuSIy/ojR464vMcuyFNPPaXp06drxYoVatq06RVnDKhO0LXXXivD+G3O9LZt22r//v3Kzc3Nt++KFSt0/fXXq3LlyoqMjNRdd92l48eP68yZM4W+/q5du5Sbm6u6desqIiLCuaxZs0ZpaWmFPq+gluFTK3f8sW8WAAAAgcvC4XBFFRoaqlatWrlManBxkoO2bdsW+ryZM2dq6tSpSk5OVuvWra/q9ARUJ6ioDh06pN69e+u+++7TE088obJly2rdunUaMmSIsrOzVbp06QKfl5WVpaCgIG3dulVBQa5dnIiIiEKPl5iYqDFjxrisy31+5B//RgAAAAAfNmbMGA0YMECtW7fWNddcozlz5uj06dMaNGiQJKl///6qXLmy85qiGTNm6NFHH9Vbb72lhIQE57VDF5sPRRVQRdCmTZtcHn/xxReqU6dOvoJl69atysvL06xZs2T7/2p26dKlLvuEhobm6yC1aNFCubm5Onr0qDp06FDkXAW1DM8wFA4AAABX65LRT76sX79++umnn/Too48qMzNTzZs3V3JysnOyhPT0dOf7cUl64YUXlJ2drb/+9a8urzNp0iTnRGVFEVBFUHp6usaMGaN//vOf2rZtm5599lnNmjUr3361a9dWTk6Onn32WfXp00fr16/X/PnzXfZJSEhQVlaWUlJS1KxZM5UuXVp169bVnXfeqf79+2vWrFlq0aKFfvrpJ6WkpKhp06bq1auXt75VAAAAoES4OINzQX4/y/KhQ4eK5ZgBdU1Q//79dfbsWV1zzTUaPny4Ro4cqXvvvTfffs2aNdPs2bM1Y8YMNW7cWG+++Wa+af3atWunoUOHql+/fqpQoYJmzpwpSVq4cKH69++vsWPHql69eurbt682b96satWqeeV7BAAAAOBeQHWCQkJCNGfOHL3wwgv5tv2+qhw9erRGjx7tsu6uu+5yefzCCy/ke62QkBBNnjxZkydPLp7QAAAAwJW6ggkKAhFnBwAAAEBACahOEAAAABAQDHod7gRMEfT7i6oAAAAABKaAKYIAAACAgME1QW5xdgAAAAAEFIogAAAAAAGF4XAAAACAv2E4nFucHQAAAAABhU4QAAAA4G8Mw+oEPo1OEAAAAICAQhEEAAAAIKAwHM5HmWfOWh1BkmSeO211BCfDCLI6wgVmntUJfI5DptURnHwnie/wld8nPiMv1+oEv8lxWJ1AklQqONTqCD7Hl87JufPZVkeQJJkO38ghSQz0KgImRnCLswMAAAAgoNAJAgAAAPwNnSC3ODsAAAAAAgqdIAAAAMDfGPQ63OHsAAAAAAgoFEEAAAAAAgrD4QAAAAB/w8QIbnF2AAAAAAQUOkEAAACAv2FiBLc4OwAAAAACCkUQAAAAgIBCEXSJgQMHyjAMDR06NN+24cOHyzAMDRw40Llv37598z3XMAyFhIQoLi5O3bt314IFC5SXl+el7wAAAADQhYkRrFpKgJKR0ouqVq2qJUuW6OzZs851586d01tvvaVq1aq5fW7Pnj2VkZGhQ4cO6dNPP1WXLl00cuRI9e7dW+fPn/d0dAAAAABFQBH0Oy1btlTVqlW1bNky57ply5apWrVqatGihdvn2u12VaxYUZUrV1bLli31r3/9S//973/16aefatGiRR5ODgAAAPw/w2bdUgKUjJReNnjwYC1cuND5eMGCBRo0aNBVvVbXrl3VrFkzl6IKAAAAgHUoggrwj3/8Q+vWrdPhw4d1+PBhrV+/Xv/4xz+u+vXq16+vQ4cOFbrd4XDo5MmTLovjfO5VHw8AAAABjmuC3CoZKb2sQoUK6tWrlxYtWqSFCxeqV69eKl++/FW/nmmaMgyj0O1JSUmKjo52WZ5a+9VVHw8AAABA4bhZaiEGDx6sESNGSJLmzZv3h15rz549qlGjRqHbExMTNWbMGJd155+69w8dEwAAAEDBKIIK0bNnT2VnZ8swDPXo0eOqX2flypXatWuXRo8eXeg+drtddrvdZd3p4KCrPiYAAAACXAkZlmYViqBCBAUFac+ePc6vi8LhcCgzM1O5ubk6cuSIkpOTlZSUpN69e6t///6ejAsAAACgiCiC3IiKiip0W15enoKDXU9fcnKy4uPjFRwcrDJlyqhZs2aaO3euBgwYIBvVOAAAALylhExVbRWKoEtc7l4+//nPf5xfHz16VLVr13Z5LvcCAgAAAHwfJeIV+uWXX/TRRx9p9erV6tatm9VxAAAAAFwhOkFXaPDgwdq8ebPGjh2rW265xeo4AAAAQH5ciuEWRdAVev/9962OAAAAAOAPoAgCAAAA/A0TI7jF2QEAAAAQUOgEAQAAAP6Ga4Lc4uwAAAAACCgUQQAAAAACCsPhAAAAAH/DxAhucXYAAAAABBQ6QQAAAIC/YWIEtzg7AAAAAAIKnSAfFdy3v9URLsjNsTqBk61aI6sjXBBitzqBk2F1gP83dly01RF+ExJidQJJkhEWaXUEJ5/5feIjzu9aZXUEp+CGHayOIEk6OuV6qyM4Gc1bWx1BknQ0dYvVEZxMR7bVESRJ0ZNTrI7gdPb7R6yOgBKOIggAAADwM4YRZHUEn8ZwOAAAAAABhU4QAAAA4G+YGMEtzg4AAACAgEInCAAAAPA3dILc4uwAAAAACCgUQQAAAAACCsPhAAAAAH9j0Otwh7MDAAAAIKD4fBFkmqbuvfdelS1bVoZhKCYmRqNGjXJuT0hI0Jw5cyzLBwAAAPgcm826pQTw+ZTJyclatGiRPvroI2VkZGjfvn2aOnWq1bE0cOBA9e3b1+WxYRgyDEMhISGKi4tT9+7dtWDBAuXl5VkXFAAAAIALny+C0tLSFB8fr3bt2qlixYqKjY1VZGSkR4+ZnZ19Vc/r2bOnMjIydOjQIX366afq0qWLRo4cqd69e+v8+fPFnBIAAADA1fDpImjgwIG6//77lZ6eLsMwlJCQoM6dO7sMh5OkU6dO6fbbb1d4eLgqV66sefPmuWz/9ddfdffdd6tChQqKiopS165dtWPHDuf2xx57TM2bN9crr7yiGjVqqFSpUleV1263q2LFiqpcubJatmypf/3rX/rvf/+rTz/9VIsWLbqq1wQAAACumGGzbikBfDrlM888oylTpqhKlSrKyMjQ5s2bC9zvySefVLNmzbR9+3ZNnDhRI0eO1Geffebc/re//U1Hjx7Vp59+qq1bt6ply5a6/vrr9fPPPzv3+fbbb/Xee+9p2bJlSk1NLbbvoWvXrmrWrJmWLVtWbK8JAAAA4Or59BTZ0dHRioyMVFBQkCpWrFjofu3bt9fEiRMlSXXr1tX69ev19NNPq3v37lq3bp2+/PJLHT16VHa7XZL01FNP6T//+Y/effdd3XvvvZIuDIF77bXXVKFChWL/PurXr6+dO3cW++sCAAAABbIFWZ3Ap/l0EVRUbdu2zff44oxxO3bsUFZWlsqVK+eyz9mzZ5WWluZ8XL16dY8UQNKFGe4Mwyh0u8PhkMPhcF2ZnS17aKhH8gAAAACBzC+KIHeysrIUHx+v1atX59sWExPj/Do8PNxjGfbs2aMaNWoUuj0pKUmTJ092WffQ0Dv1yH13eSwTAAAA/FgJuTbHKn5RBH3xxRf5Hjdo0ECS1LJlS2VmZio4OFgJCQlez7Zy5Urt2rVLo0ePLnSfxMREjRkzxnXlvjUeTgYAAAAEJr8ogtavX6+ZM2eqb9+++uyzz/Tvf/9bH3/8sSSpW7duatu2rfr27auZM2eqbt26+vHHH/Xxxx/rz3/+s1q3bl1sORwOhzIzM5Wbm6sjR44oOTlZSUlJ6t27t/r371/o8+x2u/N6JedrMRQOAAAA8Ai/KILGjh2rLVu2aPLkyYqKitLs2bPVo0cPSZJhGPrkk0/00EMPadCgQfrpp59UsWJFdezYUXFxccWaIzk5WfHx8QoODlaZMmXUrFkzzZ07VwMGDJCthNw9FwAAAH6A955uGaZpmlaHQH6OncutjiBJMqI9M1lEiRZiv/w+Aeb8e/Muv5O3hIRYnUCSFHLLUKsjOOX9lG51BEmSvWkPqyNIks6mvGR1BKfghh2sjiBJynlzltURnIzmxTdC448wU7dYHcHJdFzdTdyLW/TkFKsjOJ39frXVESRJIbF1rI5QqHOpH1l27FLNe1t27KLyi04QAAAAgEswMYJbnJ0CpKenKyIiotAlPd03PlUFAAAAcOXoBBWgUqVKSk1NdbsdAAAAQMlEEVSA4OBg1a5d2+oYAAAAwFUxjCCrI/g0hsMBAAAACCh0ggAAAAB/wxTZbnF2AAAAAAQUiiAAAAAAAYXhcAAAAIC/4T5BbnF2AAAAAAQUOkEAAACAv2FiBLc4OwAAAAACCp0gH2WUrWR1BEmSEVrK6ghOZtYvVke4ICjE6gRORpBv/C8c3Gug1RGcclNXWB3hAh/6BM5Xfp/4iqB6ba2O4JR35oTVESRJxjXXWR3BKW/tSqsjSJJsHbpaHcHJsDrA/zv7/SNWR3AKq9LZ6giSpPPZP1gdoXBcE+QWZwcAAABAQKEIAgAAABBQfGMsDQAAAIDiYwuyOoFPoxMEAAAAIKDQCQIAAAD8DRMjuMXZAQAAABBQKIIAAAAABBSGwwEAAAD+xofuV+eLODsAAAAAAorPFEGdO3fWqFGjvHrMRYsWKSYmxqvHBAAAADzNMGyWLSWBz6RctmyZpk6dWqR9MzMzNXLkSNWuXVulSpVSXFyc2rdvrxdeeEFnzpzxcFIAAAAAJZnPXBNUtmzZIu134MABtW/fXjExMZo2bZqaNGkiu92uXbt26aWXXlLlypV18803ezgtAAAA4MO4Jsgtnzk7lw6He/7551WnTh1nl+evf/2rc79hw4YpODhYW7Zs0W233aYGDRqoZs2auuWWW/Txxx+rT58+zn1nz56tJk2aKDw8XFWrVtWwYcOUlZVVaIa0tDTdcsstiouLU0REhP70pz9pxYoVzu3ffPONSpcurbfeesu5bunSpQoLC9PXX3+tzz//XCEhIcrMzHR53VGjRqlDhw5/9BQBAAAAKAY+UwRdtGXLFj3wwAOaMmWK9u7dq+TkZHXs2FGSdPz4cf3vf//T8OHDFR4eXuDzDcNwfm2z2TR37lx99dVXWrx4sVauXKkJEyYUeuysrCzddNNNSklJ0fbt29WzZ0/16dNH6enpkqT69evrqaee0rBhw5Senq7vv/9eQ4cO1YwZM9SwYUN17NhRNWvW1Ouvv+58zZycHL355psaPHhwcZweAAAAAH+QzxVB6enpCg8PV+/evVW9enW1aNFCDzzwgCTp22+/lWmaqlevnstzypcvr4iICEVEROjBBx90rh81apS6dOmihIQEde3aVY8//riWLl1a6LGbNWumf/7zn2rcuLHq1KmjqVOnqlatWvrggw+c+wwbNkzXXXed/vGPf2jgwIH605/+pPvvv9+5fciQIVq4cKHz8Ycffqhz587ptttu+8PnBgAAACgSw2bdUgL4XMru3burevXqqlmzpu666y69+eabl53s4Msvv1RqaqoaNWokh8PhXL9ixQpdf/31qly5siIjI3XXXXfp+PHjhb5eVlaWxo0bpwYNGigmJkYRERHas2ePsxN00YIFC7Rz505t27ZNixYtcuk+DRw4UN9++62++OILSRdmoLvtttsK7VxJksPh0MmTJ10WhyP7sucKAAAAwJXzuSIoMjJS27Zt09tvv634+Hg9+uijatasmX799VfVrl1bhmFo7969Ls+pWbOmateurbCwMOe6Q4cOqXfv3mratKnee+89bd26VfPmzZMkZWcXXGCMGzdO77//vqZNm6a1a9cqNTVVTZo0ybf/jh07dPr0aZ0+fVoZGRku22JjY9WnTx8tXLhQR44c0aeffnrZoXBJSUmKjo52WWbOe6XI5wwAAABwYQuybikBfGZ2uEsFBwerW7du6tatmyZNmqSYmBitXLlSf/nLX9S9e3c999xzuv/++912V7Zu3aq8vDzNmjVLtv+fHcPdUDhJWr9+vQYOHKg///nPki50hg4dOuSyz88//6yBAwfqoYceUkZGhu68805t27bNpQC7++67dfvtt6tKlSqqVauW2rdv7/a4iYmJGjNmjMs646f9bp8DAAAA4Or4XCfoo48+0ty5c5WamqrDhw/rtddeU15envM6oOeff17nz59X69at9c4772jPnj3au3ev3njjDX3zzTcKCrpQfdauXVs5OTl69tlndeDAAb3++uuaP3++22PXqVNHy5YtU2pqqnbs2KE77rhDeXl5LvsMHTpUVatW1cMPP6zZs2crNzdX48aNc9mnR48eioqK0uOPP65BgwZd9nu22+2KiopyWez20Cs5bQAAAACKyOeKoJiYGC1btkxdu3ZVgwYNNH/+fL399ttq1KiRJKlWrVravn27unXrpsTERDVr1kytW7fWs88+q3HjxjlvuNqsWTPNnj1bM2bMUOPGjfXmm28qKSnJ7bFnz56tMmXKqF27durTp4969Oihli1bOre/9tpr+uSTT/T6668rODhY4eHheuONN/Tyyy/r008/de5ns9k0cOBA5ebmqn///h44SwAAAIAbTIzglmGapml1CH80ZMgQ/fTTTy4zy12J7O93FXOiq2OElrI6gpOZ9YvVES4IDbv8Pl5iBPnGiFbz7CmrIzjlpq64/E5eENz+VqsjOJk5vjHRSmiVJlZHkOQ7v18lyXSctjqCJCnvh2+sjuCUt3al1REkSbYOXa2O4HOC67sf3u9NYVU6Wx1BknQ++werIxTKyt91vvL73h3feAflR06cOKFdu3bprbfeuuoCCAAAAPhDbCWjI2MViqBidsstt+jLL7/U0KFD1b17d6vjAAAAAPgdiqBitnr1aqsjAAAAIMAZJeTaHKtwdgAAAAAEFIogAAAAAAGF4XAAAACAv2FiBLc4OwAAAAACCp0gAAAAwN8wMYJbnB0AAAAAAYUiCAAAAEBAYTgcAAAA4G9sQVYn8Gl0ggAAAAAEFhN+6dy5c+akSZPMc+fOWR3FZ7L4Sg5fykIO383iKzl8KYuv5PClLL6Sw5eykMN3s/hKDl/LAmsYpmmaVhdiKH4nT55UdHS0Tpw4oaioKLL4UA5fykIO383iKzl8KYuv5PClLL6Sw5eykMN3s/hKDl/LAmswHA4AAABAQKEIAgAAABBQKIIAAAAABBSKID9lt9s1adIk2e12q6P4TBZfyeFLWcjhu1l8JYcvZfGVHL6UxVdy+FIWcvhuFl/J4WtZYA0mRgAAAAAQUOgEAQAAAAgoFEEAAAAAAgpFEAAAAICAQhEEAAAAIKBQBAEAAAAIKMFWB0DxOnbsmA4dOiTDMJSQkKBy5cpZHQk+ZsyYMQWuNwxDpUqVUu3atXXLLbeobNmyHs2Rk5Ojnj17av78+apTp45Hj1VSdO3aVZ06ddKkSZNc1v/yyy+69dZbtXLlSouSAfmZpqmtW7c6/+bUqFFDLVq0kGEYVkcDgMtiimw/8dVXX+m+++7T+vXrXdZ36tRJL7zwgurVq+f1TKdPn9aaNWuUnp6u7Oxsl20PPPCA1/OcO3cuX46oqCivHX/KlClutz/66KNeydGlSxdt27ZNubm5zp+Lffv2KSgoSPXr19fevXtlGIbWrVunhg0bejRLhQoVtGHDBkuKoDFjxmjq1KkKDw8vtDC8aPbs2V7JZLPZVK5cObVv315vvvmmwsPDJUlHjhxRpUqVlJub65UcF5mmqePHj8swDEs/ULEqx9y5c4u8r7d+p50+fVozZszQsmXLXIqPv/71rxo3bpxKly7tlRyrVq3SkCFDdPjwYV18G3Exy4IFC9SxY0ev5LhoypQpBX7/Z8+e1ZNPPum1369wlZeXp0WLFhX483rXXXdRMMNSFEF+IDMzU40bN1aFChU0dOhQ1a9fX6Zp6uuvv9bLL7+s48ePa/fu3YqNjfVapu3bt+umm27SmTNndPr0aZUtW1bHjh1T6dKlFRsbqwMHDnglx5kzZzRhwgQtXbpUx48fz7fdm28qW7Ro4fI4JydHBw8eVHBwsGrVqqVt27Z5JcecOXO0du1aLVy40FkEnjhxQnfffbeuu+463XPPPbrjjjt09uxZLV++3KNZRo8eLbvdrunTp3v0OAXp0qWL3n//fcXExKhLly6F7mcYhtc6MDabTdu3b9c///lPnT59Wh9++KESEhK8XgRlZmZqwoQJ+uCDD3Tq1ClJFz4w+POf/6ykpCTFxcUFRI4aNWoUaT/DMLzyOy07O1vt2rXT7t27deONNzp/1+/Zs0fJyclq2bKlPv/8c4WEhHg0x7fffqtmzZqpTZs2GjlypMvfnLlz52rLli3auXOnatas6dEclwoKClJGRka+v3PHjx9XbGys1z9ASEtL08KFC5WWlqZnnnlGsbGx+vTTT1WtWjU1atTI48f3heLDNE316dNHn3zyiZo1a+by87pr1y7dfPPN+s9//uPxHJfq1KmThgwZor/97W8KCwvz6rHhg0yUeBMmTDBbtmxpnj17Nt+2M2fOmC1btjQnTpzo1UydOnUy77nnHjM3N9eMiIgw09LSzPT0dLNjx47me++957Ucw4YNMxs0aGC+++67ZlhYmLlgwQJz6tSpZpUqVcw33njDazkKc+LECfPPf/6z+dprr3ntmJUqVTK/+uqrfOt3795tVqpUyTRN09y6datZrlw5j2cZMWKEGRUVZbZq1cq89957zdGjR7ssgcYwDPPIkSPmuXPnzNtvv90sX768uWrVKjMzM9O02WxeyXDixAmzRo0aZoUKFcxRo0aZ8+fPN1944QXz/vvvN8uXL2/WqVPHPHXqVMDk8CVz5swx4+LizG+++Sbftj179phxcXHm3LlzPZ5j+PDhZteuXQvclpeXZ3bt2tUcMWKEx3NcyjAM8+jRo/nWp6SkmOXLl/dqltWrV5thYWFmt27dzNDQUDMtLc00TdNMSkoyb731Vo8fPy8vz+zVq5dpGIbZvHlz8+9//7vZr18/s2nTpqZhGOYtt9zi8QymaZoLFiwwIyMjzZUrV+bblpKSYkZGRpqLFy/2SpaLRo4caVaoUMGMiooy7777bnPjxo1ePT58C0WQH2jRooX5zjvvFLr97bffNlu0aOHFRKYZHR3t/EMdHR1tfv3116ZpmuYXX3xh1qtXz2s5qlataq5atco0TdOMjIw09+/fb5qmab722mvmjTfe6LUc7uzcudOsXr26144XHh7uPCeXWrVqlRkREWGapmmmpaWZkZGRHs/SuXPnQpcuXbp4/Pi+xmazmUeOHHE+njp1qmm3281HH33Ua0XQlClTzNq1axf4hvLIkSNm7dq1zSeeeCJgchQkLy/PzMvL8/pxO3bsaD733HOFbp87d67ZsWNHj+do1KiR+cEHHxS6/YMPPjAbNWrk8RymaZoxMTFmmTJlTJvN5vz64hIVFWXabDZz2LBhXsly0bXXXmvOmjXLNE3T+SGgaZrmpk2bzMqVK3v8+L5SfHTv3t1MSkoqdPsTTzxh3nDDDR7P8Xs5OTnme++9Z958881mSEiI2aBBA/PJJ580MzMzvZ4F1qII8gPR0dHON/cF2b9/vxkdHe29QKZpli9f3ty3b59pmqZZp04dMzk52TTNC59Wli5d2ms5wsPDzcOHD5umaZqVK1c2N23aZJqmaR44cMAMDw/3Wg531q5da8bExHjteHfccYdZo0YNc9myZeZ3331nfvfdd+ayZcvMmjVrmv/4xz9M07xQOLdq1cprmXDBxU7Qpd59910zPDzca0VQmzZtzAULFhS6/dVXXzWvvfbagMlxqcWLF5uNGzc27Xa7abfbzSZNmni1i1u+fHlz9+7dhW7ftWuXV7oekZGR5sGDBwvdfuDAAecHKp62aNEic+HChaZhGOYzzzxjLlq0yLm89dZb5oYNG7yS41Lh4eHmgQMHTNN0LYIOHjxo2u12jx/fV4qPuLg4c/v27YVu37ZtmxkXF+fxHO4cOXLEnDp1qlmqVCkzJCTEvOWWW8yUlBRLM8F7mB3OD5w6dcrtBf6RkZHKysryYqIL179s3rxZderUUadOnfToo4/q2LFjev3119W4cWOv5ahZs6YOHjyoatWqqX79+lq6dKmuueYaffjhh4qJifFaDin/RdamaSojI0Ovv/66brzxRq/lePHFFzV69Gj9/e9/1/nz5yVJwcHBGjBggJ5++mlJUv369fXKK694LRMuOHjwoCpUqOCy7tZbb1X9+vW1ZcsWr2TYt2+f2rVrV+j2du3aady4cQGT46LZs2frkUce0YgRI9S+fXtJ0rp16zR06FAdO3ZMo0eP9niGX3/91e3EEOXKldOJEyc8niMrK8vtBAylS5fWmTNnPJ6jZcuWSklJUZkyZbR48WINHjxYERERHj/u5cTExCgjIyPfNWXbt29X5cqVPX78nTt3aubMmYVuv/HGG69o0o+r9fPPP7u9bi8uLk6//PKLx3MU5ssvv9TChQu1ZMkSxcbGauDAgfrhhx/Uu3dvDRs2TE899ZRl2eAdTIzgB4KCgrRv3758b54uOnLkiOrXr+/VC0O3bNmiU6dOqUuXLjp69Kj69+/vnAVswYIFatasmVdyPP300woKCtIDDzygFStWqE+fPjJNUzk5OZo9e7ZGjhzplRxS/ousbTabKlSooK5duyoxMVGRkZFeyyJdeCNz8WLumjVr+sSbB1gvODhYP/zwQ6FvXjIzM1WlShVnAe3vOS6qUaOGJk+erP79+7usX7x4sR577DEdPHjQ4xmCgoKUmZnp9ne9NybQsNlsWrlyZaHT6B87dkzdu3f3eI6wsDDt379fVapUuey58aZx48Zp06ZN+ve//626detq27ZtOnLkiPr376/+/fvnmwK/uIWGhurw4cOKj48vcPuPP/6oGjVqyOFweDSHr/y8Xuro0aN6/fXXtXDhQu3fv199+vTR3XffrR49ejgni1i3bp169uzp9Q+P4X0UQX7AZrO5nenFNE0ZhuH12XF80eHDh7V161bVrl1bTZs2tToO4HN85Y2Lr+S4qFSpUtq9e7dq167tsn7//v1q0qSJzp075/EMNptNjRs3VnBwwYM4zp8/r6+++sorRZBhGCro7cPF9d74m9O2bVtFRETouuuu0+TJkzVu3LhCP8zx5hTZ2dnZGj58uBYtWqTc3FwFBwcrNzdXd9xxhxYtWqSgoCCPHt9X/t+x2Wy68cYbZbfbC9zucDiUnJzs1fcmoaGhqlWrlgYPHqyBAwcWeI5OnjypW265RatWrfJaLliDIsgPrFmzpkj7derUycNJfM9rr72mfv365fslnJ2drSVLluT7VBcIdDabTdHR0YV+sGKapk6ePOmVN1C+kOOixo0b64477tC//vUvl/WPP/643nnnHe3atcvjGSZPnlyk/TzdaTh8+HCR9qtevbpHc+zdu1eTJk1SWlqatm3bpoYNGxZYIBqG4bVbEFzqu+++065du5SVlaUWLVp47X5ovlJ8DBo0qEj7LVy40KM5LrV27Vp16NDBa8eDb6MIgkccOXJE48aNU0pKio4ePZrvE0NvvXHxtXtHAL5u8eLFRdpvwIABAZHjovfee0/9+vVTt27dnNcErV+/XikpKVq6dKn+/Oc/eyUHCmaz2ZSZmenV++EVxuobt/pi8eErvvnmG9WvX7/AbcuXL1ePHj28nAhWogjyAydPnizSfu4mTyhuN954o9LT0zVixAjFx8fn+zT3lltu8UoOm82mI0eO5Gt579ixQ126dNHPP//slRwASr6tW7fq6aef1p49eyRJDRo00NixY/PdCNnf7dy5s0j7BeqQYz58812lS5fWk08+qeHDhzvXORwOjR07Vq+88opXhrXCdzA7nB+IiYnxuWuC1q1bp7Vr16p58+ZeO+alWrRoIcMwZBiGrr/+epchErm5uTp48KB69uxpSTYAJVOrVq30xhtvWHb8i7/XLsfTQ7+aN29e6DVBF3njb84HH3ygG2+8USEhIfrggw/c7nvzzTd7NMulLv7N/b0dO3YUOpmEP/rLX/5SpP2WLVvm4SS/WbRoke677z59/PHHWrhwoTIyMnTHHXcoLy9Pa9eu9VoO+AaKID/gixfvVa1a1e0fSE/r27evJCk1NVU9evRwuVg2NDRUCQkJuvXWWy1KB/iuMmXKFOmNtqe7qL6S46JPPvlEQUFB+YbLLF++XHl5eV6Z5v7i7zWreWMmvKLo27evcwicu3PjrQ8BL/7MGoahunXruvz85ubmKisrS0OHDvV4jqIUH8HBwapYsaK6d++uPn36eCRHdHS0R173j7jtttvUrl07DRo0SI0aNdLp06c1cOBAzZo1y+207/BPFEF+4EonPJg+fbqGDh3q0fvkzJkzRxMnTtSLL76ohIQEjx2nMBcvDE5ISFC/fv1UqlQpr2cASqI5c+ZYHUGS7+S4aOLEiZo+fXq+9aZpauLEiV4pgq50woP169erdevWhV4gf7WudMKDYcOGacqUKSpfvnyx5sjLyyvwa6vMmTNHpmlq8ODBmjx5sksRcPHDt7Zt23o8R1GKj7y8PO3fv1+vvPKKxo0bpylTphR7jiu95uj7779XpUqVZLPZij3L72VnZys3N1e5ubmKj4/nPUKA4pqgABQVFaXU1FTVrFmzWF/395/cnj59WufPn1fp0qUVEhLisi/X4gD+4e2339bNN9+s8PBwv84RFhamPXv25PtQ59ChQ85PlH2Np37Xl9Qc3rJmzRq1a9cu3989X/TRRx9p2LBhSk9PtzqKV35OlixZovvuu08dOnTQq6++qtTUVA0aNEjVq1fX66+/HjA/o7iATlAA8lTd6yuf3BZ1GI1EMQb8Uf/85z/Vpk0by988eDpHdHS0Dhw4kK8I+vbbby0vAAvjK59xeitHSkqKc0bS33eGFixY4JUMkuvojHPnzik7O9tlu6cnKRo8ePBl9zEMQ6+++qquu+46tW7d2qN5isobPydDhgzRU089pfvuu0+S1L17d+3atUv//Oc/1bx58yJPNAX/QBGEYuOtqWovx1eKMSAQBMob7VtuuUWjRo3S+++/r1q1akm6UACNHTvWqxfdo2CTJ0/WlClT1Lp16wJnJPWmM2fOaMKECVq6dKmOHz+eb7unr09atGiRqlevrhYtWlz2/4uYmBivTkxgtW3btqlevXou68qUKaOlS5fq9ddftygVrEIRBI/Jzc3V+++/75xOtmHDhrrlllsKvdt5cfGVYgyA/5g5c6Z69uyp+vXrq0qVKpIuXMPQoUMHPfXUUxanw/z587Vo0SLdddddVkfR+PHjtWrVKr3wwgu66667NG/ePP3www968cUXC7yurLjdd999evvtt3Xw4EENGjRI//jHPwJqVjp3fl8AXcoXfnbgXRRB8IivvvpKN998szIzM52/dGbMmKEKFSroww8/VOPGjb2WJS0tTQsXLlRaWpqeeeYZxcbG6tNPP1W1atXUqFEjr+UAUHJFR0drw4YN+uyzz7Rjxw6FhYWpadOm6tixo9XRoAsXurdr187qGJKkDz/8UK+99po6d+6sQYMGqUOHDqpdu7aqV6+uN998U3feeadHjz9v3jzNnj1by5Yt04IFC5SYmKhevXppyJAhuuGGGyztkvmC77//Xh988IHS09PzDVWcPXu2RalgBc9PwYGAdPfdd6tRo0b6/vvvtW3bNm3btk3fffedmjZtqnvvvddrOdasWaMmTZpo06ZNWrZsmbKysiRduF/Dlc60BCCwGYahG264QePHj9eIESMKLICaNGmi7777zoJ0+QXSm927775bb731ltUxJF241vTitWlRUVHOa0+vu+46ff75517JYLfbdfvtt+uzzz7T119/rUaNGmnYsGFKSEhw/h30Nd74eU1JSVG9evX0wgsvaNasWVq1apUWLlyoBQsWKDU11ePHh2+hExSAOnTooLCwMI8eIzU1VVu2bFGZMmWc68qUKaMnnnhCf/rTnzx67EtNnDhRjz/+uMaMGaPIyEjn+q5du+q5557zWg4AgeHQoUPKycmxOoYk37le6x//+IdHJgMYM2aM8+u8vDy99NJLWrFihZo2bZpvZjZvfsJfs2ZNHTx4UNWqVVP9+vW1dOlSXXPNNfrwww89emuKwthsNufNbb150/Qr5Y2f18TERI0bN06TJ09WZGSk3nvvPcXGxurOO+/kBuoBiCKohDt58qTzj8vlZjUpXbq0goOD9cknn3g8V926dXXkyJF8w82OHj2q2rVre/z4F+3atavATwdjY2N17Ngxr+UA/FX16tV9YipgX8nhS06dOlXsr7lz5041btxYNptNO3fudLtvRESEqlatqhdeeKHYc0jS9u3bXR43b95ckrR7926X9d7uiA0aNEg7duxQp06dNHHiRPXp00fPPfeccnJyvFaMORwO53C4devWqXfv3nruuefUs2dPr9yH56KcnByFhYUpNTX1ssPgv/76a1WqVMmjefbs2aO3335b0oUbxp49e1YRERGaMmWKbrnlFuescQgMFEElXJkyZZSRkaHY2FjFxMS4/WVvGIbq1Kmj559/Xl26dPForqSkJD3wwAN67LHHdO2110qSvvjiC02ZMkUzZsxwKdg8OV1oTEyMMjIyVKNGDZf127dvV+XKlT12XMBfZGdnFzjlcLVq1STlf8Pp7zms0qJFiyK/md+2bZvHcjRv3lyZmZmKjY1V8+bNnR2GwkRHR2v+/Pnq169fsWdZtWpVsb9mcRg9erTz627duumbb77R1q1bVbt2bTVt2tTjxx82bJiWLFmiqlWravDgwXr77beL/Ua1RRUSEqJq1aoVqQNVtWpVj+cJDw93XgcUHx+vtLQ054e1fDAaeLhZagm3Zs0atW/fXsHBwVqzZo3bfR0Oh/7zn/9o5cqV+uabbzya69JPmi7+4b74o3bpY8MwPNqeHzdunDZt2qR///vfqlu3rrZt26YjR46of//+6t+/P9cFAYXYv3+/Bg8erA0bNris98b/t76Yo6giIyO1Y8eOYr9f0eTJk51fnzt3Ts8//7waNmyotm3bSrrwIdNXX32lYcOGKSkpqViPfanDhw+rWrVqMgxDhw8fdruvw+HQv//9b7388ss6dOiQxzIV5OTJk1q5cqXq16+v+vXre/XYVrPZbKpWrdplC2dvTY396quvatmyZXr99dctn6Wub9++6tWrl+655x6NGzdO//3vfzVw4EAtW7ZMZcqU0YoVKyzNB++iCAowR48e1U033aQtW7Z49DiXK8gudemN5Ypbdna2hg8frkWLFik3N1fBwcE6f/687rzzTi1atEhBQUEeOzZQkl38cGXixIkF3nelWbNmAZWjqDxVBF3q7rvvVnx8vKZOneqyftKkSfruu++8emPQy/nll180ZMgQj7/hvu2229SxY0eNGDFCZ8+eVbNmzXTo0CGZpqklS5bo1ltv9ejx586dW+R9H3jgAQ8mkQYOHFikruHChQs9muOiFi1a6Ntvv1VOTo6qV6+e7+bCnuxc/t6BAweUlZWlpk2b6vTp0xo7dqw2bNigOnXqaPbs2apevbrXssB6FEF+xqp78/i67777Trt27VJWVpZatGihOnXqWB0J8Gnh4eHaunWr5Z+i+0qOovJGERQdHa0tW7bk+z22f/9+tW7dWidOnPDYsX/vl19+0auvvur8m9OgQQMNHjzY65/4V6xYUcuXL1ezZs301ltvadKkSdqxY4cWL16sl156Kd/1Q8Xt90OuC2MYhg4cOODRLL7m0i5mQRiRAasE9jtjP2P1vXkud5HspTw5LvrSGYMK8sUXXzi/5p4AQMEaNmzoE2PkfSVHUb344ouKi4vz6DHCwsK0fv36fEXQ+vXrVapUKY8e+1Kff/65+vTpo+joaLVu3VqS9Oyzz2rq1Kn68MMPvXoPpRMnTjgLr+TkZN16660qXbq0evXqpfHjx3v8+AcPHixw/e+HgQciihz4KoogP3Lx3jyXTk39yy+/aODAgbr33nvzjakvbkW5SFaSx8fx//4Tv23btun8+fPOwnDfvn0KCgpSq1atPJYBKOlmzJihCRMmaNq0aWrSpEm+mdc8OaGJL+aQpM2bN2vVqlUFTtBw8QOVO+64w+M5Ro0apfvuu0/btm3TNddcI0natGmTFixYoEceecTjx79o+PDh6tevn1544QXn0OLc3FwNGzZMw4cP165du7yWpWrVqtq4caPKli2r5ORkLVmyRNKFv4HeLAwvevXVV/X0009r//79kqQ6depo1KhRuvvuu72exRf8+uuvevfdd5WWlqbx48erbNmy2rZtm+Li4jw+SVGZMmWKXIRevKcTAgPD4fxIWFiYtmzZkm9a6t27d+tPf/qTzp4969HjX+4i2Ut5a9zt7NmztXr1ai1evNilMLx4F++xY8d6JQdQ0lyc3OT3bx68PSGBr+SYNm2aHn74YdWrV09xcXEueQzD0MqVK72S46KlS5fqmWeecRmGNnLkSN12221ey3Bx6uOLHzBdtHfvXjVv3tzjf3Mu9fzzz2vkyJGKiIhQ9erVtW3bNtlsNj377LNatmyZV2eSe/TRRzV79mzdf//9zokrNm7cqOeee06jR4/WlClTvJbFF+zcuVPdunVTdHS0Dh06pL1796pmzZp6+OGHlZ6ertdee82jx1+8eHGR9x0wYIAHk8DXUAT5kWbNmunpp59W165dXdavXLlSI0eO9Oqnchd9/fXXSk9Pd05JKV14w9CnTx+vHL9y5cr63//+V2BheMMNN+jHH3/0Sg6gpLnc5CaenNDEF3PExcVpxowZGjhwoFeOVxK0b99e48ePV9++fV3W/+c//9H06dNdhh57w5YtW/Tdd9+pe/fuioiIkCR9/PHHiomJUfv27b2Wo0KFCpo7d65uv/12l/Vvv/227r///hI1vLM4dOvWTS1bttTMmTNdrpnbsGGD7rjjDq/PHAhcxHC4Eu7S++1c7t483nTgwAH9+c9/1q5du1yGyF389NRbn96ePHlSP/30U771P/30k0duJAj4C28VF5fjKzlsNptX30j7qkuv/XzggQc0cuRIffvtty5/c+bNm6fp06d7PVvr1q2d1yZd1KtXL6/nyMnJyZdDklq1aqXz5897PY/VNm/erBdffDHf+sqVKyszM9OCRBecO3fO5QNaybvDa2E9OkElnM1mcxmWUdC9eC4+9ub9NPr06aOgoCC98sorqlGjhjZt2qSff/5ZY8eO1VNPPaUOHTp4JUf//v21du1azZo1y2Xs/Pjx49WhQ4crapMDgeTzzz93u91bF737So6ZM2fqxx9/1Jw5c7xyvN/zlesaLv7NsfraT+nyk+BcypuT4Nx///0KCQnJd8xx48bp7Nmzmjdvntey+ILY2FgtX75cLVq0cOkEffbZZxo8eLC+++47r2U5ffq0HnzwQS1dulTHjx/Pt93X7jsGz6IIKuF85X48v1e+fHmtXLlSTZs2VXR0tL788kvVq1dPK1eu1NixYz0+XelFZ86c0bhx47RgwQLl5ORIkoKDgzVkyBA9+eST+e5XAOCCS294fNGlb8K9fU2Q1Tny8vLUq1cv7du3Tw0bNsw3QYOn74PjK9c1+NK1n126dHF57G4SHG9es3X//ffrtddeU9WqVZ0dsk2bNik9PV39+/d3+dkJhBlK7777bh0/flxLly5V2bJltXPnTgUFBalv377q2LGjVz9YGD58uFatWqWpU6fqrrvu0rx58/TDDz/oxRdf1PTp03XnnXd6LQusRxHkZ3799VeXezY0bNhQQ4YMUXR0tFdzlClTRtu2bVONGjVUq1YtvfLKK+rSpYvS0tLUpEkTnTlzxqt5Tp8+rbS0NElSrVq1KH6Ay/j9vWZycnK0fft2PfLII3riiSd0/fXXB1SOESNGOH+P/X5iBMl7N55EwXxpEpzfF2eFsWJCDSucOHFCf/3rX7VlyxadOnVKlSpVUmZmptq2batPPvnEq3+Pq1Wrptdee02dO3dWVFSUtm3bptq1a+v111/X22+/rU8++cRrWWA9iiA/smXLFvXs2VOlSpVyDv3avHmzzp49q//9739q2bKl17Jc/KPTt29f3XHHHfrll1/08MMP66WXXtLWrVu1e/dur2UBUHzWrFmjMWPGaOvWrQGVIzIyUkuWLLHkGpOCpKWlaeHChUpLS9Mzzzyj2NhYffrpp6pWrVq+iWA8nWPOnDkuH7yNHDlStWrV8loGiUlwSoJ169Zp586dysrKUsuWLdWtWzevZ4iIiNDXX3+tatWqqUqVKlq2bJmuueYaHTx4UE2aNFFWVpbXM8E6+ccZoMQaPXq0+vTpo0OHDmnZsmVatmyZDh48qN69e2vUqFFezfLwww8776MxZcoUHTx4UB06dNAnn3yiuXPnejULgOITFxenvXv3Wh3D6znKli3r9Tf2hVmzZo2aNGmiTZs2admyZc43bjt27PDqjSmXL1+uhg0b6ssvv1TTpk3VtGlTbdq0SY0aNdJnn33mtRwSk+CUBNddd52GDRumCRMmWFIASVLNmjWdN7atX7++li5dKkn68MMPFRMTY0kmWIdOkB8JCwvT9u3bVb9+fZf1X3/9tVq3bu31IWi/9/PPP1/Rxb0ArHPpLGDShUlWMjIyNH36dJ0/f17r1q0LqBwLFy5UcnKyFi5cqNKlS3vlmIVp27at/va3v2nMmDEuF5p/+eWX+stf/qLvv//eKzlatGihHj165JsJbuLEifrf//6nbdu2eSWHxCQ4vi4lJUVPP/20y32tRo0a5fVi6Omnn1ZQUJAeeOABrVixQn369JFpmsrJydHs2bM1cuRIr+aBtSiC/EhcXJxef/113XDDDS7rly9frv79++vIkSMWJQNQ0hQ2C9i1/9fe/cdEXf9xAH/eGb/kN4aIgh0IKVkQRokSV9NFFLYKmqkVazTciAMC+eFPZmGyFEYrI0xGhFmURmxOBhLZsgsM+SVaiYhAm4c26HQEcfz6/sG4b+cJdq37fD7K8/GXvj9s9/yDsXt93u/36xUcjKKiIqOXLXd6jsDAQFy8eBHj4+NQKBRGjRGE/MJvZ2eH1tZWeHl5GRRBnZ2dWLJkCf766y9BclhbW6O1tRW+vr4G621tbfD39xcsB8AmOFI2Ocj2hRde0A+Praurw5EjR5CXl4f4+HjRsnV1daGhoQE+Pj7w9/cXLQeJg3OC7iAvvvgiXnvtNeTk5GDlypUAALVajbS0NKOhbUREUxkeHsbjjz+OgoICWFlZAZgoRlxdXWFtbS1olsmjK5PEynHjQFAxOTk5QaPRwMvLy2C9qakJCxYsECyHq6srmpubjYqg5uZmzJ07V7AcADB79mzk5+dj7969bIIjMbt370ZeXh5UKpV+LTExESEhIdi9e7eoRdA999xj9i6GJF0sgu4gOTk5kMlkiI6O1g9ks7CwQFxcnCiD64jo9mRhYYHW1lbI5XJRvyAMDw8jJiYGBQUFRl+0hSbkXZtbWbduHTIyMnD48GHIZDKMjY1BrVYjNTUV0dHRguWIjY3Fxo0b0dHRYfDi7Z133jFphs9/SaPRQKPRQKlUwsbGBuPj4zyCLTKtVovw8HCj9bCwMGRkZAiSYXBwEDU1NVizZg0AYMuWLRgaGtI/nzVrFrKysgR/uULi4nG4O9DAwIDBmzCxz68T0e0nOTkZVlZWor9AcXV1xY8//ih6ESQlOp0O8fHxKC4uxujoKO666y6Mjo5iw4YNKC4uxqxZswTJMT4+jnfffRe5ubn67mvz589HWloaEhMTBS0+ent7sXbtWpw4cQIymQwXLlyAt7c3YmJi4OzsjNzcXMGykKENGzYgMDAQaWlpBus5OTk4ffo0SktLzZ6hoKAAx44dw9GjRwFMdHtcunQpbGxsAAC//vor0tPTkZycbPYsJB0sgoiIyMjkwEdfX1889NBDRseKhBryKJVibHR0FHl5efjyyy/R3d0NnU5n8Lyvr0/wTN3d3Th79iz6+/sRGBgoaqE42YHN3t7e6JlarUZQUJD+aKU5REdH4+rVqygsLISfn5/+nlRVVRVSUlJw7tw5s302Gft7F9jr168jJycHISEhBneC1Go1Nm3ahO3bt5s9T2hoKNLT0/HMM88AgMFdOgD49NNP8cEHH6C2ttbsWUg6WAQREZGR6QY+CjnkUSrFWGZmJgoLC/Vf2rZt24bOzk6Ul5cjMzMTiYmJguS4HTk4OKC5uVn/hdMc5s2bh6qqKgQEBBh8we3o6IC/vz/nvwjsxvtqU5HJZOjo6DBzGsDd3R21tbVQKBQAJnaY6+vr9f9va2vDww8/bDScme5svBNERERGTpw4IXYEABPDLicHPbe1tRk8E/K41aFDh3DgwAFERERg586dWL9+PRYtWgR/f3/U1dWZvQhKSUlBVlYWbG1tb3nfRqjC8J8S4l3rn3/+edOj3319fWbdgaKbu7Ghidi0Wq3BHaAbZ0qNjY0ZPKeZgUUQERFJllSKsZ6eHjzwwAMAJlpUT74xXrNmDXbs2GH2zy8uLsbWrVtha2uLpqamKX9upjYBCA0NRUlJCbKysgBA3zBiz5490+5q0szg4eGBs2fPYvHixTd9fubMGXh4eAicisTGIoiIiCSvvb0dFy9eFK3rl4eHBzQaDRYuXIhFixbh+PHjWLZsGerr6wXZadBqtRgbGwMwMdukvr4ec+bMMfvn3i727t2LVatW4fTp09DpdEhPT8e5c+fQ19cHtVotdrwZR2o7l08//TQyMzMRERFh1AFucHAQb775JiIiIsyeg6SFd4KIiEiypNL1a/PmzXBwcMDWrVvxxRdf4OWXX4ZCoUB3dzeSk5PN3rhhzpw5qKiowPLlyyGXy3HlyhW4urqa9TP/KzdeQv+vDQ8PIzw8HNnZ2aiurkZLSwv6+/uxbNkyxMfHw93d3SyfS1NzcXFBW1sb7r77bkncL7xy5QoefPBBWFpaQqVS4d577wUAnD9/Hvv27cPIyAiamprg5uZm9iwkHSyCiIhIsqTa9auurk7funuy45Q5bdy4ESUlJXB3d0d3dzc8PDymbIUtxEVzUwjRGIGt1KVFLpejp6cHc+fOhbe3tyR2Li9duoS4uDhUV1fr76nJZDI88cQTyM/PN+vvJ0kTiyAiIpIsqXT9ys7OhpubG2JiYgzWi4qK8Pvvvwsy9LGyshLt7e1ITEzEW2+9ddN21ACQlJRk9iymMPdOECCdVuo0Qco7l319fWhvbwcA+Pj4wMXFReREJBbeCSIiIsmSStev/fv347PPPjNaX7p0KdatWydIERQeHg4AaGhoQFJS0pRFkFAuXbqEkZERo92XCxcuwMLCQt9+eHKGkDmNjIygqKgI33zzjait1GlCVFQUHnvsMbi7u0MmkyEoKEgyO5cuLi545JFHAEzMMCovL8fixYvh5+cnaA4SH4sgIiKSLKl0/erp6bnp3RJXV1doNBrBcgDAxx9/LOjnTeXVV19FTEyMURF06tQpFBYW4rvvvhMsi1RaqdOEjz76CJGRkfqdy9jYWNGLdgBYu3YtlEolVCoVBgcHERQUhM7OToyPj6O0tBRRUVFiRyQBsQgiIiLJkkrXL09PT6jVaqMhkGq1GvPnzxcsh5Q0NTUhJCTEaD04OBgqlUrQLFJppU7/J7WdSwD4/vvvsW3bNgDA119/jfHxcWi1WnzyySfYtWsXi6AZhkUQERFJ0vDwMBITE3H06FFUV1fD3t4e/f39iIyMFLzrV2xsLN544w0MDw9j1apVAICamhqkp6dj06ZNguWQEplMdtOjbteuXcPo6KgIiUiKpLJzCUz8bk7eAaqsrERUVBRmz56NiIgIpKWliZyOhMYiiIiIJMnCwgJnzpyBs7Oz/u2tWNLS0tDb24vXX38dOp0OAGBtbY2MjAxs2bJF1GxiUSqVyM7Oxueff66/7zE6Oors7Gw8+uijIqcjMubp6Yna2lq4uLigsrISpaWlAIA//vjDaH4Q3fnYHY6IiCRLal2/+vv78csvv8DGxga+vr6CNmeQmp9//hlKpRJOTk4IDQ0FAJw8eRLXr1/Ht99+i/vvv1/khESG8vPzkZSUBDs7OyxcuBBNTU2Qy+V4//33UVZWxmOVMwyLICIikqyEhASUlJTA19eXXb8k6PLly9i3bx9aWlpgY2MDf39/qFQqth0myWpoaEB3dzfCwsL0f0+OHTsGZ2dnrFy5UuR0JCQWQUREJFlSmDZPRLevlJQUZGVlwdbWFikpKdP+LF+qzCy8E0RERJLF4ynSdvLkSezfvx8dHR04fPgwFixYgIMHD8LLy4v3gkgSmpqaMDw8rP/3VNhKfeZhEUREREQm++qrr/DKK6/gpZdeQmNjI4aGhgBMdODavXs3KioqRE5IZPgihS9V6O/kYgcgIiKi28+uXbtQUFCAAwcOwMLCQr8eEhKCxsZGEZMREd0aiyAiIiIy2fnz56FUKo3WHR0dodVqhQ9ERGQCFkFERERksnnz5qG9vd1o/YcffoC3t7cIiYiI/jkWQURERGSy2NhYJCUl4dSpU5DJZLh8+TIOHTqE1NRUxMXFiR2PiGhabIxAREREJtu8eTPGxsawevVqDAwMQKlUwsrKCqmpqUhISBA7HhHRtDgniIiIiP41nU6H9vZ29Pf347777oOdnZ3YkYiIbok7QURERPSvWVpawt7eHvb29iyAiOi2wTtBREREZLKRkRHs2LEDjo6OUCgUUCgUcHR0xPbt2/XDKYmIpIo7QURERGSyhIQElJWVYc+ePVixYgUAoLa2Fjt37kRvby8+/PBDkRMSEU2Nd4KIiIjIZI6OjigtLcVTTz1lsF5RUYH169fj2rVrIiUjIro1HocjIiIik1lZWUGhUBite3l5wdLSUvhAREQmYBFEREREJlOpVMjKysLQ0JB+bWhoCG+//TZUKpWIyYiIbo3H4YiIiMhkzz//PGpqamBlZYWAgAAAQEtLC3Q6HVavXm3ws2VlZWJEJCKaEhsjEBERkcmcnJwQFRVlsObp6SlSGiIi03AniIiIiEw2ODiIsbEx2NraAgA6OztRXl4OPz8/PPnkkyKnIyKaHu8EERERkcmeffZZHDx4EACg1WoRHByM3NxcPPfcc2yPTUSSxyKIiIiITNbY2IjQ0FAAwJEjR+Dm5oauri6UlJTgvffeEzkdEdH0WAQRERGRyQYGBmBvbw8AOH78OCIjIyGXyxEcHIyuri6R0xERTY9FEBEREZnMx8cH5eXl+O2331BVVYWwsDAAwNWrV+Hg4CByOiKi6bEIIiIiIpNlZmYiNTUVCoUCy5cvx4oVKwBM7AoFBgaKnI6IaHrsDkdERET/Sk9PDzQaDQICAiCXT7xX/emnn+Dg4IAlS5aInI6IaGosgoiIiIiIaEbhcTgiIiIiIppRWAQREREREdGMwiKIiIiIiIhmFBZBREREREQ0o7AIIiIiIiKiGYVFEBERERERzSgsgoiIiIiIaEZhEURERERERDPK/wDxsEIL/aNC4AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ploting heatmap of the dataset...\n",
        "\n",
        "dataNum = data.select_dtypes(include='number')\n",
        "correlatedData = dataNum.corr()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "sns.heatmap(correlatedData.abs(),annot=False, ax=ax, cmap='rocket_r')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOZZowSJfvd3"
      },
      "source": [
        "Performing train-dev-test split..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "f9IC9t6N_y-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "4c92f1d0-298b-4696-d513-0b5b10f728e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "isGalaxy\n",
              "1    0.593\n",
              "0    0.407\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>isGalaxy</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "# the reason we split the data sample into 20000 is because of the fact that i run out of storage / CPU to run the entire dataset...\n",
        "dataSubset = data.sample(n=20000, random_state=42)\n",
        "\n",
        "dataSubset.isGalaxy.value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "xkduT16Sl05W"
      },
      "outputs": [],
      "source": [
        "# formatting data such that i can train-dev-test split it...\n",
        "\n",
        "# excluding \"y\" column for X matrix...\n",
        "tmp = dataSubset.drop(columns = ['isGalaxy'])\n",
        "dataNum = tmp.select_dtypes(include='number')\n",
        "X = dataNum.values\n",
        "\n",
        "# standardizing...\n",
        "avg, stdev = X.mean(), X.std()\n",
        "X = (X - avg) / stdev\n",
        "\n",
        "# normalizing...\n",
        "min, max = X.min(), X.max()\n",
        "X = (X - min) / (max - min)\n",
        "\n",
        "y = dataSubset['isGalaxy'].values.reshape(-1,1)\n",
        "n = X.shape[1]\n",
        "\n",
        "if False:\n",
        "  print(X.shape)\n",
        "  sys.exit(0)\n",
        "\n",
        "if False:\n",
        "  # print(X)\n",
        "  print(y)\n",
        "  print(y.shape)\n",
        "  sys.exit(0)\n",
        "\n",
        "\n",
        "# excluding \"y\" column for X matrix...\n",
        "tmp = dataSubset.drop(columns = ['isGalaxy'])\n",
        "dataNum = tmp.select_dtypes(include='number')\n",
        "X = dataNum.values\n",
        "\n",
        "# standardizing...\n",
        "avg, stdev = X.mean(), X.std()\n",
        "X = (X - avg) / stdev\n",
        "\n",
        "# normalizing...\n",
        "min, max = X.min(), X.max()\n",
        "X = (X - min) / (max - min)\n",
        "\n",
        "y = dataSubset['isGalaxy'].values.reshape(-1,1)\n",
        "n = X.shape[1]\n",
        "\n",
        "\n",
        "if False:\n",
        "  print(X.shape)\n",
        "  sys.exit(0)\n",
        "\n",
        "if False:\n",
        "  # print(X)\n",
        "  print(y)\n",
        "  print(y.shape)\n",
        "  sys.exit(0)\n",
        "\n",
        "\n",
        "# dividing data into train and test sets...\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.T\n",
        "y_train = y_train.T\n",
        "X_test = X_test.T\n",
        "y_test = y_test.T\n",
        "\n",
        "if False:\n",
        "  print(X_train.shape)\n",
        "  print(y_train.shape)\n",
        "  sys.exit(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfUSEJRKHG5V"
      },
      "source": [
        "PART 1 START..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EATfM-al-7jP"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "  # initialization method...\n",
        "  def __init__(self, inputSize, hiddenSize, outputSize, inLearningRate, inActivation, inGradient):\n",
        "    # weights...\n",
        "    # this is because we do the W * X (input) as our first computation...\n",
        "    # so does this mean that the X format must be of the format (inputSize, numSamples)...?\n",
        "    self.W1 = np.random.randn(hiddenSize, inputSize) * .01\n",
        "\n",
        "    # i think intuitively, it makes sense to have outputsize first since we want\n",
        "    # our computation to result in something that is of the outputsize...\n",
        "    self.W2 = np.random.randn(outputSize, hiddenSize) * .01\n",
        "\n",
        "    # biases...\n",
        "    self.b1 = np.zeros((hiddenSize, 1))\n",
        "    self.b2 = np.zeros((outputSize, 1))\n",
        "\n",
        "    # learning rate...\n",
        "    self.learningRate = inLearningRate\n",
        "\n",
        "\n",
        "    # to store the values that were calculated, since we need them for back propagation...\n",
        "    self.tempCache = {\n",
        "        'Z1': None,\n",
        "        'A1': None,\n",
        "        'Z2': None,\n",
        "        'A2': None,\n",
        "    }\n",
        "\n",
        "    self.gradients = {\n",
        "        'dW1': None,\n",
        "        'db1': None,\n",
        "        'dW2': None,\n",
        "        'db2': None,\n",
        "    }\n",
        "\n",
        "\n",
        "    self.activationMethod = inActivation\n",
        "    self.gradientMethod = inGradient\n",
        "\n",
        "\n",
        "  # activation method...\n",
        "  def activation(self, z):\n",
        "    # implementation of different activation methods as part of my hyperparamter tuning...\n",
        "    if (self.activationMethod == \"tanh\"):\n",
        "      return np.tanh(z)\n",
        "\n",
        "    elif (self.activationMethod == \"sigmoid\"):\n",
        "      return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    # relu...\n",
        "    else:\n",
        "      if False:\n",
        "        res = np.maximum(0, z)\n",
        "\n",
        "      else:\n",
        "        res = (z > 0).astype(float)\n",
        "\n",
        "      # assert 0 <= z <= 1\n",
        "\n",
        "      return res\n",
        "\n",
        "\n",
        "  # forward propagation method...\n",
        "  def forwardPropagation(self, X):\n",
        "    # layer1...\n",
        "    Z1 = np.dot(self.W1, X) + self.b1\n",
        "    A1 = self.activation(Z1)\n",
        "\n",
        "    # layer2...\n",
        "    Z2 = np.dot(self.W2, A1) + self.b2\n",
        "\n",
        "    # i have binary classification problem, so i am using BCE as my loss function\n",
        "    # however, the problem with using tanh or relu for a final activation is that\n",
        "    # having output that is not between 0 to 1 causes log to \"break\".\n",
        "    # therefore, i strictly use sigmoid as the final output, since it will bound\n",
        "    # the final classification to consistently be btwn 0 and 1, and thus, we can\n",
        "    # safely use BCE\n",
        "    if False:\n",
        "      A2 = self.activation(Z2)\n",
        "\n",
        "    else:\n",
        "      A2 = 1 / (1 + np.exp(-Z2))\n",
        "      # assert 0 <= A2 and A2 <= 1\n",
        "\n",
        "\n",
        "    # storing values...\n",
        "    self.tempCache['Z1'] = Z1\n",
        "    self.tempCache['A1'] = A1\n",
        "    self.tempCache['Z2'] = Z2\n",
        "    self.tempCache['A2'] = A2\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "  # backward propagation method...\n",
        "  def backwardPropagation(self, X, y):\n",
        "    # so again, X data must be of the form (inputSize, numSamples)...\n",
        "    m = X.shape[1]\n",
        "\n",
        "    dZ2 = self.tempCache['A2'] - y\n",
        "    dW2 = np.dot(dZ2, self.tempCache['A1'].T) / m\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
        "\n",
        "\n",
        "    # difference in dZ1 depends on which activation method was used in forward propagation method...\n",
        "    if (self.activationMethod == \"tanh\"):\n",
        "      dZ1 = np.dot(self.W2.T, dZ2) * (1 - np.power(self.tempCache['A1'], 2))\n",
        "\n",
        "    elif (self.activationMethod == \"sigmoid\"):\n",
        "      dZ1 = np.dot(self.W2.T, dZ2) * (self.tempCache['A1'] * (1 - self.tempCache['A1']))\n",
        "\n",
        "    else:\n",
        "      reluDeriv = (self.tempCache['Z1'] > 0).astype(int)\n",
        "      # dZ1 = np.dot(self.W2.T, dZ2) * (self.tempCache['A1'] * reluDeriv)\n",
        "      dZ1 = np.dot(self.W2.T, dZ2) * reluDeriv\n",
        "\n",
        "\n",
        "    dW1 = np.dot(dZ1, X.T) / m\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
        "\n",
        "\n",
        "    self.gradients['dW1'] = dW1\n",
        "    self.gradients['db1'] = db1\n",
        "    self.gradients['dW2'] = dW2\n",
        "    self.gradients['db2'] = db2\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "  # updates parameters based on the gradient descent calculations...\n",
        "  def updateParameters(self):\n",
        "    self.W1 -= self.learningRate * self.gradients['dW1']\n",
        "    self.b1 -= self.learningRate * self.gradients['db1']\n",
        "    self.W2 -= self.learningRate * self.gradients['dW2']\n",
        "    self.b2 -= self.learningRate * self.gradients['db2']\n",
        "\n",
        "\n",
        "  # cost method that calculates the loss function...\n",
        "  def computeCost(self, y):\n",
        "    m = y.shape[1]\n",
        "\n",
        "    logprobs = np.multiply(np.log(self.tempCache['A2']), y) + np.multiply(np.log(1 - self.tempCache['A2']), 1 - y)\n",
        "    cost = -np.sum(logprobs) / m\n",
        "\n",
        "    cost = float(np.squeeze(cost))\n",
        "\n",
        "    return cost\n",
        "\n",
        "\n",
        "  # train method...\n",
        "  def train(self, X, y, numIterations=1000, batchSize=32):\n",
        "    if (self.gradientMethod == \"batch\"):\n",
        "      for i in range(numIterations):\n",
        "        self.forwardPropagation(X)\n",
        "\n",
        "        cost = self.computeCost(y)\n",
        "\n",
        "        self.backwardPropagation(X, y)\n",
        "        self.updateParameters()\n",
        "\n",
        "        if True and i % (numIterations // 10) == 0:\n",
        "          print(f\"Cost after iteration {i}: {cost}\")\n",
        "\n",
        "\n",
        "    elif (self.gradientMethod == \"miniBatch\"):\n",
        "      m = X.shape[1]\n",
        "\n",
        "      for i in range(numIterations):\n",
        "        # Shuffle indices\n",
        "        indices = np.arange(m)\n",
        "        np.random.shuffle(indices)\n",
        "        X_shuffled = X[:, indices]\n",
        "        y_shuffled = y[:, indices]\n",
        "\n",
        "        for j in range(0, m, batchSize):\n",
        "          X_batch = X_shuffled[:, j:j+batchSize]\n",
        "          y_batch = y_shuffled[:, j:j+batchSize]\n",
        "\n",
        "          self.forwardPropagation(X_batch)\n",
        "          self.backwardPropagation(X_batch, y_batch)\n",
        "          self.updateParameters()\n",
        "\n",
        "        cost = self.computeCost(y_batch)\n",
        "\n",
        "\n",
        "        # Optional: track cost after each epoch\n",
        "        if i % (numIterations // 10) == 0:\n",
        "          print(f\"Cost after iteration {i}: {cost}\")\n",
        "\n",
        "\n",
        "    # stochastic method...\n",
        "    else:\n",
        "      y = y.reshape(1, -1)\n",
        "      m = X.shape[1]\n",
        "\n",
        "      for i in range(numIterations):\n",
        "        # Shuffle the dataset\n",
        "        indices = np.arange(m)\n",
        "        np.random.shuffle(indices)\n",
        "        X_shuffled = X[:, indices]\n",
        "        y_shuffled = y[:, indices]\n",
        "\n",
        "        for j in range(m):\n",
        "          X_sample = X_shuffled[:, j].reshape(-1, 1)\n",
        "          y_sample = y_shuffled[:, j].reshape(-1, 1)\n",
        "\n",
        "          self.forwardPropagation(X_sample)\n",
        "          self.backwardPropagation(X_sample, y_sample)\n",
        "          self.updateParameters()\n",
        "\n",
        "        # Optional: compute cost on last sample for feedback\n",
        "        if i % (numIterations // 10) == 0:\n",
        "          cost = self.computeCost(y_sample)\n",
        "          print(f\"Cost after iteration {i}: {cost}\")\n",
        "\n",
        "    print(f\"Final cost: {cost}\")\n",
        "    return\n",
        "\n",
        "\n",
        "  # predict method for test set calculations...\n",
        "  def predict(self, X):\n",
        "    self.forwardPropagation(X)\n",
        "    res = self.tempCache['A2']\n",
        "\n",
        "    return (res > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acRk3zy2AIc7"
      },
      "source": [
        "hyperparameter tuning...\n",
        "(independently varying factors such as hidden layer size, learning rate, activation method, gradient method...)\n",
        "\n",
        "i will show the accuracy, precision, recall, and f1 score upon varying the following parameters at the same time:\n",
        "- hidden layer size\n",
        "- activation method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-U4YscpU8jW",
        "outputId": "d6f6fee4-15f0-4760-de41-70b40f22eace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden Layer Size: 16\n",
            "Activation Method: tanh\n",
            "Cost after iteration 0: 0.6909166777426963\n",
            "Cost after iteration 100: 0.686523411195702\n",
            "Cost after iteration 200: 0.6836641869938426\n",
            "Cost after iteration 300: 0.6813349741799366\n",
            "Cost after iteration 400: 0.6796209044815081\n",
            "Cost after iteration 500: 0.6783947223314972\n",
            "Cost after iteration 600: 0.6775956363542704\n",
            "Cost after iteration 700: 0.6771111872589861\n",
            "Cost after iteration 800: 0.676760244214793\n",
            "Cost after iteration 900: 0.6765460077698756\n",
            "Final cost: 0.6764024694640605\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Activation Method: sigmoid\n",
            "Cost after iteration 0: 0.6932527354327555\n",
            "Cost after iteration 100: 0.6885670444651468\n",
            "Cost after iteration 200: 0.6850457040237935\n",
            "Cost after iteration 300: 0.6824708667302919\n",
            "Cost after iteration 400: 0.6805592342741457\n",
            "Cost after iteration 500: 0.6791349680897528\n",
            "Cost after iteration 600: 0.6780785609172983\n",
            "Cost after iteration 700: 0.677287300655723\n",
            "Cost after iteration 800: 0.6766939954143104\n",
            "Cost after iteration 900: 0.6762461775903484\n",
            "Final cost: 0.6759034207380757\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Activation Method: relu\n",
            "Cost after iteration 0: 0.6873120851571541\n",
            "Cost after iteration 100: 0.6827678702090195\n",
            "Cost after iteration 200: 0.6800792411371372\n",
            "Cost after iteration 300: 0.6784148561428491\n",
            "Cost after iteration 400: 0.6772030906747502\n",
            "Cost after iteration 500: 0.676372498514139\n",
            "Cost after iteration 600: 0.6756983550708144\n",
            "Cost after iteration 700: 0.6752627990475073\n",
            "Cost after iteration 800: 0.674787289092204\n",
            "Cost after iteration 900: 0.6743318895270589\n",
            "Final cost: 0.6737004140433274\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Activation Method: tanh\n",
            "Cost after iteration 0: 0.6864325178995587\n",
            "Cost after iteration 100: 0.676886431183165\n",
            "Cost after iteration 200: 0.6747419695721171\n",
            "Cost after iteration 300: 0.6740116655839988\n",
            "Cost after iteration 400: 0.6736122602813488\n",
            "Cost after iteration 500: 0.6731420960806856\n",
            "Cost after iteration 600: 0.6725752607185813\n",
            "Cost after iteration 700: 0.6721276941283868\n",
            "Cost after iteration 800: 0.6718119133101663\n",
            "Cost after iteration 900: 0.6716315040443708\n",
            "Final cost: 0.6713337855035296\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Activation Method: sigmoid\n",
            "Cost after iteration 0: 0.6950983638733076\n",
            "Cost after iteration 100: 0.6804686737767442\n",
            "Cost after iteration 200: 0.6759935282460862\n",
            "Cost after iteration 300: 0.6749790350732005\n",
            "Cost after iteration 400: 0.674410184109998\n",
            "Cost after iteration 500: 0.6738682113580614\n",
            "Cost after iteration 600: 0.6735771770649647\n",
            "Cost after iteration 700: 0.6732361305649776\n",
            "Cost after iteration 800: 0.672922439862376\n",
            "Cost after iteration 900: 0.6725695796808674\n",
            "Final cost: 0.6722816288776947\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Activation Method: relu\n",
            "Cost after iteration 0: 0.6953180299888166\n",
            "Cost after iteration 100: 0.6817617795624155\n",
            "Cost after iteration 200: 0.6773994239383798\n",
            "Cost after iteration 300: 0.6755590298166023\n",
            "Cost after iteration 400: 0.6746485308478316\n",
            "Cost after iteration 500: 0.6739809368287593\n",
            "Cost after iteration 600: 0.6736910180988237\n",
            "Cost after iteration 700: 0.6732483757181607\n",
            "Cost after iteration 800: 0.6729870275480924\n",
            "Cost after iteration 900: 0.6727862923409523\n",
            "Final cost: 0.6725624473121513\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Activation Method: tanh\n",
            "Cost after iteration 0: 0.6855516768541063\n",
            "Cost after iteration 100: 0.674558358373688\n",
            "Cost after iteration 200: 0.6733994067807548\n",
            "Cost after iteration 300: 0.6726461287844708\n",
            "Cost after iteration 400: 0.672158192035761\n",
            "Cost after iteration 500: 0.6715682186296861\n",
            "Cost after iteration 600: 0.6711011836409694\n",
            "Cost after iteration 700: 0.670719504134852\n",
            "Cost after iteration 800: 0.6700634566571868\n",
            "Cost after iteration 900: 0.6698714424200688\n",
            "Final cost: 0.6695965665838187\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Activation Method: sigmoid\n",
            "Cost after iteration 0: 0.6922249764286502\n",
            "Cost after iteration 100: 0.6758219726776553\n",
            "Cost after iteration 200: 0.6746326208248392\n",
            "Cost after iteration 300: 0.6740567531890213\n",
            "Cost after iteration 400: 0.6735338054972531\n",
            "Cost after iteration 500: 0.6728821303492775\n",
            "Cost after iteration 600: 0.6721355015735976\n",
            "Cost after iteration 700: 0.6716960696542273\n",
            "Cost after iteration 800: 0.6713875633909397\n",
            "Cost after iteration 900: 0.6711169094134566\n",
            "Final cost: 0.6709220440303391\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Activation Method: relu\n",
            "Cost after iteration 0: 0.698283937483354\n",
            "Cost after iteration 100: 0.6774112778234405\n",
            "Cost after iteration 200: 0.6750692746623499\n",
            "Cost after iteration 300: 0.673851474459038\n",
            "Cost after iteration 400: 0.6728737920726164\n",
            "Cost after iteration 500: 0.6722212552723728\n",
            "Cost after iteration 600: 0.6717676780099159\n",
            "Cost after iteration 700: 0.6712709528975074\n",
            "Cost after iteration 800: 0.6709998195166238\n",
            "Cost after iteration 900: 0.6705899981740503\n",
            "Final cost: 0.6703452554902305\n"
          ]
        }
      ],
      "source": [
        "# tuning...\n",
        "allHiddenSizes = [16, 64, 128]\n",
        "# allLearningRates = [.0001, .001, .01]\n",
        "allActivationMethods = [\"tanh\", \"sigmoid\", \"relu\"]\n",
        "# allGradientMethods = [\"batch\", \"miniBatch\", \"stochastic\"]\n",
        "\n",
        "\n",
        "# constant...\n",
        "inputSize = X.shape[1]\n",
        "outputSize = 1\n",
        "learningRate = .001\n",
        "gradientMethod = \"batch\"\n",
        "\n",
        "allAccuracy = []\n",
        "allPrecision = []\n",
        "allRecall = []\n",
        "allF1 = []\n",
        "allyTrue = []\n",
        "allyPred = []\n",
        "\n",
        "\n",
        "for hidden in allHiddenSizes:\n",
        "  for activation in allActivationMethods:\n",
        "    # for rate in allLearningRates:\n",
        "    print(\"\\nHidden Layer Size:\", hidden)\n",
        "    print(\"Activation Method:\", activation)\n",
        "    # print(\"Learning Rate:\", rate)\n",
        "\n",
        "    activation = \"relu\"\n",
        "\n",
        "    myNN = NeuralNetwork(inputSize, hidden, outputSize, learningRate, activation, gradientMethod)\n",
        "    myNN.train(X_train, y_train, numIterations=1000)\n",
        "\n",
        "# myNN = NeuralNetwork(inputSize, hiddenSize, outputSize, learningRate, activation, gradient)\n",
        "# myNN.train(X_train, y_train, numIterations=1000)\n",
        "\n",
        "\n",
        "    y_pred = myNN.predict(X_test)\n",
        "\n",
        "    # for compatibility...\n",
        "    y_true = y_test.flatten()\n",
        "    y_pred_flat = y_pred.flatten()\n",
        "\n",
        "    # print(\"Accuracy:\", accuracy_score(y_true, y_pred_flat))\n",
        "    # print(\"Precision:\", precision_score(y_true, y_pred_flat))\n",
        "    # print(\"Recall:\", recall_score(y_true, y_pred_flat))\n",
        "    # print(\"F1 Score:\", f1_score(y_true, y_pred_flat))\n",
        "\n",
        "\n",
        "    allAccuracy.append(accuracy_score(y_true, y_pred_flat))\n",
        "    allPrecision.append(precision_score(y_true, y_pred_flat))\n",
        "    allRecall.append(recall_score(y_true, y_pred_flat))\n",
        "    allF1.append(f1_score(y_true, y_pred_flat))\n",
        "\n",
        "    # print(\"\\nHidden Layer Size:\", hidden)\n",
        "    # print(\"Activation Method:\", activation)\n",
        "    # print(\"Gradient Method:\", gradient)\n",
        "\n",
        "\n",
        "    allyTrue.append(y_true)\n",
        "    allyPred.append(y_pred_flat)\n",
        "\n",
        "    # print(\"\\nConfusion Matrix:\")\n",
        "    # print(confusion_matrix(y_true, y_pred_flat))\n",
        "    # print(\"\\nClassification Report:\")\n",
        "    # print(classification_report(y_true, y_pred_flat))\n",
        "\n",
        "\n",
        "      # TN FP\n",
        "      # FN TP\n",
        "\n",
        "    # break\n",
        "  # break\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4YMaOWRYzar",
        "outputId": "c9f23289-9d37-4e49-97ee-91fecb379175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 16\n",
            "Activation Method: tanh\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Activation Method: sigmoid\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Activation Method: relu\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Activation Method: tanh\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Activation Method: sigmoid\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Activation Method: relu\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Activation Method: tanh\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Activation Method: sigmoid\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Activation Method: relu\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# printing all results...\n",
        "index = 0\n",
        "for hidden in allHiddenSizes:\n",
        "  for activation in allActivationMethods:\n",
        "    # for gradient in allGradientMethods:\n",
        "    print(\"Hidden Layer Size:\", hidden)\n",
        "    print(\"Activation Method:\", activation)\n",
        "    # print(\"Gradient Method:\", gradient)\n",
        "\n",
        "    print(\"\\nAccuracy:\", allAccuracy[index])\n",
        "    print(\"Precision:\", allPrecision[index])\n",
        "    print(\"Recall:\", allRecall[index])\n",
        "    print(\"F1 Score:\", allF1[index])\n",
        "\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(allyTrue[index], allyPred[index]))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(allyTrue[index], allyPred[index]))\n",
        "\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktsQT9uHESAw"
      },
      "source": [
        "Discussion:\n",
        "\n",
        "The tecnique used to help with runtime was mainly just randomly selecting a smaller population of my data (from 100000 entries to 20000).\n",
        "\n",
        "\n",
        "For our hypertuning, varying hidden layer did not seem to have an effect on the results.\n",
        "\n",
        "However, there was certainly a big notice in both runtime and accuracy (in terms of loss) for varying gradient. Batch gradient had the highest loss, while not having significantly long runtime. On the other hand, stochastic did not converge as well as the fact that it took severely more time to execute, which is why I had to lower the number of iterations. Lastly, minibatch gradient seemed to do ok in runtime. It is worth noting that the only gradient to converge was batch... Perhaps this is due to the sensitivity of hyper parameter tuning, as there are many things that can be tuned.\n",
        "\n",
        "Lastly, upon independently varying activation functions, it was observed that both relu and and tanh seemed to display similar performance. However, sigmoid was generally the most accurate (least amount of final loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEsa-pVRHRkz"
      },
      "source": [
        "TASK2 START..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YybqsjcCRBs4"
      },
      "source": [
        "While my dataset is tabular, it can be considered complex, given the total number of data observations (100000) and data features that it has (18).\n",
        "\n",
        "For the Deep Learning Framework that I chose to implement, I used PyTorch.\n",
        "The resources I utilized for the completion of this part 2 are the following:\n",
        "- https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
        "- https://docs.pytorch.org/docs/stable/optim.html\n",
        "- https://blog.paperspace.com/why-use-pytorch-deep-learning-framework/\n",
        "\n",
        "I also used ChatGPT to help me with debugging and also getting familiar with the PyTorch built-in methods.\n",
        "\n",
        "\n",
        "The main motivation for using PyTorch is given how beginner friendly it is, both in syntax and is considered easier to learn compared to other deep learning frameworks, such as TensorFlow.\n",
        "\n",
        "\n",
        "To implement forward propagation, I needed to learn how to build custom model layers using torch.nn.Linear and how to apply activation functions like ReLU and Sigmoid using torch.nn.functional. Additionally, for backward propagation, I looked into different optimizers for different verions of gradient descent. This was necessary in my hyperparameter tuning. Finally, I had to understand how to use DataLoader for batching and torch.Tensor operations for vectorized computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "nlVbiqIUrNCm"
      },
      "outputs": [],
      "source": [
        "# formatting data such that i can train-dev-test split it...\n",
        "\n",
        "# excluding \"y\" column for X matrix...\n",
        "tmp = data.drop(columns = ['isGalaxy'])\n",
        "dataNum = tmp.select_dtypes(include='number')\n",
        "X = dataNum.values\n",
        "\n",
        "# getting rid of features that don't have very high variation...\n",
        "# these features are effectively \"useless\" for the model to learn from\n",
        "selector = VarianceThreshold(threshold=1e-5)\n",
        "X = selector.fit_transform(X)\n",
        "\n",
        "# print(X.std(axis=0))\n",
        "# print(X_reduced.std(axis=0))\n",
        "\n",
        "# sys.exit(1)\n",
        "\n",
        "# standardizing...\n",
        "avg, stdev = X.mean(), X.std()\n",
        "X = (X - avg) / stdev\n",
        "\n",
        "# normalizing...\n",
        "min, max = X.min(), X.max()\n",
        "X = (X - min) / (max - min)\n",
        "\n",
        "y = data['isGalaxy'].values.reshape(-1,1)\n",
        "n = X.shape[1]\n",
        "\n",
        "if False:\n",
        "  print(X.shape)\n",
        "  sys.exit(0)\n",
        "\n",
        "if False:\n",
        "  # print(X)\n",
        "  print(y)\n",
        "  print(y.shape)\n",
        "  sys.exit(0)\n",
        "\n",
        "# dividing data into train and test sets...\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train = X_train.T\n",
        "# y_train = y_train.T\n",
        "\n",
        "if False:\n",
        "  print(X_train.shape)\n",
        "  print(y_train.shape)\n",
        "  sys.exit(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "zVmlZaULdwFm"
      },
      "outputs": [],
      "source": [
        "# converting numpy arrays to pytorch tensors...\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# creating datasets...\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# creating loaders...\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "h45lfng1ctAl"
      },
      "outputs": [],
      "source": [
        "# initializing the NN itself...\n",
        "class nnTorch(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(nnTorch, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "    # choice of nonlinear activation function is RELU...\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # nn.init.xavier_uniform_(self.fc1.weight)\n",
        "    # nn.init.zeros_(self.fc1.bias)\n",
        "    # nn.init.xavier_uniform_(self.fc2.weight)\n",
        "    # nn.init.zeros_(self.fc2.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # input layer --> hidden layer\n",
        "    out = self.fc1(x)\n",
        "\n",
        "    # apply nonlinear activation (hidden layer --> hidden layer)\n",
        "    out = self.relu(out)\n",
        "\n",
        "    # hidden layer --> output layer\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    # binary classification, so we use sigmoid for final nonlinear activation\n",
        "    # sigmoid specifically clamps the output btwn 0 and 1\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kcOq_sReD2s"
      },
      "source": [
        "hyperparameter tuning...\n",
        "(independently varying factors such as hidden layer size, learning rate, activation method, optimizer...)\n",
        "\n",
        "i will show the accuracy, precision, recall, and f1 score upon varying the following 2 parameters:\n",
        "- hidden layer size\n",
        "- optimizer for gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "Smxdyn8Md__E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb38bfda-3272-4813-e9d1-44e9b108d787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 0.6904\n",
            "Epoch 2/20, Loss: 0.6931\n",
            "Epoch 3/20, Loss: 0.6920\n",
            "Epoch 4/20, Loss: 0.6844\n",
            "Epoch 5/20, Loss: 0.6841\n",
            "Epoch 6/20, Loss: 0.6913\n",
            "Epoch 7/20, Loss: 0.6840\n",
            "Epoch 8/20, Loss: 0.6950\n",
            "Epoch 9/20, Loss: 0.6925\n",
            "Epoch 10/20, Loss: 0.6833\n",
            "Epoch 11/20, Loss: 0.6881\n",
            "Epoch 12/20, Loss: 0.6822\n",
            "Epoch 13/20, Loss: 0.6959\n",
            "Epoch 14/20, Loss: 0.6886\n",
            "Epoch 15/20, Loss: 0.6923\n",
            "Epoch 16/20, Loss: 0.6890\n",
            "Epoch 17/20, Loss: 0.6826\n",
            "Epoch 18/20, Loss: 0.6950\n",
            "Epoch 19/20, Loss: 0.6875\n",
            "Epoch 20/20, Loss: 0.6963\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 0.7075\n",
            "Epoch 2/20, Loss: 0.7106\n",
            "Epoch 3/20, Loss: 0.7009\n",
            "Epoch 4/20, Loss: 0.7128\n",
            "Epoch 5/20, Loss: 0.7053\n",
            "Epoch 6/20, Loss: 0.7055\n",
            "Epoch 7/20, Loss: 0.7149\n",
            "Epoch 8/20, Loss: 0.7078\n",
            "Epoch 9/20, Loss: 0.7043\n",
            "Epoch 10/20, Loss: 0.7046\n",
            "Epoch 11/20, Loss: 0.7118\n",
            "Epoch 12/20, Loss: 0.7016\n",
            "Epoch 13/20, Loss: 0.6983\n",
            "Epoch 14/20, Loss: 0.6980\n",
            "Epoch 15/20, Loss: 0.7032\n",
            "Epoch 16/20, Loss: 0.6962\n",
            "Epoch 17/20, Loss: 0.7015\n",
            "Epoch 18/20, Loss: 0.7007\n",
            "Epoch 19/20, Loss: 0.6954\n",
            "Epoch 20/20, Loss: 0.6946\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 0.6775\n",
            "Epoch 2/20, Loss: 0.6868\n",
            "Epoch 3/20, Loss: 0.6823\n",
            "Epoch 4/20, Loss: 0.6685\n",
            "Epoch 5/20, Loss: 0.6729\n",
            "Epoch 6/20, Loss: 0.6820\n",
            "Epoch 7/20, Loss: 0.6752\n",
            "Epoch 8/20, Loss: 0.6868\n",
            "Epoch 9/20, Loss: 0.6775\n",
            "Epoch 10/20, Loss: 0.6821\n",
            "Epoch 11/20, Loss: 0.6752\n",
            "Epoch 12/20, Loss: 0.6777\n",
            "Epoch 13/20, Loss: 0.7005\n",
            "Epoch 14/20, Loss: 0.6845\n",
            "Epoch 15/20, Loss: 0.6869\n",
            "Epoch 16/20, Loss: 0.6868\n",
            "Epoch 17/20, Loss: 0.6821\n",
            "Epoch 18/20, Loss: 0.6914\n",
            "Epoch 19/20, Loss: 0.6801\n",
            "Epoch 20/20, Loss: 0.6821\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 0.6984\n",
            "Epoch 2/20, Loss: 0.7044\n",
            "Epoch 3/20, Loss: 0.6934\n",
            "Epoch 4/20, Loss: 0.7118\n",
            "Epoch 5/20, Loss: 0.6861\n",
            "Epoch 6/20, Loss: 0.7082\n",
            "Epoch 7/20, Loss: 0.7184\n",
            "Epoch 8/20, Loss: 0.7136\n",
            "Epoch 9/20, Loss: 0.7116\n",
            "Epoch 10/20, Loss: 0.7224\n",
            "Epoch 11/20, Loss: 0.7136\n",
            "Epoch 12/20, Loss: 0.7084\n",
            "Epoch 13/20, Loss: 0.6953\n",
            "Epoch 14/20, Loss: 0.7156\n",
            "Epoch 15/20, Loss: 0.7189\n",
            "Epoch 16/20, Loss: 0.6974\n",
            "Epoch 17/20, Loss: 0.7068\n",
            "Epoch 18/20, Loss: 0.7200\n",
            "Epoch 19/20, Loss: 0.7206\n",
            "Epoch 20/20, Loss: 0.7022\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 0.6914\n",
            "Epoch 2/20, Loss: 0.7019\n",
            "Epoch 3/20, Loss: 0.6949\n",
            "Epoch 4/20, Loss: 0.6920\n",
            "Epoch 5/20, Loss: 0.6996\n",
            "Epoch 6/20, Loss: 0.6983\n",
            "Epoch 7/20, Loss: 0.6984\n",
            "Epoch 8/20, Loss: 0.6960\n",
            "Epoch 9/20, Loss: 0.6983\n",
            "Epoch 10/20, Loss: 0.6959\n",
            "Epoch 11/20, Loss: 0.6991\n",
            "Epoch 12/20, Loss: 0.6983\n",
            "Epoch 13/20, Loss: 0.6992\n",
            "Epoch 14/20, Loss: 0.6964\n",
            "Epoch 15/20, Loss: 0.6977\n",
            "Epoch 16/20, Loss: 0.7014\n",
            "Epoch 17/20, Loss: 0.6941\n",
            "Epoch 18/20, Loss: 0.6938\n",
            "Epoch 19/20, Loss: 0.6922\n",
            "Epoch 20/20, Loss: 0.6963\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 0.7120\n",
            "Epoch 2/20, Loss: 0.6918\n",
            "Epoch 3/20, Loss: 0.7092\n",
            "Epoch 4/20, Loss: 0.7170\n",
            "Epoch 5/20, Loss: 0.7029\n",
            "Epoch 6/20, Loss: 0.7086\n",
            "Epoch 7/20, Loss: 0.7040\n",
            "Epoch 8/20, Loss: 0.7023\n",
            "Epoch 9/20, Loss: 0.7093\n",
            "Epoch 10/20, Loss: 0.7087\n",
            "Epoch 11/20, Loss: 0.7174\n",
            "Epoch 12/20, Loss: 0.7067\n",
            "Epoch 13/20, Loss: 0.7139\n",
            "Epoch 14/20, Loss: 0.7118\n",
            "Epoch 15/20, Loss: 0.6983\n",
            "Epoch 16/20, Loss: 0.6989\n",
            "Epoch 17/20, Loss: 0.7025\n",
            "Epoch 18/20, Loss: 0.7088\n",
            "Epoch 19/20, Loss: 0.6914\n",
            "Epoch 20/20, Loss: 0.6964\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 0.6968\n",
            "Epoch 2/20, Loss: 0.6894\n",
            "Epoch 3/20, Loss: 0.6889\n",
            "Epoch 4/20, Loss: 0.6903\n",
            "Epoch 5/20, Loss: 0.6904\n",
            "Epoch 6/20, Loss: 0.6893\n",
            "Epoch 7/20, Loss: 0.6932\n",
            "Epoch 8/20, Loss: 0.6902\n",
            "Epoch 9/20, Loss: 0.6905\n",
            "Epoch 10/20, Loss: 0.6917\n",
            "Epoch 11/20, Loss: 0.6913\n",
            "Epoch 12/20, Loss: 0.6885\n",
            "Epoch 13/20, Loss: 0.6923\n",
            "Epoch 14/20, Loss: 0.6922\n",
            "Epoch 15/20, Loss: 0.6921\n",
            "Epoch 16/20, Loss: 0.6896\n",
            "Epoch 17/20, Loss: 0.6900\n",
            "Epoch 18/20, Loss: 0.6934\n",
            "Epoch 19/20, Loss: 0.6919\n",
            "Epoch 20/20, Loss: 0.6916\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 0.6964\n",
            "Epoch 2/20, Loss: 0.6988\n",
            "Epoch 3/20, Loss: 0.6990\n",
            "Epoch 4/20, Loss: 0.6978\n",
            "Epoch 5/20, Loss: 0.6952\n",
            "Epoch 6/20, Loss: 0.6978\n",
            "Epoch 7/20, Loss: 0.6951\n",
            "Epoch 8/20, Loss: 0.6979\n",
            "Epoch 9/20, Loss: 0.6973\n",
            "Epoch 10/20, Loss: 0.6967\n",
            "Epoch 11/20, Loss: 0.6947\n",
            "Epoch 12/20, Loss: 0.6973\n",
            "Epoch 13/20, Loss: 0.6952\n",
            "Epoch 14/20, Loss: 0.6983\n",
            "Epoch 15/20, Loss: 0.6979\n",
            "Epoch 16/20, Loss: 0.7016\n",
            "Epoch 17/20, Loss: 0.6977\n",
            "Epoch 18/20, Loss: 0.6983\n",
            "Epoch 19/20, Loss: 0.6995\n",
            "Epoch 20/20, Loss: 0.6947\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 0.6910\n",
            "Epoch 2/20, Loss: 0.6848\n",
            "Epoch 3/20, Loss: 0.6808\n",
            "Epoch 4/20, Loss: 0.6859\n",
            "Epoch 5/20, Loss: 0.6735\n",
            "Epoch 6/20, Loss: 0.6777\n",
            "Epoch 7/20, Loss: 0.6902\n",
            "Epoch 8/20, Loss: 0.6834\n",
            "Epoch 9/20, Loss: 0.6925\n",
            "Epoch 10/20, Loss: 0.6995\n",
            "Epoch 11/20, Loss: 0.6761\n",
            "Epoch 12/20, Loss: 0.6902\n",
            "Epoch 13/20, Loss: 0.6831\n",
            "Epoch 14/20, Loss: 0.6951\n",
            "Epoch 15/20, Loss: 0.6866\n",
            "Epoch 16/20, Loss: 0.6772\n",
            "Epoch 17/20, Loss: 0.6862\n",
            "Epoch 18/20, Loss: 0.6723\n",
            "Epoch 19/20, Loss: 0.6877\n",
            "Epoch 20/20, Loss: 0.6748\n"
          ]
        }
      ],
      "source": [
        "# tuning...\n",
        "allHiddenSizes = [16, 64, 128]\n",
        "# allLearningRates = [.0001, .001, .01]\n",
        "allOptimizers = [\"Adam\", \"SGD\", \"RMS\"]\n",
        "\n",
        "\n",
        "# constants...\n",
        "input_size = X_train.shape[1]\n",
        "output_size = 1\n",
        "num_epochs = 20\n",
        "learningRate = .001\n",
        "\n",
        "# we use BCELoss because this is binary classification problem...\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "allAccuracy = []\n",
        "allPrecision = []\n",
        "allRecall = []\n",
        "allF1 = []\n",
        "allyTrue = []\n",
        "allyPred = []\n",
        "\n",
        "\n",
        "for hidden in allHiddenSizes:\n",
        "  # for rate in allLearningRates:\n",
        "  for optimizerName in allOptimizers:\n",
        "    model = nnTorch(input_size, hidden, output_size)\n",
        "\n",
        "    if (optimizerName == \"Adam\"):\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
        "    elif (optimizerName == \"SGD\"):\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "    else:\n",
        "      optimizer = torch.optim.RMSprop(model.parameters(), lr=learningRate)\n",
        "\n",
        "    print(\"\\nHidden Layer Size:\", hidden)\n",
        "    print(\"Learning Rate:\", learningRate)\n",
        "    print(\"Optimizer:\", optimizerName)\n",
        "\n",
        "    model = nnTorch(input_size, hidden, output_size)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for batch_X, batch_y in train_loader:\n",
        "        # batch_y = torch.argmax(batch_y, dim=1).unsqueeze(1).float()\n",
        "        batch_y = batch_y.view(-1, 1).float()\n",
        "\n",
        "\n",
        "        if False:\n",
        "          print(batch_y)\n",
        "          sys.exit(0)\n",
        "\n",
        "        # forward...\n",
        "        outputs = model.forward(batch_X)\n",
        "        # print(\"Predictions:\", outputs.min().item(), outputs.max().item())\n",
        "\n",
        "        # print(batch_y.view(-1,1).float()[:5])\n",
        "        # sys.exit(1)\n",
        "\n",
        "        # print(\"Batch Y stats:\", batch_y.min().item(), batch_y.max().item())\n",
        "\n",
        "        loss = criterion(outputs, batch_y.view(-1, 1).float())\n",
        "\n",
        "        if False:\n",
        "          print(outputs.shape, batch_y.view(-1, 1).shape)\n",
        "          sys.exit(0)\n",
        "\n",
        "        # backward...\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # for name, param in model.named_parameters():\n",
        "        #   if param.grad is not None:\n",
        "        #     print(f\"{name} grad mean: {param.grad.mean().item():.6f}\")\n",
        "\n",
        "\n",
        "        # if (loss < epsilon):\n",
        "        #   break\n",
        "\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        y_pred = model(X_test_tensor)\n",
        "\n",
        "      y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "\n",
        "      # print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "      # print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "      # print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "      # print(\"F1:\", f1_score(y_test, y_pred))\n",
        "\n",
        "      # # confusion matrix and other evaluation metrics...\n",
        "      # print(confusion_matrix(y_test, y_pred))\n",
        "      # print(classification_report(y_test, y_pred))\n",
        "\n",
        "      allAccuracy.append(accuracy_score(y_true, y_pred_flat))\n",
        "      allPrecision.append(precision_score(y_true, y_pred_flat))\n",
        "      allRecall.append(recall_score(y_true, y_pred_flat))\n",
        "      allF1.append(f1_score(y_true, y_pred_flat))\n",
        "\n",
        "      allyTrue.append(y_true)\n",
        "      allyPred.append(y_pred_flat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing all results...\n",
        "index = 0\n",
        "for hidden in allHiddenSizes:\n",
        "  for opt in allOptimizers:\n",
        "    # for gradient in allGradientMethods:\n",
        "    print(\"Hidden Layer Size:\", hidden)\n",
        "    print(\"Optimizer:\", opt)\n",
        "    # print(\"Gradient Method:\", gradient)\n",
        "\n",
        "    print(\"\\nAccuracy:\", allAccuracy[index])\n",
        "    print(\"Precision:\", allPrecision[index])\n",
        "    print(\"Recall:\", allRecall[index])\n",
        "    print(\"F1 Score:\", allF1[index])\n",
        "\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(allyTrue[index], allyPred[index]))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(allyTrue[index], allyPred[index]))\n",
        "\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC0Nu-9bMOjG",
        "outputId": "caf4186e-7853-44c4-cd3c-3815bca3acd2"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 16\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "regularization...\n",
        "\n",
        "this is done by adding a weight decay to the optimizer..."
      ],
      "metadata": {
        "id": "l9_fic0ncRYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning...\n",
        "allHiddenSizes = [16, 64, 128]\n",
        "# allLearningRates = [.0001, .001, .01]\n",
        "allOptimizers = [\"Adam\", \"SGD\", \"RMS\"]\n",
        "\n",
        "\n",
        "# constants...\n",
        "input_size = X_train.shape[1]\n",
        "output_size = 1\n",
        "num_epochs = 20\n",
        "learningRate = .001\n",
        "\n",
        "# we use BCELoss because this is binary classification problem...\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "allAccuracy = []\n",
        "allPrecision = []\n",
        "allRecall = []\n",
        "allF1 = []\n",
        "allyTrue = []\n",
        "allyPred = []\n",
        "\n",
        "\n",
        "for hidden in allHiddenSizes:\n",
        "  # for rate in allLearningRates:\n",
        "  for optimizerName in allOptimizers:\n",
        "    model = nnTorch(input_size, hidden, output_size)\n",
        "\n",
        "    if (optimizerName == \"Adam\"):\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learningRate, weight_decay=1e-4)\n",
        "    elif (optimizerName == \"SGD\"):\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=1e-4)\n",
        "    else:\n",
        "      optimizer = torch.optim.RMSprop(model.parameters(), lr=learningRate, weight_decay=1e-4)\n",
        "\n",
        "    print(\"\\nHidden Layer Size:\", hidden)\n",
        "    print(\"Learning Rate:\", learningRate)\n",
        "    print(\"Optimizer:\", optimizerName)\n",
        "\n",
        "    model = nnTorch(input_size, hidden, output_size)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for batch_X, batch_y in train_loader:\n",
        "        # batch_y = torch.argmax(batch_y, dim=1).unsqueeze(1).float()\n",
        "        batch_y = batch_y.view(-1, 1).float()\n",
        "\n",
        "\n",
        "        if False:\n",
        "          print(batch_y)\n",
        "          sys.exit(0)\n",
        "\n",
        "        # forward...\n",
        "        outputs = model.forward(batch_X)\n",
        "        # print(\"Predictions:\", outputs.min().item(), outputs.max().item())\n",
        "\n",
        "        # print(batch_y.view(-1,1).float()[:5])\n",
        "        # sys.exit(1)\n",
        "\n",
        "        # print(\"Batch Y stats:\", batch_y.min().item(), batch_y.max().item())\n",
        "\n",
        "        loss = criterion(outputs, batch_y.view(-1, 1).float())\n",
        "\n",
        "        if False:\n",
        "          print(outputs.shape, batch_y.view(-1, 1).shape)\n",
        "          sys.exit(0)\n",
        "\n",
        "        # backward...\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # for name, param in model.named_parameters():\n",
        "        #   if param.grad is not None:\n",
        "        #     print(f\"{name} grad mean: {param.grad.mean().item():.6f}\")\n",
        "\n",
        "\n",
        "        # if (loss < epsilon):\n",
        "        #   break\n",
        "\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        y_pred = model(X_test_tensor)\n",
        "\n",
        "      y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "\n",
        "      # print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "      # print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "      # print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "      # print(\"F1:\", f1_score(y_test, y_pred))\n",
        "\n",
        "      # # confusion matrix and other evaluation metrics...\n",
        "      # print(confusion_matrix(y_test, y_pred))\n",
        "      # print(classification_report(y_test, y_pred))\n",
        "\n",
        "      allAccuracy.append(accuracy_score(y_true, y_pred_flat))\n",
        "      allPrecision.append(precision_score(y_true, y_pred_flat))\n",
        "      allRecall.append(recall_score(y_true, y_pred_flat))\n",
        "      allF1.append(f1_score(y_true, y_pred_flat))\n",
        "\n",
        "      allyTrue.append(y_true)\n",
        "      allyPred.append(y_pred_flat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sxOjkvqcREm",
        "outputId": "84eef421-3668-4653-ea3c-f57c1b45967b"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 0.7539\n",
            "Epoch 2/20, Loss: 0.7357\n",
            "Epoch 3/20, Loss: 0.7700\n",
            "Epoch 4/20, Loss: 0.7313\n",
            "Epoch 5/20, Loss: 0.6971\n",
            "Epoch 6/20, Loss: 0.7477\n",
            "Epoch 7/20, Loss: 0.7204\n",
            "Epoch 8/20, Loss: 0.7479\n",
            "Epoch 9/20, Loss: 0.7244\n",
            "Epoch 10/20, Loss: 0.7693\n",
            "Epoch 11/20, Loss: 0.7476\n",
            "Epoch 12/20, Loss: 0.7380\n",
            "Epoch 13/20, Loss: 0.7416\n",
            "Epoch 14/20, Loss: 0.7418\n",
            "Epoch 15/20, Loss: 0.7596\n",
            "Epoch 16/20, Loss: 0.7144\n",
            "Epoch 17/20, Loss: 0.7201\n",
            "Epoch 18/20, Loss: 0.7863\n",
            "Epoch 19/20, Loss: 0.7532\n",
            "Epoch 20/20, Loss: 0.7245\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 0.6942\n",
            "Epoch 2/20, Loss: 0.6847\n",
            "Epoch 3/20, Loss: 0.6612\n",
            "Epoch 4/20, Loss: 0.6874\n",
            "Epoch 5/20, Loss: 0.6613\n",
            "Epoch 6/20, Loss: 0.6866\n",
            "Epoch 7/20, Loss: 0.6739\n",
            "Epoch 8/20, Loss: 0.6733\n",
            "Epoch 9/20, Loss: 0.6976\n",
            "Epoch 10/20, Loss: 0.6873\n",
            "Epoch 11/20, Loss: 0.6789\n",
            "Epoch 12/20, Loss: 0.6919\n",
            "Epoch 13/20, Loss: 0.6533\n",
            "Epoch 14/20, Loss: 0.6934\n",
            "Epoch 15/20, Loss: 0.6617\n",
            "Epoch 16/20, Loss: 0.6742\n",
            "Epoch 17/20, Loss: 0.6907\n",
            "Epoch 18/20, Loss: 0.6824\n",
            "Epoch 19/20, Loss: 0.6780\n",
            "Epoch 20/20, Loss: 0.6949\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 0.6713\n",
            "Epoch 2/20, Loss: 0.6716\n",
            "Epoch 3/20, Loss: 0.6678\n",
            "Epoch 4/20, Loss: 0.6787\n",
            "Epoch 5/20, Loss: 0.6748\n",
            "Epoch 6/20, Loss: 0.7026\n",
            "Epoch 7/20, Loss: 0.6714\n",
            "Epoch 8/20, Loss: 0.7137\n",
            "Epoch 9/20, Loss: 0.6542\n",
            "Epoch 10/20, Loss: 0.6820\n",
            "Epoch 11/20, Loss: 0.6751\n",
            "Epoch 12/20, Loss: 0.6784\n",
            "Epoch 13/20, Loss: 0.6892\n",
            "Epoch 14/20, Loss: 0.6756\n",
            "Epoch 15/20, Loss: 0.6777\n",
            "Epoch 16/20, Loss: 0.6952\n",
            "Epoch 17/20, Loss: 0.6818\n",
            "Epoch 18/20, Loss: 0.6822\n",
            "Epoch 19/20, Loss: 0.6888\n",
            "Epoch 20/20, Loss: 0.6643\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 0.6956\n",
            "Epoch 2/20, Loss: 0.6872\n",
            "Epoch 3/20, Loss: 0.6876\n",
            "Epoch 4/20, Loss: 0.6812\n",
            "Epoch 5/20, Loss: 0.6878\n",
            "Epoch 6/20, Loss: 0.6815\n",
            "Epoch 7/20, Loss: 0.6742\n",
            "Epoch 8/20, Loss: 0.6937\n",
            "Epoch 9/20, Loss: 0.6818\n",
            "Epoch 10/20, Loss: 0.6871\n",
            "Epoch 11/20, Loss: 0.6819\n",
            "Epoch 12/20, Loss: 0.6794\n",
            "Epoch 13/20, Loss: 0.6994\n",
            "Epoch 14/20, Loss: 0.6994\n",
            "Epoch 15/20, Loss: 0.6910\n",
            "Epoch 16/20, Loss: 0.6835\n",
            "Epoch 17/20, Loss: 0.6698\n",
            "Epoch 18/20, Loss: 0.6857\n",
            "Epoch 19/20, Loss: 0.6814\n",
            "Epoch 20/20, Loss: 0.6738\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 0.6956\n",
            "Epoch 2/20, Loss: 0.6920\n",
            "Epoch 3/20, Loss: 0.6931\n",
            "Epoch 4/20, Loss: 0.6884\n",
            "Epoch 5/20, Loss: 0.6921\n",
            "Epoch 6/20, Loss: 0.6910\n",
            "Epoch 7/20, Loss: 0.6893\n",
            "Epoch 8/20, Loss: 0.6916\n",
            "Epoch 9/20, Loss: 0.6944\n",
            "Epoch 10/20, Loss: 0.6935\n",
            "Epoch 11/20, Loss: 0.6919\n",
            "Epoch 12/20, Loss: 0.6873\n",
            "Epoch 13/20, Loss: 0.6868\n",
            "Epoch 14/20, Loss: 0.6895\n",
            "Epoch 15/20, Loss: 0.6908\n",
            "Epoch 16/20, Loss: 0.6901\n",
            "Epoch 17/20, Loss: 0.6863\n",
            "Epoch 18/20, Loss: 0.6842\n",
            "Epoch 19/20, Loss: 0.6911\n",
            "Epoch 20/20, Loss: 0.6899\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 0.7023\n",
            "Epoch 2/20, Loss: 0.7023\n",
            "Epoch 3/20, Loss: 0.7054\n",
            "Epoch 4/20, Loss: 0.7094\n",
            "Epoch 5/20, Loss: 0.6898\n",
            "Epoch 6/20, Loss: 0.7022\n",
            "Epoch 7/20, Loss: 0.7041\n",
            "Epoch 8/20, Loss: 0.6996\n",
            "Epoch 9/20, Loss: 0.7163\n",
            "Epoch 10/20, Loss: 0.6995\n",
            "Epoch 11/20, Loss: 0.7010\n",
            "Epoch 12/20, Loss: 0.6997\n",
            "Epoch 13/20, Loss: 0.6939\n",
            "Epoch 14/20, Loss: 0.7066\n",
            "Epoch 15/20, Loss: 0.6953\n",
            "Epoch 16/20, Loss: 0.6926\n",
            "Epoch 17/20, Loss: 0.6954\n",
            "Epoch 18/20, Loss: 0.7065\n",
            "Epoch 19/20, Loss: 0.6980\n",
            "Epoch 20/20, Loss: 0.7051\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 0.6950\n",
            "Epoch 2/20, Loss: 0.6924\n",
            "Epoch 3/20, Loss: 0.6957\n",
            "Epoch 4/20, Loss: 0.6939\n",
            "Epoch 5/20, Loss: 0.6945\n",
            "Epoch 6/20, Loss: 0.6962\n",
            "Epoch 7/20, Loss: 0.6947\n",
            "Epoch 8/20, Loss: 0.6953\n",
            "Epoch 9/20, Loss: 0.6966\n",
            "Epoch 10/20, Loss: 0.6944\n",
            "Epoch 11/20, Loss: 0.6927\n",
            "Epoch 12/20, Loss: 0.6955\n",
            "Epoch 13/20, Loss: 0.6949\n",
            "Epoch 14/20, Loss: 0.6947\n",
            "Epoch 15/20, Loss: 0.6950\n",
            "Epoch 16/20, Loss: 0.6953\n",
            "Epoch 17/20, Loss: 0.6951\n",
            "Epoch 18/20, Loss: 0.6960\n",
            "Epoch 19/20, Loss: 0.6943\n",
            "Epoch 20/20, Loss: 0.6958\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 0.6914\n",
            "Epoch 2/20, Loss: 0.6924\n",
            "Epoch 3/20, Loss: 0.6921\n",
            "Epoch 4/20, Loss: 0.6928\n",
            "Epoch 5/20, Loss: 0.6931\n",
            "Epoch 6/20, Loss: 0.6919\n",
            "Epoch 7/20, Loss: 0.6916\n",
            "Epoch 8/20, Loss: 0.6938\n",
            "Epoch 9/20, Loss: 0.6924\n",
            "Epoch 10/20, Loss: 0.6922\n",
            "Epoch 11/20, Loss: 0.6921\n",
            "Epoch 12/20, Loss: 0.6918\n",
            "Epoch 13/20, Loss: 0.6925\n",
            "Epoch 14/20, Loss: 0.6921\n",
            "Epoch 15/20, Loss: 0.6928\n",
            "Epoch 16/20, Loss: 0.6921\n",
            "Epoch 17/20, Loss: 0.6918\n",
            "Epoch 18/20, Loss: 0.6916\n",
            "Epoch 19/20, Loss: 0.6928\n",
            "Epoch 20/20, Loss: 0.6919\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 0.7311\n",
            "Epoch 2/20, Loss: 0.7141\n",
            "Epoch 3/20, Loss: 0.7242\n",
            "Epoch 4/20, Loss: 0.7089\n",
            "Epoch 5/20, Loss: 0.7187\n",
            "Epoch 6/20, Loss: 0.7062\n",
            "Epoch 7/20, Loss: 0.7315\n",
            "Epoch 8/20, Loss: 0.7238\n",
            "Epoch 9/20, Loss: 0.7011\n",
            "Epoch 10/20, Loss: 0.7242\n",
            "Epoch 11/20, Loss: 0.7232\n",
            "Epoch 12/20, Loss: 0.7068\n",
            "Epoch 13/20, Loss: 0.7165\n",
            "Epoch 14/20, Loss: 0.7162\n",
            "Epoch 15/20, Loss: 0.7161\n",
            "Epoch 16/20, Loss: 0.7089\n",
            "Epoch 17/20, Loss: 0.7137\n",
            "Epoch 18/20, Loss: 0.7075\n",
            "Epoch 19/20, Loss: 0.7164\n",
            "Epoch 20/20, Loss: 0.7141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing all results...\n",
        "index = 0\n",
        "for hidden in allHiddenSizes:\n",
        "  for opt in allOptimizers:\n",
        "    # for gradient in allGradientMethods:\n",
        "    print(\"Hidden Layer Size:\", hidden)\n",
        "    print(\"Optimizer:\", opt)\n",
        "    # print(\"Gradient Method:\", gradient)\n",
        "\n",
        "    print(\"\\nAccuracy:\", allAccuracy[index])\n",
        "    print(\"Precision:\", allPrecision[index])\n",
        "    print(\"Recall:\", allRecall[index])\n",
        "    print(\"F1 Score:\", allF1[index])\n",
        "\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(allyTrue[index], allyPred[index]))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(allyTrue[index], allyPred[index]))\n",
        "\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89en3Jbcopr",
        "outputId": "3cd30139-3eaf-4e10-8fe1-27022f35867a"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 16\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYJuzRnlYn5K"
      },
      "source": [
        "no normalization / standardization of input..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "rgDOROuoYqAx"
      },
      "outputs": [],
      "source": [
        "# formatting data such that i can train-dev-test split it...\n",
        "\n",
        "# excluding \"y\" column for X matrix...\n",
        "tmp = data.drop(columns = ['isGalaxy'])\n",
        "dataNum = tmp.select_dtypes(include='number')\n",
        "X = dataNum.values\n",
        "\n",
        "\n",
        "y = data['isGalaxy'].values.reshape(-1,1)\n",
        "n = X.shape[1]\n",
        "\n",
        "\n",
        "# dividing data into train and test sets...\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# X_train = X_train.T\n",
        "# y_train = y_train.T\n",
        "\n",
        "if False:\n",
        "  print(X_train.shape)\n",
        "  print(y_train.shape)\n",
        "  sys.exit(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "GS3O7qN4ZKhv"
      },
      "outputs": [],
      "source": [
        "# converting numpy arrays to pytorch tensors...\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# creating datasets...\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# creating loaders...\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning...\n",
        "allHiddenSizes = [16, 64, 128]\n",
        "# allLearningRates = [.0001, .001, .01]\n",
        "allOptimizers = [\"Adam\", \"SGD\", \"RMS\"]\n",
        "\n",
        "\n",
        "# constants...\n",
        "input_size = X_train.shape[1]\n",
        "output_size = 1\n",
        "num_epochs = 20\n",
        "learningRate = .001\n",
        "\n",
        "# we use BCELoss because this is binary classification problem...\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "allAccuracy = []\n",
        "allPrecision = []\n",
        "allRecall = []\n",
        "allF1 = []\n",
        "allyTrue = []\n",
        "allyPred = []\n",
        "\n",
        "\n",
        "for hidden in allHiddenSizes:\n",
        "  # for rate in allLearningRates:\n",
        "  for optimizerName in allOptimizers:\n",
        "    model = nnTorch(input_size, hidden, output_size)\n",
        "\n",
        "    if (optimizerName == \"Adam\"):\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
        "    elif (optimizerName == \"SGD\"):\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "    else:\n",
        "      optimizer = torch.optim.RMSprop(model.parameters(), lr=learningRate)\n",
        "\n",
        "    print(\"\\nHidden Layer Size:\", hidden)\n",
        "    print(\"Learning Rate:\", learningRate)\n",
        "    print(\"Optimizer:\", optimizerName)\n",
        "\n",
        "    model = nnTorch(input_size, hidden, output_size)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      for batch_X, batch_y in train_loader:\n",
        "        # batch_y = torch.argmax(batch_y, dim=1).unsqueeze(1).float()\n",
        "        batch_y = batch_y.view(-1, 1).float()\n",
        "\n",
        "\n",
        "        if False:\n",
        "          print(batch_y)\n",
        "          sys.exit(0)\n",
        "\n",
        "        # forward...\n",
        "        outputs = model.forward(batch_X)\n",
        "        # print(\"Predictions:\", outputs.min().item(), outputs.max().item())\n",
        "\n",
        "        # print(batch_y.view(-1,1).float()[:5])\n",
        "        # sys.exit(1)\n",
        "\n",
        "        # print(\"Batch Y stats:\", batch_y.min().item(), batch_y.max().item())\n",
        "\n",
        "        loss = criterion(outputs, batch_y.view(-1, 1).float())\n",
        "\n",
        "        if False:\n",
        "          print(outputs.shape, batch_y.view(-1, 1).shape)\n",
        "          sys.exit(0)\n",
        "\n",
        "        # backward...\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # for name, param in model.named_parameters():\n",
        "        #   if param.grad is not None:\n",
        "        #     print(f\"{name} grad mean: {param.grad.mean().item():.6f}\")\n",
        "\n",
        "\n",
        "        # if (loss < epsilon):\n",
        "        #   break\n",
        "\n",
        "      print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        y_pred = model(X_test_tensor)\n",
        "\n",
        "      y_pred = (y_pred > 0.5).float()\n",
        "\n",
        "\n",
        "      # print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "      # print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "      # print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "      # print(\"F1:\", f1_score(y_test, y_pred))\n",
        "\n",
        "      # # confusion matrix and other evaluation metrics...\n",
        "      # print(confusion_matrix(y_test, y_pred))\n",
        "      # print(classification_report(y_test, y_pred))\n",
        "\n",
        "      allAccuracy.append(accuracy_score(y_true, y_pred_flat))\n",
        "      allPrecision.append(precision_score(y_true, y_pred_flat))\n",
        "      allRecall.append(recall_score(y_true, y_pred_flat))\n",
        "      allF1.append(f1_score(y_true, y_pred_flat))\n",
        "\n",
        "      allyTrue.append(y_true)\n",
        "      allyPred.append(y_pred_flat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RENXhpS-aa5U",
        "outputId": "3afeca46-623e-458c-9ae9-16358b9b7f70"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 37.5000\n",
            "Epoch 2/20, Loss: 45.3125\n",
            "Epoch 3/20, Loss: 25.0000\n",
            "Epoch 4/20, Loss: 42.1875\n",
            "Epoch 5/20, Loss: 42.1875\n",
            "Epoch 6/20, Loss: 21.8750\n",
            "Epoch 7/20, Loss: 42.1875\n",
            "Epoch 8/20, Loss: 43.7500\n",
            "Epoch 9/20, Loss: 42.1875\n",
            "Epoch 10/20, Loss: 45.3125\n",
            "Epoch 11/20, Loss: 50.0000\n",
            "Epoch 12/20, Loss: 39.0625\n",
            "Epoch 13/20, Loss: 43.7500\n",
            "Epoch 14/20, Loss: 42.1875\n",
            "Epoch 15/20, Loss: 43.7500\n",
            "Epoch 16/20, Loss: 35.9375\n",
            "Epoch 17/20, Loss: 43.7500\n",
            "Epoch 18/20, Loss: 25.0000\n",
            "Epoch 19/20, Loss: 40.6250\n",
            "Epoch 20/20, Loss: 35.9375\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 51.5625\n",
            "Epoch 2/20, Loss: 46.8750\n",
            "Epoch 3/20, Loss: 60.9375\n",
            "Epoch 4/20, Loss: 60.9375\n",
            "Epoch 5/20, Loss: 51.5625\n",
            "Epoch 6/20, Loss: 59.3750\n",
            "Epoch 7/20, Loss: 40.6250\n",
            "Epoch 8/20, Loss: 56.2500\n",
            "Epoch 9/20, Loss: 59.3750\n",
            "Epoch 10/20, Loss: 53.1250\n",
            "Epoch 11/20, Loss: 51.5625\n",
            "Epoch 12/20, Loss: 62.5000\n",
            "Epoch 13/20, Loss: 64.0625\n",
            "Epoch 14/20, Loss: 60.9375\n",
            "Epoch 15/20, Loss: 65.6250\n",
            "Epoch 16/20, Loss: 57.8125\n",
            "Epoch 17/20, Loss: 53.1250\n",
            "Epoch 18/20, Loss: 54.6875\n",
            "Epoch 19/20, Loss: 59.3750\n",
            "Epoch 20/20, Loss: 56.2500\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 68.7500\n",
            "Epoch 2/20, Loss: 57.8125\n",
            "Epoch 3/20, Loss: 67.1875\n",
            "Epoch 4/20, Loss: 60.9375\n",
            "Epoch 5/20, Loss: 56.2500\n",
            "Epoch 6/20, Loss: 60.9375\n",
            "Epoch 7/20, Loss: 56.2500\n",
            "Epoch 8/20, Loss: 50.0000\n",
            "Epoch 9/20, Loss: 56.2500\n",
            "Epoch 10/20, Loss: 70.3125\n",
            "Epoch 11/20, Loss: 75.0000\n",
            "Epoch 12/20, Loss: 67.1875\n",
            "Epoch 13/20, Loss: 67.1875\n",
            "Epoch 14/20, Loss: 62.5000\n",
            "Epoch 15/20, Loss: 59.3750\n",
            "Epoch 16/20, Loss: 56.2500\n",
            "Epoch 17/20, Loss: 51.5625\n",
            "Epoch 18/20, Loss: 57.8125\n",
            "Epoch 19/20, Loss: 59.3750\n",
            "Epoch 20/20, Loss: 64.0625\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 39.0625\n",
            "Epoch 2/20, Loss: 43.7500\n",
            "Epoch 3/20, Loss: 34.3750\n",
            "Epoch 4/20, Loss: 42.1875\n",
            "Epoch 5/20, Loss: 40.6250\n",
            "Epoch 6/20, Loss: 43.7500\n",
            "Epoch 7/20, Loss: 59.3750\n",
            "Epoch 8/20, Loss: 45.3125\n",
            "Epoch 9/20, Loss: 32.8125\n",
            "Epoch 10/20, Loss: 32.8125\n",
            "Epoch 11/20, Loss: 35.9375\n",
            "Epoch 12/20, Loss: 34.3750\n",
            "Epoch 13/20, Loss: 25.0000\n",
            "Epoch 14/20, Loss: 42.1875\n",
            "Epoch 15/20, Loss: 32.8125\n",
            "Epoch 16/20, Loss: 34.3750\n",
            "Epoch 17/20, Loss: 39.0625\n",
            "Epoch 18/20, Loss: 46.8750\n",
            "Epoch 19/20, Loss: 37.5000\n",
            "Epoch 20/20, Loss: 45.3125\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 57.8125\n",
            "Epoch 2/20, Loss: 70.3125\n",
            "Epoch 3/20, Loss: 60.9375\n",
            "Epoch 4/20, Loss: 60.9375\n",
            "Epoch 5/20, Loss: 57.8125\n",
            "Epoch 6/20, Loss: 62.5000\n",
            "Epoch 7/20, Loss: 59.3750\n",
            "Epoch 8/20, Loss: 48.4375\n",
            "Epoch 9/20, Loss: 51.5625\n",
            "Epoch 10/20, Loss: 64.0625\n",
            "Epoch 11/20, Loss: 64.0625\n",
            "Epoch 12/20, Loss: 57.8125\n",
            "Epoch 13/20, Loss: 54.6875\n",
            "Epoch 14/20, Loss: 62.5000\n",
            "Epoch 15/20, Loss: 53.1250\n",
            "Epoch 16/20, Loss: 62.5000\n",
            "Epoch 17/20, Loss: 54.6875\n",
            "Epoch 18/20, Loss: 62.5000\n",
            "Epoch 19/20, Loss: 62.5000\n",
            "Epoch 20/20, Loss: 64.0625\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 50.0000\n",
            "Epoch 2/20, Loss: 56.2500\n",
            "Epoch 3/20, Loss: 56.2500\n",
            "Epoch 4/20, Loss: 57.8125\n",
            "Epoch 5/20, Loss: 57.8125\n",
            "Epoch 6/20, Loss: 60.9375\n",
            "Epoch 7/20, Loss: 59.3750\n",
            "Epoch 8/20, Loss: 54.6875\n",
            "Epoch 9/20, Loss: 62.5000\n",
            "Epoch 10/20, Loss: 60.9375\n",
            "Epoch 11/20, Loss: 53.1250\n",
            "Epoch 12/20, Loss: 59.3750\n",
            "Epoch 13/20, Loss: 54.6875\n",
            "Epoch 14/20, Loss: 53.1250\n",
            "Epoch 15/20, Loss: 60.9375\n",
            "Epoch 16/20, Loss: 62.5000\n",
            "Epoch 17/20, Loss: 46.8750\n",
            "Epoch 18/20, Loss: 60.9375\n",
            "Epoch 19/20, Loss: 54.6875\n",
            "Epoch 20/20, Loss: 65.6250\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: Adam\n",
            "Epoch 1/20, Loss: 46.8750\n",
            "Epoch 2/20, Loss: 51.5625\n",
            "Epoch 3/20, Loss: 46.8750\n",
            "Epoch 4/20, Loss: 42.1875\n",
            "Epoch 5/20, Loss: 45.3125\n",
            "Epoch 6/20, Loss: 45.3125\n",
            "Epoch 7/20, Loss: 45.3125\n",
            "Epoch 8/20, Loss: 35.9375\n",
            "Epoch 9/20, Loss: 54.6875\n",
            "Epoch 10/20, Loss: 40.6250\n",
            "Epoch 11/20, Loss: 45.3125\n",
            "Epoch 12/20, Loss: 57.8125\n",
            "Epoch 13/20, Loss: 35.9375\n",
            "Epoch 14/20, Loss: 48.4375\n",
            "Epoch 15/20, Loss: 48.4375\n",
            "Epoch 16/20, Loss: 43.7500\n",
            "Epoch 17/20, Loss: 60.9375\n",
            "Epoch 18/20, Loss: 45.3125\n",
            "Epoch 19/20, Loss: 45.3125\n",
            "Epoch 20/20, Loss: 46.8750\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: SGD\n",
            "Epoch 1/20, Loss: 50.0000\n",
            "Epoch 2/20, Loss: 53.1250\n",
            "Epoch 3/20, Loss: 59.3750\n",
            "Epoch 4/20, Loss: 51.5625\n",
            "Epoch 5/20, Loss: 62.5000\n",
            "Epoch 6/20, Loss: 59.3750\n",
            "Epoch 7/20, Loss: 68.7500\n",
            "Epoch 8/20, Loss: 62.5000\n",
            "Epoch 9/20, Loss: 59.3750\n",
            "Epoch 10/20, Loss: 81.2500\n",
            "Epoch 11/20, Loss: 42.1875\n",
            "Epoch 12/20, Loss: 46.8750\n",
            "Epoch 13/20, Loss: 62.5000\n",
            "Epoch 14/20, Loss: 62.5000\n",
            "Epoch 15/20, Loss: 54.6875\n",
            "Epoch 16/20, Loss: 46.8750\n",
            "Epoch 17/20, Loss: 64.0625\n",
            "Epoch 18/20, Loss: 60.9375\n",
            "Epoch 19/20, Loss: 62.5000\n",
            "Epoch 20/20, Loss: 57.8125\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Learning Rate: 0.001\n",
            "Optimizer: RMS\n",
            "Epoch 1/20, Loss: 43.7500\n",
            "Epoch 2/20, Loss: 42.1875\n",
            "Epoch 3/20, Loss: 42.1875\n",
            "Epoch 4/20, Loss: 39.0625\n",
            "Epoch 5/20, Loss: 31.2500\n",
            "Epoch 6/20, Loss: 46.8750\n",
            "Epoch 7/20, Loss: 45.3125\n",
            "Epoch 8/20, Loss: 42.1875\n",
            "Epoch 9/20, Loss: 39.0625\n",
            "Epoch 10/20, Loss: 40.6250\n",
            "Epoch 11/20, Loss: 48.4375\n",
            "Epoch 12/20, Loss: 40.6250\n",
            "Epoch 13/20, Loss: 46.8750\n",
            "Epoch 14/20, Loss: 39.0625\n",
            "Epoch 15/20, Loss: 37.5000\n",
            "Epoch 16/20, Loss: 28.1250\n",
            "Epoch 17/20, Loss: 45.3125\n",
            "Epoch 18/20, Loss: 35.9375\n",
            "Epoch 19/20, Loss: 40.6250\n",
            "Epoch 20/20, Loss: 51.5625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing all results...\n",
        "index = 0\n",
        "for hidden in allHiddenSizes:\n",
        "  for opt in allOptimizers:\n",
        "    # for gradient in allGradientMethods:\n",
        "    print(\"Hidden Layer Size:\", hidden)\n",
        "    print(\"Optimizer:\", opt)\n",
        "    # print(\"Gradient Method:\", gradient)\n",
        "\n",
        "    print(\"\\nAccuracy:\", allAccuracy[index])\n",
        "    print(\"Precision:\", allPrecision[index])\n",
        "    print(\"Recall:\", allRecall[index])\n",
        "    print(\"F1 Score:\", allF1[index])\n",
        "\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(allyTrue[index], allyPred[index]))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(allyTrue[index], allyPred[index]))\n",
        "\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhSSh7bladmZ",
        "outputId": "bd3e6cf9-2608-44cf-ec07-88a80a5fadb0"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden Layer Size: 16\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 16\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 64\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: Adam\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: SGD\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Hidden Layer Size: 128\n",
            "Optimizer: RMS\n",
            "\n",
            "Accuracy: 0.586\n",
            "Precision: 0.586\n",
            "Recall: 1.0\n",
            "F1 Score: 0.7389659520807061\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0 1656]\n",
            " [   0 2344]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1656\n",
            "           1       0.59      1.00      0.74      2344\n",
            "\n",
            "    accuracy                           0.59      4000\n",
            "   macro avg       0.29      0.50      0.37      4000\n",
            "weighted avg       0.34      0.59      0.43      4000\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLfwaT9tICCZ"
      },
      "source": [
        "TASK3 START..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train.ravel())\n",
        "print(\"Train acc:\", model.score(X_train, y_train))\n",
        "print(\"Test acc:\", model.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADE0LsvlYnX1",
        "outputId": "de8b87fc-ef37-4b39-af8e-ca39d2de0a29"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc: 0.6057125\n",
            "Test acc: 0.6078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc6Y4J2tZ7zO"
      },
      "source": [
        "For my hyperparameter tuning, I varied different optimizers such as RMSProp, Adam, and SGD. Concurrently, I varied the hidden layer size. By varying multiple hyperparameters at once, I was hoping to observe the highest accurate parameters for the model. However, all the results were the same.\n",
        "\n",
        "Even with incorporating regularization as well as not standardizing and normalizing the data, all the results were the same.\n",
        "\n",
        "I also noticed that the model did not seem to be learning on the data, no matter what I did to the data (standardization / normalization vs not standardization / normalization, getting rid of features that have barely any variation in them, as well as typical EDA and cleaning the data).\n",
        "\n",
        "Having checked all my work, I am inclined to believe that the problem lies with the data itself and not my model. I have a couple of reasons why I believe this:\n",
        "- my NN from scratch exhibits the exact same behavior, in which it only predicts all 1's (and in fact, the accuracy, precision scores, etc are the exact same)\n",
        "- using a prebuilt logistic regression above, we observe roughly the exact same accuracy of my model, both built from scratch and prebuilt.\n",
        "\n",
        "While the data labels themselves don't appear too unbalanced, with ~60% being 1's and the rest being 0's, my model from scratch, my prebuilt model, and the prebuild logistic regression model all exihibit the same accuracy of ~60%. This suggests that the problem lies within the data itself, such as having features that are not correlated at all with each other.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4uz7f2mo+HemooldQrcho",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}